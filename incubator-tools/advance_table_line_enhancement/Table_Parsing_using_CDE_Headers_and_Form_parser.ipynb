{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c0a10c-1269-4a48-b4c5-ef4bbbdd2644",
   "metadata": {},
   "source": [
    "# Table Parsing using Custom CDE Headers and Form parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f01fe57-ffc0-402b-81ac-5f77ebd77ece",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa07f2d-5087-4d8d-9ceb-5d46a21e8926",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the **DocAI Incubator Team**. No guarantees of performance are implied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c6bbc7-49af-4a2d-98b8-09b9b8739e57",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The purpose of this notebook is to convert tables found in PDF documents into CSV files, which are then stored in a GCS bucket. It utilizes the headers from the tables extracted by the CDE parser, along with the table output from the Form Parser, to generate the desired table result, which is subsequently saved in CSV format. Notably, this workflow does not involve any table enhancement to the input PDF files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ff6ab-a7a9-4e31-b00f-9e7706fca09f",
   "metadata": {},
   "source": [
    "# Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b0a705-8144-40d4-a92a-15488bd4d1bf",
   "metadata": {},
   "source": [
    "This tool requires the following services:\n",
    "\n",
    " * Vertex AI Notebook instance\n",
    " * Access to Document AI CDE & Form Parser Processor\n",
    " * GCS Bucket for storage purpose\n",
    " \n",
    "Google Jupyter Notebook is used for running the python notebook file. Cloud Storage Buckets is needed to store and pass input files to this script & to store results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114a1ed5-30fc-4b57-9f4a-3c84a73b3591",
   "metadata": {},
   "source": [
    "CDE for Headers, Create a Custom Document Extractor(CDE) Processor & Configure HITL to review poor performing documents. Train your CDE as per your use-case table by annotating **row headers** & **column headers** for specific use-case-table\n",
    "* Input for this step is GCS bucket containing PDF files(which has only your specific-use-case tables), now run `batch_process_documents`\n",
    "* Output JSON files will be store GCS bucket \n",
    "\n",
    "Sample image after training CDE processor for row columns & header columns\n",
    "<table>\n",
    "  <tr>\n",
    "      <td><b>CDE Sample</b></td>\n",
    "    <td><img src=\"./Images/cde_train_sample.png\" width=500 height=200></td>\n",
    "  </tr>\n",
    "</table> \n",
    "Here are sample row headers and column headers which we followed while training CDE for our specific use-case table  \n",
    "\n",
    "**column headers** are as follow a[\"SCC\", \"DNSH\", \"DNSH_P\", \"code\", \"business_measure\", \"DNSH_BE\", \"DNSH_CCA\", \"DNSH_CCM\", \"DNSH_CE\", \"DNSH_WMR\", \"min_safeguards\", \"proportion_of_bm\", \"SCC_BE\", \"SCC_CCA\", \"SCC_CCM\", \"SCC_CE\", \"SCC_P\", \"SCC_WMR\"] and **row headers** are as follow [\"taxonomy_disclosure\", \"activity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53acbcf2-499b-481d-a64d-f2f334554577",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad3f0db-8f32-4fec-b480-a17cd2b39967",
   "metadata": {},
   "source": [
    "# 1. Import Modules/Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8cf73b-4a79-4c6e-b214-1aef4c16240a",
   "metadata": {},
   "source": [
    "**Note** : Please download the **tool_helper_functions.py** Python file before proceeding to further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789a344-ca2e-49a6-b8ce-e7c9b1a0d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tool_helper_functions import (\n",
    "    batch_process_documents,\n",
    "    get_processor_metadata,\n",
    "    poll_hitl_operations,\n",
    "    walk_the_ocr,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60bfb4d-f9e2-48de-894a-f0c736ba45e6",
   "metadata": {},
   "source": [
    "# 2. Input Details : Configure below Input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b531f5c-b126-4074-8b4c-3b425f9b1513",
   "metadata": {},
   "source": [
    "* **project_id**: GCP project ID\n",
    "* **project_num**: GCP project Number\n",
    "* **location**: Processor location `us` or `eu`\n",
    "* **cde_processor_id**: CDE processor ID to call batch process\n",
    "* **gcs_input_uri**: GCS folder which contains input pdf files(files with only specific-use-case tables)\n",
    "* **input_mime_type**: Mime type of input files which is `application/pdf` here\n",
    "* **gcs_output_bucket_uri**: GCS output bucket uri without trailing slash\n",
    "* **gcs_cde_output_uri_prefix**: GCS output folder path to store CDE results\n",
    "* **gcs_fp_output_uri_prefix**: GCS output folder path to store FP results\n",
    "* **gcs_cde_fp_output_uri_prefix**: GCS prefix to store ocr walk final output results\n",
    "* **field_mask**: To store specific keys of document proto (entities,pages.pageNumber)\n",
    "* **timeout**: to wait for batch process LRO operation to complete\n",
    "* **flow**: for this notebook file flow is `ocr_walk`\n",
    "* **fp_processor_id**: FP Processor ID to call batch process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6c085-a232-480e-ba7d-7ac00d47e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_suffix = \"{date:%Y-%m-%d_%H:%M:%S}\".format(date=datetime.datetime.now())\n",
    "project_id = \"<your-project-id>\"\n",
    "project_num = \"<your-project-number>\"\n",
    "location = \"<processor-location>\"  # us or eu\n",
    "cde_processor_id = \"<cde-processor-id>\"\n",
    "gcs_input_uri = f\"gs://bucket_name/prefix/to_input/{datetime_suffix}\"\n",
    "input_mime_type = \"<mime-type-of-input-file>\"  # \"application/pdf\"\n",
    "gcs_output_bucket_uri = \"gs://bucket_name\"\n",
    "gcs_cde_output_uri_prefix = f\"cde_output/prefix/{datetime_suffix}\"\n",
    "gcs_fp_output_uri_prefix = f\"fp_output/prefix/{datetime_suffix}\"\n",
    "gcs_cde_fp_output_uri_prefix = f\"cde_fp_output/prefix/{datetime_suffix}\"\n",
    "field_mask = None\n",
    "timeout = 5000\n",
    "flow = \"ocr_walk\"\n",
    "fp_processor_id = \"<cde-processor-id>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc17cd73-dc06-44c9-9e1c-95b91224b077",
   "metadata": {},
   "source": [
    "# 3. Run below code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b4fdc-86ca-4fb9-acc7-8882d5e55f02",
   "metadata": {},
   "source": [
    "Now call `batch_process_documents` function to process all files in input folder(each file contains specific-use-case table only), it results metadata & operation_id of batch process(Long Running Operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d85f9-e1eb-4897-a1e8-e8e0abcacdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cde_metadata, cde_operation = batch_process_documents(\n",
    "    project_id,\n",
    "    location,\n",
    "    cde_processor_id,\n",
    "    gcs_input_uri,\n",
    "    input_mime_type,\n",
    "    gcs_output_bucket_uri,\n",
    "    gcs_cde_output_uri_prefix,\n",
    "    field_mask,\n",
    "    timeout,\n",
    ")\n",
    "print(\"CDE batch process completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c39adc-e0bf-4329-a77c-b88eb083f4ce",
   "metadata": {},
   "source": [
    "Now use `get_processor_metadata` function from utils module, it takes batch process metsdata as input and results key-value pairs of filenames & it's prefix and hitl operation-id(if input files triggers hitl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a8006e-2ab7-4644-9529-ef141c7d16ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cde_input_output_map = get_processor_metadata(cde_metadata)\n",
    "# cde_input_output_map variable data as below\n",
    "# {'03_Non-Financial_Corporate_Report_2022_extracted.pdf': {'cde': 'msci/TESTING/test_cde_output/2023-11-03_05:45:35/4236894205843634293/0', 'hitl': '12795457638097959002'}, '1962771_extracted.pdf': {'cde': 'msci/TESTING/test_cde_output/2023-11-03_05:45:35/4236894205843634293/1', 'hitl': '11860520012484438543'}, '2022_VGT_Group Annual Report_extracted.pdf': {'cde': 'msci/TESTING/test_cde_output/2023-11-03_05:45:35/4236894205843634293/5', 'hitl': '2523802694474965110'}, 'DE0007030009-JA-2022-EQ-E-00-pg144_extracted.pdf': {'cde': 'msci/TESTING/test_cde_output/2023-11-03_05:45:35/4236894205843634293/3', 'hitl': '14342450698739476592'}, 'DE0007030009-JA-2022-EQ-E-00_extracted.pdf': {'cde': 'msci/TESTING/test_cde_output/2023-11-03_05:45:35/4236894205843634293/4', 'hitl': '17242897657994716395'}, 'DE000STRA555-JA-2022-EQ-E-00_extracted.pdf': {'cde': 'msci/TESTING/test_cde_output/2023-11-03_05:45:35/4236894205843634293/2', 'hitl': '2909143051612169782'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b515162-d9a8-4674-8935-4d04165f808c",
   "metadata": {},
   "source": [
    "`poll_hitl_operations` is a waiting function to check & resolve HITL triggered documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78897271-f857-41c9-9b2d-217b85b29d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "poll_hitl_operations(project_num, location, cde_input_output_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600796f-b260-4850-ae73-ed784d382551",
   "metadata": {},
   "source": [
    "Now call `batch_process_documents` function to process all files in input folder(each file contains specific-use-case table only), it results metadata & operation_id of batch process(Long Running Operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f379570-ce6a-4b8e-b791-cfceb7f2d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_metadata, fp_operation = batch_process_documents(\n",
    "    project_id,\n",
    "    location,\n",
    "    fp_processor_id,\n",
    "    gcs_input_uri,\n",
    "    input_mime_type,\n",
    "    gcs_output_bucket_uri,\n",
    "    gcs_fp_output_uri_prefix,\n",
    "    field_mask,\n",
    "    timeout,\n",
    "    fp_processor_v2,\n",
    ")\n",
    "print(\"FP batch process completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b915c-6610-4592-96d9-e643c244523f",
   "metadata": {},
   "source": [
    "Now use `get_processor_metadata` function from utils module, it takes batch process metsdata as input and results key-value pairs of filenames & it's prefix and hitl operation-id(if input files triggers hitl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237c658-7021-4613-8f24-c3570c60c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_input_output_map = get_processor_metadata(fp_metadata, fp=True)\n",
    "# fp_input_output_map sample as below\n",
    "# {'03_Non-Financial_Corporate_Report_2022_extracted.pdf': 'msci/TESTING/fp_output/2023-11-02_18:25:31/10273358736471385291/0', '1962771_extracted.pdf': 'msci/TESTING/fp_output/2023-11-02_18:25:31/10273358736471385291/1','2022_VGT_Group Annual Report_extracted.pdf': 'msci/TESTING/fp_output/2023-11-02_18:25:31/10273358736471385291/4','DE0007030009-JA-2022-EQ-E-00-pg144_extracted.pdf': 'msci/TESTING/fp_output/2023-11-02_18:25:31/10273358736471385291/5','DE0007030009-JA-2022-EQ-E-00_extracted.pdf': 'msci/TESTING/fp_output/2023-11-02_18:25:31/10273358736471385291/2','DE000STRA555-JA-2022-EQ-E-00_extracted.pdf': 'msci/TESTING/fp_output/2023-11-02_18:25:31/10273358736471385291/3'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ba28f7-c87c-447e-8bd6-ae91c303ed65",
   "metadata": {},
   "source": [
    "`poll_hitl_operations` is a waiting function to check & resolve HITL triggered documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80982dee-0f66-43a2-a0ad-e5c2222771a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "poll_hitl_operations(project_num, location, cde_input_output_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49867d1-4451-43e8-b0c7-1665821d9eb6",
   "metadata": {},
   "source": [
    "`walk_the_ocr` function uses CDE and FP json output and parse it to get final output for both row headers & column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6810abf-b33f-4501-8f8a-d81aaca01d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_the_ocr(\n",
    "    project_id,\n",
    "    location,\n",
    "    cde_input_output_map,\n",
    "    gcs_output_bucket,\n",
    "    gcs_cde_hitl_output_prefix,\n",
    "    fp_input_output_map,\n",
    "    f\"{gcs_output_uri_prefix}/{flow}/{datetime_suffix}\",\n",
    "    offset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589ae870-f711-4736-ab1e-0b08fa189e74",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Output Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f22c7-e68a-4f34-8ce9-e7b4822d31f2",
   "metadata": {},
   "source": [
    "One of the table Sample from pdf file\n",
    "![](./Images/ocr_walk_input_sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac67de3-7306-4e41-b046-7021ae086d79",
   "metadata": {},
   "source": [
    "output sample for one-table which stored as csv files in GCS bucket\n",
    "![](./Images/ocr_walk_output_sample.png)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
