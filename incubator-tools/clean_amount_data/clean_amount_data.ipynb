{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29399724",
   "metadata": {},
   "source": [
    "# Entity Amount Cleanup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e4a6def",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6029ebef",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the **DocAI Incubator Team**. No guarantees of performance are implied."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18bbfedd",
   "metadata": {},
   "source": [
    "# Objective\n",
    "This document is to clean amount entity, which cleans the mention_text and converts it to business readable text data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a77d9e9",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "* Vertex AI Notebook\n",
    "* GCS Folder Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cad788f5",
   "metadata": {},
   "source": [
    "# Step-by-Step Procedure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e511f7a",
   "metadata": {},
   "source": [
    "## 1. Import Modules/Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80ecc19e-d0fb-4435-9284-44318db1937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-storage\n",
    "!pip install google-cloud-documentai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10e90cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to download utilities module\n",
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d4b7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from google.cloud.documentai_toolbox import gcs_utilities\n",
    "\n",
    "from utilities import (\n",
    "    documentai_json_proto_downloader,\n",
    "    file_names,\n",
    "    store_document_as_json,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aa4caea",
   "metadata": {},
   "source": [
    "## 2. Input Details"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "717bb8cc",
   "metadata": {},
   "source": [
    "* **INPUT_GCS_PATH** : It is input GCS folder path which contains DocumentAI processor JSON results\n",
    "* **OUTPUT_GCS_PATH** : It is a GCS folder path to store post-processing results\n",
    "* **AMOUNT_ENTITY_TYPE** : The amount type of an entity to consider for cleaning and converting it to business readable text data\n",
    "* **IS_CURRENCY_EXIST**: If currency symbol exists at beginning of amount entity text provide `True` otherwise `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfdd838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_GCS_PATH = \"gs://bucket/path_to/jsons\"\n",
    "OUTPUT_GCS_PATH = \"gs://bucket/path_to/output\"\n",
    "# It is an entity type which contains Digit Data(Amount); edit as per entity name in your schema\n",
    "AMOUNT_ENTITY_TYPE = \"annual_income\"\n",
    "IS_CURRENCY_EXIST = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3347e5d1",
   "metadata": {},
   "source": [
    "## 3. Run Below Code-Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94606760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_annual_amount(doc: documentai.Document) -> documentai.Document:\n",
    "    \"\"\"It will removes unexpected commas, periods and spaces\n",
    "\n",
    "    Args:\n",
    "        doc (documentai.Document): DocumetAI Document proto Object\n",
    "\n",
    "    Returns:\n",
    "        documentai.Document: Updated DocumetAI Document proto Object for given `AMOUNT_ENTITY_TYPE`\n",
    "    \"\"\"\n",
    "\n",
    "    for entity in doc.entities:\n",
    "        if entity.type_ == AMOUNT_ENTITY_TYPE:\n",
    "            mention_text = entity.mention_text\n",
    "            print(\"\\t\", mention_text, end=\" ---> \")\n",
    "            currency_symbol = mention_text[0] if IS_CURRENCY_EXIST else \"\"\n",
    "            digits = re.findall(\"\\d.*?\", mention_text)\n",
    "            mention_text = \"\".join(digits)\n",
    "            if mention_text.endswith(\"00\") and len(digits) > 3:\n",
    "                mention_text = mention_text[::-1]\n",
    "                mention_text = mention_text.replace(\"00\", \"00.\", 1)[::-1]\n",
    "            mention_text = float(mention_text)\n",
    "            mention_text = f\"{mention_text:,.2f}\"\n",
    "            mention_text = currency_symbol + mention_text\n",
    "            print(mention_text)\n",
    "            entity.mention_text = mention_text\n",
    "    return doc\n",
    "\n",
    "\n",
    "input_bucket, input_files_dir = gcs_utilities.split_gcs_uri(INPUT_GCS_PATH)\n",
    "output_bucket, output_files_dir = gcs_utilities.split_gcs_uri(OUTPUT_GCS_PATH)\n",
    "_, files_dict = file_names(INPUT_GCS_PATH)\n",
    "for fn, fp in files_dict.items():\n",
    "    print(f\"Process started for {fn}\")\n",
    "    # print(f\"\\tReading data from gs://{input_bucket}/{fp}\")\n",
    "    doc = documentai_json_proto_downloader(input_bucket, fp)\n",
    "    doc = clean_annual_amount(doc)\n",
    "    str_data = documentai.Document.to_json(\n",
    "        doc, use_integers_for_enums=False, including_default_value_fields=False\n",
    "    )\n",
    "    target_path = f\"{output_files_dir.rstrip('/')}/{fn}\" if output_files_dir else fn\n",
    "    store_document_as_json(str_data, output_bucket, target_path)\n",
    "    # print(f\"\\tStoring JSON file to gs://{output_bucket}/{target_path}\")\n",
    "print(\"Process Completed for all files\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9eda18a",
   "metadata": {},
   "source": [
    "# 4. Output Details\n",
    "\n",
    "Refer below images for preprocessed and postprocessed results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7347f175",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>Pre-processed data</b>\n",
    "        </td>\n",
    "        <td>\n",
    "            <b>Post-processed data</b>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src='./images/annual_income_sample1_pre.png' width=400 height=600></img>\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src='./images/annual_income_sample1_post.png' width=400 height=600></img>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src='./images/annual_income_sample2_pre.png' width=400 height=600></img>\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src='./images/annual_income_sample2_post.png' width=400 height=600></img>\n",
    "        </td>\n",
    "    </tr>\n",
    "    </table>\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a81e368",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
