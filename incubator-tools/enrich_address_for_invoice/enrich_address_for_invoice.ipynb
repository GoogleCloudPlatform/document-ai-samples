{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b561af-dfd4-43b5-9baa-36ba937ff124",
   "metadata": {},
   "source": [
    "# Enrich Address for Invoice and Expense Documents\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb81020b-6cf8-486e-98d7-def30ce0490a",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455354e7-a77e-44ca-b44e-0425d8b59a3d",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the **DocAI Incubator Team**. No guarantees of performance are implied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9962c16-5cc6-4642-93d5-11d11b6b8de1",
   "metadata": {},
   "source": [
    "# Objective\n",
    "The tool facilitates a more detailed and accurate address parsing process. Detected addresses are broken down into their constituent parts, such as city, country, and ZIP code. The address data is enriched with additional relevant information, enhancing its overall usability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb319168-3b6d-40e5-8681-fb47ad709556",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "* Python : Jupyter notebook (Vertex AI).\n",
    "\n",
    "NOTE : \n",
    " * The version of Python currently running in the Jupyter notebook should be greater than 3.8\n",
    "  * The normalizedValue attribute will be accessible exclusively in JSON file and is not visible in the processor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52acc46e-5e4c-4daa-ac9e-7031283f10a0",
   "metadata": {},
   "source": [
    "# Step-by-Step Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c1532-21cb-4950-8446-7cabc0394332",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8a5b9-f90e-4575-87ff-95810f84ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f3332-6473-457c-922a-d6eb26b395c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to download utilities module\n",
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ad36024-52db-4628-9a87-a1fcbdfdc66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from google.cloud import storage\n",
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "from utilities import file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ea2a0-d3ea-4b2b-a2c1-0af6ec85f4d9",
   "metadata": {},
   "source": [
    "## 2. Input Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c4c0b-3872-40dd-8a4e-17d5e05f01b7",
   "metadata": {},
   "source": [
    "* **PROJECT_ID** : It contains the project ID of the working project.\n",
    "* **LOCATION** : It contains the location.\n",
    "* **GCS_INPUT_PATH** : It contains the input jsons bucket path. \n",
    "* **GCS_OUTPUT_PATH** : It contains the output bucket path where the updated jsons after adding the attribute will be stored.\n",
    "* **ENTITY_NAME** : It contains the names of the entities which the user wants to split. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b83232-34e7-4ff1-abab-ab68235ad29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"projectID\" # Your Google Cloud project ID.\n",
    "LOCATION = \"us-central1\"\n",
    "# '/' should be provided at the end of the path.\n",
    "GCS_INPUT_PATH = 'gs://{input_bucket_name}/{subfolder_name}/'\n",
    "# '/' should be provided at the end of the path.\n",
    "GCS_OUTPUT_PATH = 'gs://{output_bucket_name}/{subfolder_name}/'\n",
    "# Name of the entities in a list format.\n",
    "ENTITY_NAME = ['receiver_address','remit_to_address']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b658d0-d777-4bc6-8a94-2d7452b03db6",
   "metadata": {},
   "source": [
    "## 3. Run Below Code-Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b98d18d7-9a44-4d0b-b743-25bc26010ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def documentai_json_downloader(bucket_name:str, blob_name_with_prefix_path:str) -> dict:\n",
    "    \"\"\"\n",
    "    Download a JSON file from Google Cloud Storage and parse it into a Python dictionary.\n",
    "\n",
    "    This function downloads a JSON file from the specified Google Cloud Storage bucket\n",
    "    and parses it into a Python dictionary.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the Google Cloud Storage bucket.\n",
    "        blob_name_with_prefix_path (str): The full path of the JSON file within the bucket.\n",
    "\n",
    "    Returns:\n",
    "        dict: A Python dictionary containing the parsed JSON data.\n",
    "    \"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name_with_prefix_path)\n",
    "    json_data = json.loads(blob.download_as_text())\n",
    "    return json_data\n",
    "\n",
    "def store_document_as_json(json_data:dict, bucket_name:str, file_name:str) -> None:\n",
    "    \"\"\"\n",
    "    Store a JSON document in Google Cloud Storage.\n",
    "\n",
    "    Parameters:\n",
    "        json_data (dict): The JSON data to be stored.\n",
    "        bucket_name (str): The name of the Google Cloud Storage bucket \n",
    "                            where the JSON document will be stored.\n",
    "        file_name (str): The name of the file to be created in the bucket.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    json_string = json.dumps(json_data, indent=4)\n",
    "    storage_client = storage.Client()\n",
    "    process_result_bucket = storage_client.bucket(bucket_name)\n",
    "    document_blob = process_result_bucket.blob(str(Path(file_name)))\n",
    "    document_blob.upload_from_string(json_string, content_type=\"application/json\")\n",
    "\n",
    "def split_address_to_json(address:str, project_id:str, location:str) ->dict:\n",
    "    \"\"\"\n",
    "    Split an address into JSON format with specific keys using a text generation model.\n",
    "\n",
    "    This function splits an address into JSON format with keys for streetAddress,\n",
    "    city, state, zipcode, and country\n",
    "    using a text generation model.\n",
    "\n",
    "    Args:\n",
    "        address (str): The input address string to be split.\n",
    "        project_id (str): The project ID for the Vertex AI project.\n",
    "        location (str): The location of the Vertex AI project.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: A dictionary containing the JSON-formatted address if successful, else None.\n",
    "    \"\"\"\n",
    "    vertexai.init(project = project_id, location = location)\n",
    "    parameters = {\n",
    "        \"candidate_count\": 1,\n",
    "        \"max_output_tokens\": 1024,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.8,\n",
    "        \"top_k\": 40\n",
    "    }\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "    response = model.predict(\n",
    "        f\"\"\"Please split the address into Json format with keys\n",
    "        streetAddress, city, state, zipcode, country\n",
    "\n",
    "        input: {address}\n",
    "        output:\n",
    "        \"\"\",\n",
    "        **parameters\n",
    "    )\n",
    "\n",
    "    # Extracting JSON response from the model\n",
    "    json_response = response.text\n",
    "\n",
    "    try:\n",
    "        json_output = json.loads(json_response)\n",
    "        print(\"JSON OUTPUT\",json_output)\n",
    "        return json_output\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON response: {e}\")\n",
    "        print(\"Response from Model:\", response.text)\n",
    "        return None\n",
    "\n",
    "def process_json_files(\n",
    "    list_of_files:list,\n",
    "    input_storage_bucket_name:str,\n",
    "    output_storage_bucket_name:str,\n",
    "    output_bucket_path_prefix:str,\n",
    "    project_id:str,\n",
    "    location:str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Process JSON files containing address entities, split the addresses,\n",
    "    and store the updated JSON files in Google Cloud Storage.\n",
    "\n",
    "    This function iterates over a list of JSON files containing address entities,\n",
    "    splits the addresses into JSON format with keys for streetAddress,\n",
    "    city, state, zipcode, and country,\n",
    "    and stores the updated JSON files in a specified Google Cloud Storage bucket.\n",
    "\n",
    "    Args:\n",
    "        list_of_files (list): A list of JSON file paths to be processed.\n",
    "        input_storage_bucket_name (str): The name of the input Google Cloud Storage bucket.\n",
    "        output_storage_bucket_name (str): The name of the output Google Cloud Storage bucket.\n",
    "        output_bucket_path_prefix (str): The prefix path within the output bucket\n",
    "                                         where the processed files will be stored.\n",
    "        project_id (str): The project ID for the Vertex AI project.\n",
    "        location (str): The location of the Vertex AI project.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    for k,_ in enumerate(list_of_files):\n",
    "        print(\"***************\")\n",
    "        file_name = list_of_files[k].split('/')[-1]  # Extracting the file name from the path\n",
    "        print(f\"File Name {file_name}\")\n",
    "        json_data = documentai_json_downloader(input_storage_bucket_name, list_of_files[k])\n",
    "        for ent in json_data['entities']:\n",
    "            for name in ENTITY_NAME:\n",
    "                if name in ent['type']:\n",
    "                    print('---------------')\n",
    "                    mention_text = ent.get('mentionText', \"\")\n",
    "                    #normalized_value = ent.get('normalizedValue', \"\")\n",
    "                    type_ = ent.get('type', \"\")\n",
    "                    print(f\"Type: {type_}\")\n",
    "                    print(f\"Mention Text: {mention_text}\")\n",
    "\n",
    "                    # Try splitting the address\n",
    "                    output_json = split_address_to_json(\n",
    "                        mention_text.replace('\\n', ' ').strip(),\n",
    "                        project_id,\n",
    "                        location\n",
    "                    )\n",
    "                    # If address was successfully split, update the entity\n",
    "                    if output_json is not None:\n",
    "                        ent['normalizedValue'] = output_json\n",
    "                        ent['identified_format'] = \"Address split\"\n",
    "                    else:\n",
    "                        print(\"Address couldn't be split.\")\n",
    "\n",
    "                    print(f\"New Normalized Value: {ent['normalizedValue']}\")\n",
    "\n",
    "        # save to Google Cloud Storage\n",
    "        output_file_name = f\"{output_bucket_path_prefix}{file_name}\"\n",
    "        store_document_as_json(json_data, output_storage_bucket_name, output_file_name)\n",
    "\n",
    "    print(\"--------------------\")\n",
    "    print(\"All files processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f6e420-8b24-4773-b069-771869be758f",
   "metadata": {},
   "source": [
    "## Run the main functions after executing the above functions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb6aa350-f4af-440d-8185-dbcc030b73b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************\n",
      "File Name sv202313-0.json\n",
      "---------------\n",
      "Type: receiver_address\n",
      "Mention Text: 55 NE 5th Ave., Ste. 100\n",
      "Delray Beach, Florida 33483\n"
     ]
    },
    {
     "ename": "PermissionDenied",
     "evalue": "403 Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/data-program-377222/locations/us-central1/publishers/google/models/text-bison@001' (or it may not exist). [reason: \"IAM_PERMISSION_DENIED\"\ndomain: \"aiplatform.googleapis.com\"\nmetadata {\n  key: \"permission\"\n  value: \"aiplatform.endpoints.predict\"\n}\nmetadata {\n  key: \"resource\"\n  value: \"projects/data-program-377222/locations/us-central1/publishers/google/models/text-bison@001\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:65\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1176\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1170\u001b[0m (\n\u001b[1;32m   1171\u001b[0m     state,\n\u001b[1;32m   1172\u001b[0m     call,\n\u001b[1;32m   1173\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1174\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1175\u001b[0m )\n\u001b[0;32m-> 1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1005\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/data-program-377222/locations/us-central1/publishers/google/models/text-bison@001' (or it may not exist).\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.107.95:443 {created_time:\"2024-04-23T11:08:03.512603981+00:00\", grpc_status:7, grpc_message:\"Permission \\'aiplatform.endpoints.predict\\' denied on resource \\'//aiplatform.googleapis.com/projects/data-program-377222/locations/us-central1/publishers/google/models/text-bison@001\\' (or it may not exist).\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 34\u001b[0m\n\u001b[1;32m     25\u001b[0m     list_of_files \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(json_files) \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     26\u001b[0m     process_json_files(\n\u001b[1;32m     27\u001b[0m         list_of_files,\n\u001b[1;32m     28\u001b[0m         input_storage_bucket_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m         project_id,\n\u001b[1;32m     32\u001b[0m         location)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPROJECT_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOCATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGCS_INPUT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGCS_OUTPUT_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(project_id, location, input_path, output_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m json_files \u001b[38;5;241m=\u001b[39m file_names(input_path)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m     25\u001b[0m list_of_files \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(json_files) \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m---> 26\u001b[0m \u001b[43mprocess_json_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist_of_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_storage_bucket_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_storage_bucket_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_bucket_path_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 114\u001b[0m, in \u001b[0;36mprocess_json_files\u001b[0;34m(list_of_files, input_storage_bucket_name, output_storage_bucket_name, output_bucket_path_prefix, project_id, location)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMention Text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmention_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Try splitting the address\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m output_json \u001b[38;5;241m=\u001b[39m \u001b[43msplit_address_to_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmention_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# If address was successfully split, update the entity\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_json \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[12], line 46\u001b[0m, in \u001b[0;36msplit_address_to_json\u001b[0;34m(address, project_id, location)\u001b[0m\n\u001b[1;32m     38\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_output_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1024\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m40\u001b[39m\n\u001b[1;32m     44\u001b[0m }\n\u001b[1;32m     45\u001b[0m model \u001b[38;5;241m=\u001b[39m TextGenerationModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-bison@001\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mPlease split the address into Json format with keys\u001b[39;49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;43m    streetAddress, city, state, zipcode, country\u001b[39;49m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;43m    input: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43maddress\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;43m    output:\u001b[39;49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Extracting JSON response from the model\u001b[39;00m\n\u001b[1;32m     57\u001b[0m json_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/vertexai/language_models/_language_models.py:1332\u001b[0m, in \u001b[0;36m_TextGenerationModel.predict\u001b[0;34m(self, prompt, max_output_tokens, temperature, top_k, top_p, stop_sequences, candidate_count, grounding_source, logprobs, presence_penalty, frequency_penalty, logit_bias)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gets model response for a single prompt.\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \n\u001b[1;32m   1284\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;124;03m    A `MultiCandidateTextGenerationResponse` object that contains the text produced by the model.\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m prediction_request \u001b[38;5;241m=\u001b[39m _create_text_generation_prediction_request(\n\u001b[1;32m   1318\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m   1319\u001b[0m     max_output_tokens\u001b[38;5;241m=\u001b[39mmax_output_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     logit_bias\u001b[38;5;241m=\u001b[39mlogit_bias,\n\u001b[1;32m   1330\u001b[0m )\n\u001b[0;32m-> 1332\u001b[0m prediction_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_endpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprediction_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse_text_generation_model_multi_candidate_response(\n\u001b[1;32m   1338\u001b[0m     prediction_response\n\u001b[1;32m   1339\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/models.py:1579\u001b[0m, in \u001b[0;36mEndpoint.predict\u001b[0;34m(self, instances, parameters, timeout, use_raw_predict)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Prediction(\n\u001b[1;32m   1566\u001b[0m         predictions\u001b[38;5;241m=\u001b[39mjson_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1567\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mjson_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1576\u001b[0m         ),\n\u001b[1;32m   1577\u001b[0m     )\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1579\u001b[0m     prediction_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gca_resource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstances\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1585\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prediction_response\u001b[38;5;241m.\u001b[39m_pb\u001b[38;5;241m.\u001b[39mmetadata:\n\u001b[1;32m   1586\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m json_format\u001b[38;5;241m.\u001b[39mMessageToDict(prediction_response\u001b[38;5;241m.\u001b[39m_pb\u001b[38;5;241m.\u001b[39mmetadata)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:836\u001b[0m, in \u001b[0;36mPredictionServiceClient.predict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 836\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:67\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mPermissionDenied\u001b[0m: 403 Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/data-program-377222/locations/us-central1/publishers/google/models/text-bison@001' (or it may not exist). [reason: \"IAM_PERMISSION_DENIED\"\ndomain: \"aiplatform.googleapis.com\"\nmetadata {\n  key: \"permission\"\n  value: \"aiplatform.endpoints.predict\"\n}\nmetadata {\n  key: \"resource\"\n  value: \"projects/data-program-377222/locations/us-central1/publishers/google/models/text-bison@001\"\n}\n]"
     ]
    }
   ],
   "source": [
    "def main(project_id:str, location:str, input_path:str, output_path:str) ->None:\n",
    "    \"\"\"\n",
    "    Main function to process JSON files containing address entities and\n",
    "    store the updated JSON files in Google Cloud Storage.\n",
    "\n",
    "    This function serves as the main entry point for processing JSON files \n",
    "    containing address entities, splitting the addresses,\n",
    "    and storing the updated JSON files in a specified Google Cloud Storage bucket.\n",
    "\n",
    "    Args:\n",
    "        project_id (str): The project ID for the Vertex AI project.\n",
    "        location (str): The location of the Vertex AI project.\n",
    "        input_path (str): The path to the input directory containing JSON files.\n",
    "        output_path (str): The path to the output directory\n",
    "                           where the processed files will be stored.\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    input_storage_bucket_name = input_path.split(\"/\")[2]\n",
    "    #input_bucket_path_prefix = \"/\".join(input_path.split(\"/\")[3:])\n",
    "    output_storage_bucket_name = output_path.split(\"/\")[2]\n",
    "    output_bucket_path_prefix = \"/\".join(output_path.split(\"/\")[3:])\n",
    "\n",
    "    json_files = file_names(input_path)[1].values()\n",
    "    list_of_files = [i for i in list(json_files) if i.endswith(\".json\")]\n",
    "    process_json_files(\n",
    "        list_of_files,\n",
    "        input_storage_bucket_name,\n",
    "        output_storage_bucket_name,\n",
    "        output_bucket_path_prefix,\n",
    "        project_id,\n",
    "        location)\n",
    "\n",
    "main(PROJECT_ID, LOCATION, GCS_INPUT_PATH, GCS_OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e01349-3898-4160-adcd-715a9b83b5c7",
   "metadata": {},
   "source": [
    "## Output\n",
    "The new attribute 'normalizedValue' will be added to each address entity in the newly generated json file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a46bcb-4b12-4c6a-8e5f-b56469d8a4a5",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>Pre-processed data</b>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src='./images/input_image.png' width=600 height=600></img>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1847ab37-c050-4fa4-bd7c-ac3c826e9622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5c823-b08d-4a9b-a5b2-0235b3067f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
