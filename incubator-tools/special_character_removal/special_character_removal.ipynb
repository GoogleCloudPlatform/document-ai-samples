{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49bf864f-c8d8-47c9-af54-b253f41bca88",
   "metadata": {},
   "source": [
    "# DocAI Special Character Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2388af64-6727-4876-b3ef-296cd321c302",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84b2797-4849-48ec-b222-09c150dcc4e0",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the DocAI Incubator Team. No guarantees of performance are implied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79756a4c-45b1-4507-9c8e-7b7c9e504170",
   "metadata": {},
   "source": [
    "## Purpose and Description\n",
    "\n",
    "This documentation outlines the procedure for handling special characters within the CDE JSON samples. It involves replacing the original mention text value with its corresponding post-processed value using the provided code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c3b23-a58e-4f9f-ad92-d3e05ba1a619",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Access to vertex AI Notebook or Google Colab\n",
    "2. Python\n",
    "3. Access to the google storage bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac4060-3e3c-43fc-a1ee-9feb9544373c",
   "metadata": {},
   "source": [
    "## Step by Step procedure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c96f566-cd19-444a-9b68-95d4d2d125ed",
   "metadata": {},
   "source": [
    "### 1. Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e13449-1ca7-4f1c-8a73-1cdbe4b74db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install Pillow\n",
    "%pip install google-cloud-storage\n",
    "%pip install google-cloud-documentai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b148e-2fc1-41ea-94e1-7e0681aa4c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79501f4-7df9-4ff3-9849-c0922718d939",
   "metadata": {},
   "source": [
    "### 2. Import the required libraries/Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f907df-4fe2-4ae8-9d1d-33cf77f764fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from google.cloud import storage\n",
    "from PIL import Image\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from pathlib import Path\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "from utilities import file_names,documentai_json_proto_downloader,store_document_as_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0057355b-8edb-4394-aed9-6cae90975184",
   "metadata": {},
   "source": [
    "### 3. Input Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7883f7-2912-4c8a-ab0a-31ad66b4e9cf",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>input_path : </b>It is input GCS folder path which contains DocumentAI processor JSON results</li>\n",
    "    <li><b>output_path : </b> It is a GCS folder path to store post-processing results</li>\n",
    "    <li><b>project_id : </b> It is the project id of the current project.</li>\n",
    "    <li><b>location : </b> It is the location of the project in the processor.</li>\n",
    "    <li><b>processor_id : </b> It is the cde processor id. </li>\n",
    "    <li><b>entity_name : </b> The name of an entity to consider for cleaning and converting it with post processed value.</li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b0c0d7-31b7-4657-97f7-e6f21d5906f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'gs://bucket_name/path/to/jsons/' \n",
    "output_path = 'gs://bucket_name/path/to/output/' \n",
    "project_id = \"project-id\" \n",
    "location = \"location\" \n",
    "processor_id = \"processor-id\" \n",
    "entity_name = \"Amount_in_number\" # It is the entity name which need to be converted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4d367c-4ef3-46ae-ba0a-43bd2d9c7f6b",
   "metadata": {},
   "source": [
    "### 4.Execute the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39691d-db63-4f1f-9764-67d866933da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_storage_bucket_name = input_path.split('/')[2]\n",
    "input_bucket_path_prefix = '/'.join(input_path.split('/')[3:])\n",
    "output_storage_bucket_name=output_path.split('/')[2]   \n",
    "output_bucket_path_prefix = '/'.join(output_path.split('/')[3:])\n",
    "\n",
    "def remove_special_characters(json_proto_data: documentai.Document,  entity_name: str) -> documentai.Document:\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Removes special characters from a specified entity type (\"entity_name\") in a Documentai document.\n",
    "\n",
    "    This function processes the entity bounding box, extracts the image data, performs OCR with symbol confidence, \n",
    "    and removes special characters like '-' and '/' based on confidence thresholds while considering adjacent digits.\n",
    "\n",
    "    Args:\n",
    "      json_proto_data: The Documentai document object containing text and entities (type: documentai.Document).\n",
    "      entity_name: The name of the entity type to process (type: str).\n",
    "\n",
    "    Returns:\n",
    "      The modified Documentai document object with updated entity mentions after removing special characters (type: documentai.Document).\n",
    "    \"\"\"\n",
    "    for page_index, page in enumerate(json_proto_data.pages):\n",
    "        \n",
    "        if 'image' in page and 'content' in page.image:\n",
    "            # Decode the image content\n",
    "            image_data = page.image.content\n",
    "            #image_data = base64.b64decode(image_data_base64)\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "            for entity in json_proto_data.entities:\n",
    "                if entity.type == entity_name:\n",
    "                    bounding_box = entity.page_anchor.page_refs[0].bounding_poly.normalized_vertices\n",
    "\n",
    "                    # Convert normalized coordinates to pixel coordinates\n",
    "                    img_width, img_height = image.size\n",
    "                    left = bounding_box[0].x * img_width\n",
    "                    top = bounding_box[0].y * img_height\n",
    "                    right = bounding_box[2].x * img_width\n",
    "                    bottom = bounding_box[2].y * img_height\n",
    "\n",
    "                    # Crop the image\n",
    "                    cropped_image = image.crop((left, top, right, bottom))\n",
    "\n",
    "                    # Convert the PIL image to bytes directly\n",
    "                    cropped_image_bytes = BytesIO()\n",
    "                    cropped_image.save(cropped_image_bytes, format='PNG')\n",
    "                    image_content = cropped_image_bytes.getvalue()\n",
    "\n",
    "                    docai_client = documentai.DocumentProcessorServiceClient(client_options=ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\"))\n",
    "                    RESOURCE_NAME = docai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "                    raw_document = documentai.RawDocument(content=image_content, mime_type=\"image/png\")\n",
    "                    process_options = {\"ocr_config\": {\"enable_symbol\":True}}\n",
    "                    request = documentai.ProcessRequest(name=RESOURCE_NAME, raw_document=raw_document, process_options=process_options)\n",
    "\n",
    "                    result = docai_client.process_document(request=request)\n",
    "                    new_json_proto_data = result.document\n",
    "\n",
    "                    # Extracting text and confidence values\n",
    "                    # new_json_data = json.loads(documentai.Document.to_json(document_object))\n",
    "                    complete_text = new_json_proto_data.text\n",
    "                    symbols_confidence = []\n",
    "\n",
    "                    for page in new_json_proto_data.pages:\n",
    "                        for symbol in page.symbols:\n",
    "                            segments = symbol.layout.text_anchor.text_segments[0]\n",
    "                            start_index = int(segments.start_index)\n",
    "                            end_index = int(segments.end_index)\n",
    "                            symbol_text = complete_text[start_index:end_index]\n",
    "                            confidence = symbol.layout.confidence\n",
    "                            symbols_confidence.append((symbol_text, confidence))\n",
    "\n",
    "                    # Initially filter out '-' and '/' without affecting adjacent numeric values\n",
    "                    symbols_confidence_filtered = [(sym, conf) for sym, conf in symbols_confidence if sym not in ('-', '/')]\n",
    "\n",
    "                    # Check and remove the first symbol if its confidence is below 0.85\n",
    "                    if symbols_confidence_filtered and symbols_confidence_filtered[0][1] < 0.85:\n",
    "                        symbols_confidence_filtered.pop(0)\n",
    "\n",
    "                    # Check and remove the last two symbols if their confidences are below 0.85\n",
    "                    if len(symbols_confidence_filtered) > 2 and symbols_confidence_filtered[-1][1] < 0.85:\n",
    "                        symbols_confidence_filtered.pop(-1)\n",
    "                    if len(symbols_confidence_filtered) > 2 and symbols_confidence_filtered[-2][1] < 0.85:\n",
    "                        symbols_confidence_filtered.pop(-2)\n",
    "\n",
    "                    if len(symbols_confidence_filtered) > 2:\n",
    "                        for j in range(1,len(symbols_confidence_filtered)-2):\n",
    "                            if symbols_confidence_filtered[j][1] < 0.5:\n",
    "                                symbols_confidence_filtered.pop(j)\n",
    "\n",
    "                    # Join the remaining characters from the processed list\n",
    "                    post_processed_symbols = ''.join([sym for sym, conf in symbols_confidence_filtered])\n",
    "                    entity.mention_text = post_processed_symbols\n",
    "            return json_proto_data\n",
    "                \n",
    "                \n",
    "                \n",
    "list_of_files = [i for i in  list(file_names(input_path)[1].values()) if i.endswith(\".json\")]\n",
    " \n",
    "for i in range(0,len(list_of_files)):\n",
    "    file_name = list_of_files[i]\n",
    "    #json_data=json.loads(source_bucket.blob(list_of_files[i]).download_as_string().decode('utf-8'))\n",
    "    json_proto_data = documentai_json_proto_downloader(input_storage_bucket_name, file_name)\n",
    "    print(\"Processing>>>>>>>\",file_name)\n",
    "    document_proto = remove_special_characters(json_proto_data,entity_name)\n",
    "    output_path_within_bucket = output_bucket_path_prefix + file_name.split('/')[1]\n",
    "    store_document_as_json(documentai.Document.to_json(document_proto), output_storage_bucket_name, output_path_within_bucket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c3018b-729f-40a2-ba13-3dd994987862",
   "metadata": {},
   "source": [
    "### 5.Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e124a-0fbe-45f4-8bb0-18be734d916e",
   "metadata": {},
   "source": [
    "\n",
    "The post processed json field can be found in the storage path provided by the user during the script execution that is output_bucket_path. <br><hr>\n",
    "<b>Comparison Between Input and Output File</b><br><br>\n",
    "<i><h4>Post processing results<h4><i><br>\n",
    "Upon code execution, the JSONs with the newly replaced values will be stored in the designated output Google Cloud Storage (GCS) bucket. This table summarizes the key differences between the input and output JSON files for the 'Amount_in_number' entity<br>\n",
    "    \n",
    "<table>\n",
    "    <tr>\n",
    "        <td><h3><b>Input Json </b></h3></td>\n",
    "        <td><h3><b>Output Json</b></h3></td>\n",
    "    </tr>\n",
    "<tr>\n",
    "<td><img src=\"./images/image_input_json.png\"></td>\n",
    "<td><img src=\"./images/image_output_json.png\"></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a3113-dfdb-4ec8-b119-2725da4c8b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
