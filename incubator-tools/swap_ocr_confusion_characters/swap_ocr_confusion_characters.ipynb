{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66aedf38-a792-46ff-9a1a-110b49ecc501",
   "metadata": {},
   "source": [
    "# Swap OCR Confusion Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d5b4c9-2440-43e5-ba73-0fae68988920",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533ec78-11f1-4aca-9332-43517bf37545",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the **DocAI Incubator Team**. No guarantees of performance are implied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3ccb65-96bc-493d-b92c-41b11cac3daa",
   "metadata": {},
   "source": [
    "# Objective\n",
    "This is a post processing tool to modify ocr-text, all characters/symbols are filtered based on provided confidence threshold(i.e, confidence_threshold) and then all these characters/symbols are replaced based on provided mapping dictionary(i.e, swapper) in ocr-text\n",
    " to normalize year in date related entities from 19xx to 20xx. Document AI processors will give a normalized_value attribute for date entities in Document Object and sometimes this normalized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d94cd4-355c-40a9-a5a4-2e8551e70f35",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "* Vertex AI Notebook\n",
    "* GCS Folder Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb954e7-a064-48aa-aaaa-de37818e4757",
   "metadata": {},
   "source": [
    "# Step-by-Step Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba1003-58d0-46bb-8232-63b796ec4bf2",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53066c4-af1c-4cf5-8dd2-fcb21c2810f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf0dd2f-2db4-4225-9a9e-9820b6e2bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from google.cloud import storage\n",
    "from typing import Tuple, List, Dict\n",
    "from utilities import (\n",
    "    file_names,\n",
    "    documentai_json_proto_downloader,\n",
    "    store_document_as_json,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3187de-60e3-405b-982d-65bf1f28ff74",
   "metadata": {},
   "source": [
    "## 2. Input Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226740e0-22ca-444b-8ae1-bc25581877e0",
   "metadata": {},
   "source": [
    "* **GCS_INPUT_PATH** : GCS folder path containing DocAI OCR Processor results in JSON format with Symbols data in it. \n",
    "* **GCS_OUTPUT_PATH** : GCS folder path to store post-processed results\n",
    "* **CONFIDENCE_THRESHOLD** : Based on this value, all swapping process takes place. It range is (0, 1).\n",
    "* **SWAPPER** : It is a dictionary, containing mapper configurations, {‘old_char’: ‘new_char’,...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc3b6d-7d8f-4998-b567-a923b97a86a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_INPUT_FOLDER = \"gs://{bucket-name}/{sub-folders-path}/\"\n",
    "GCS_OUTPUT_FOLDER = \"gs://{bucket-name}/{sub-folders-path}\"\n",
    "CONFIDENCE_THRESHOLD = 0.65\n",
    "SWAPPER = {\")\": \"J\", \"0\": \"Q\", \"5\": \"S\", \"1\": \"I\", \"2\": \"Z\", \"8\": \"B\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533a49a-ba10-47fa-a3f8-fe788eadc6e3",
   "metadata": {},
   "source": [
    "## 3. Run Below Code-Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16732718-d5f0-4cee-a4a6-634fe6926f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_confusion_chars(doc, confidence_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Swap characters in the document text with characters from the swapper mapping\n",
    "    based on a confidence threshold.\n",
    "\n",
    "    Parameters:\n",
    "    doc (object): The document object containing text and page symbols.\n",
    "    swapper (dict): A dictionary mapping characters to their replacement characters.\n",
    "    confidence_threshold (float): The confidence threshold below which characters will be swapped.\n",
    "\n",
    "    Returns:\n",
    "    object: The modified document object with swapped characters.\n",
    "    \"\"\"\n",
    "    text = doc.text\n",
    "    for page in doc.pages:\n",
    "        for _, symbol in enumerate(page.symbols):\n",
    "            conf = symbol.layout.confidence\n",
    "            if conf <= confidence_threshold:\n",
    "                text_segment = symbol.layout.text_anchor.text_segments[0]\n",
    "                start_ind, end_i = text_segment.start_index, text_segment.end_index\n",
    "                char = text[start_ind:end_i]\n",
    "                if char in SWAPPER:\n",
    "                    # Modifying docai text inplace\n",
    "                    text = text[:start_ind] + SWAPPER[char] + text[end_i:]\n",
    "                    doc.text = text\n",
    "    return doc\n",
    "\n",
    "\n",
    "splits = GCS_INPUT_FOLDER.strip(\"/\").split(\"/\")\n",
    "input_bucket, input_folder = splits[2], \"/\".join(splits[3:])\n",
    "output_bucket, output_folder = splits[2], \"/\".join(splits[3:])\n",
    "_, files_dict = file_names(GCS_INPUT_FOLDER)\n",
    "\n",
    "print(\n",
    "    \"Swapping process started based on provided confidence threshold and swapper_dict\"\n",
    ")\n",
    "for fn, fp in files_dict.items():\n",
    "    print(f\"Processing File: {fn} ...\")\n",
    "    doc_1 = documentai_json_proto_downloader(input_bucket, fp)\n",
    "    doc_2 = swap_confusion_chars(doc_1, CONFIDENCE_THRESHOLD)\n",
    "    json_str = documentai.Document.to_json(doc_2, including_default_value_fields=False)\n",
    "    out_fp = f\"{output_folder}/{fn}\"\n",
    "    print(f\"\\t Post-processed file storing at gs://{output_bucket}/{out_fp}\")\n",
    "    store_document_as_json(json_str, output_bucket, out_fp)\n",
    "print(\"Process Completed!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab282e87-cb9e-425f-8540-686bfb636902",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688da22-1fbf-464b-98f2-e82767ffa613",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>Pre-processed data</b>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src='./Images/input_image.png' width=600 height=600 alt='input_image'></img>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
