{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6589fc93-39d1-4d10-be1f-e7eb33fe4087",
   "metadata": {},
   "source": [
    "# Currency Normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bf22bf7-4a47-4f3a-9eef-6f19348a5250",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "361f188e-fe11-4a49-b7c8-080e0e69ce7a",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the DocAI Incubator Team. No guarantees of performance are implied. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1036937a-0221-48eb-862e-3fa0b8e646a8",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This document guides you to use the currency normalization tool which uses parsed jsons and excel file (which has parsed currency prediction and desired currency name) to normalize the currency entity to desired value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "115a4e82-5e83-468a-b0e5-097ca14f15d5",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* Vertex AI Notebook Or Colab (If using Colab, use authentication)\n",
    "* Storage Bucket for storing input and output json files\n",
    "* Permission For Google Storage and Vertex AI Notebook.\n",
    "* Excel file which contains mapping information\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe81de40-5c62-4c0b-adea-937f957b1a6e",
   "metadata": {},
   "source": [
    "## Step by Step procedure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142123d3-37b1-4aa8-841c-40c3bd52d70c",
   "metadata": {},
   "source": [
    "### 1. Importing Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba732192-48c6-411f-b772-5b2c7708a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tqdm\n",
    "%pip install pandas\n",
    "%pip install google-cloud-storage\n",
    "%pip install google-cloud-documentai\n",
    "%pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9338b4be-96a5-4c11-9e59-a4174c518ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to download utilities module\n",
    "# !wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b3ca3-e486-4614-81c2-da8e1f695666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from fuzzywuzzy import fuzz\n",
    "from tqdm import tqdm\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from typing import Dict, List\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import utilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd7c8c4c-68b8-413c-b4bc-c66f044d3b7a",
   "metadata": {},
   "source": [
    "### 2. Input and Output Paths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da0d4909-e00c-4704-a43b-6534f7403872",
   "metadata": {},
   "source": [
    "* **gcs_input_path** : GCS Input Path. It should contain DocAI processed output json files. \n",
    "* **gcs_output_path** : GCS Output Path. The post-processed json files stored in this path. \n",
    "* **project_id** : It should contains the project id of your current project.\n",
    "* **column_key** : It should contain the name of the column which should be considered as Key to convert(already existing currency format)\n",
    "* **column_value** : It should contain name of column which should be considered as Value to convert(desired format to Convert)\n",
    "* **updated_entity** : This should contain name of the entity to be converted.\n",
    "* **excel_path** : Screenshot from sample file: \n",
    "\n",
    "<img src=\"./Images/currency_issue.png\" width=800 height=400></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23e3d8-152c-418e-ba02-8e7f3afe248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and Output Bucket path\n",
    "gcs_input_path = \"gs://XXXXXXXXXXXX/\"  # Parsed json files path , end '/' is mandatory\n",
    "gcs_output_path = \"gs://XXXXXXXXXX/\"  # output path\n",
    "project_id = \"XXXXXXXXX\"  # project ID\n",
    "excel_path = \"Currency Issue.xlsx\"  # Excel Path\n",
    "column_key = \"Currency in Invoice\"  # name of column which should be considered as Key to convert(already existing currency format)\n",
    "column_value = \"Expected Currency Code\"  # name of column which should be considered as Value to convert(desired format To Convert )\n",
    "update_entity = [\"currency\"]  # Entity Names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "737d1c70-fef5-49e3-a266-695bf8076a54",
   "metadata": {},
   "source": [
    "### 3. Run the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22bfdd-abdc-4d1c-8f7c-86164e7c4103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping_dict(\n",
    "    excel_path: str, column_key: str, column_value: str\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"This Function gets the details from the excel and  returns a mapping dictionary\n",
    "\n",
    "    Args:\n",
    "      excel_path (str) : It contains the name of the excel sheet.\n",
    "      column_key (str) : It contains name of the already existing currency format.\n",
    "      column_value (str) : It contains the name of the desired format To Convert.\n",
    "\n",
    "    Returns:\n",
    "      A dictionary having currencies as key-value pair.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_excel(excel_path)\n",
    "    mapping_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        key = row[column_key]\n",
    "        value = row[column_value]\n",
    "        mapping_dict[key] = value\n",
    "\n",
    "    return mapping_dict\n",
    "\n",
    "\n",
    "def mapping_entities_dict(json_dict, update_entity, mapping_dict):\n",
    "    \"\"\"\n",
    "    This Function used Mapping dictionary and update entity list where the normalized value and mention text of the entities have to be changed\n",
    "\n",
    "    Args:\n",
    "      json_dict (object) : It contains the document object having all the document data.\n",
    "      update_entity (list) : It contains the list of names to be converted from one form to other.\n",
    "      mapping_dict (Dict) : It contains currencies as keys and values.\n",
    "\n",
    "    Returns:\n",
    "        object : updated json after updating the mentiontext and normalized value from mapping dict\n",
    "    \"\"\"\n",
    "\n",
    "    def calculate_similarity_ratio(\n",
    "        mapping_dict: Dict[str, str], mention_text: str, match_ratio: float\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "         It keeps track of the key with the highest fuzzy ratio that exceeds the specified match ratio. The function returns the key with the highest fuzzy ratio.\n",
    "\n",
    "        Args:\n",
    "            mapping_dict (dict): A dictionary where keys represent potential matches for the mention text.\n",
    "            mention_text (str): The text for which similarity ratios are calculated against the keys in the mapping dictionary.\n",
    "            match_ratio (float): The threshold ratio that a fuzzy match must exceed to be considered a valid match.\n",
    "\n",
    "        Returns:\n",
    "            str: The key from the mapping dictionary that has the highest fuzzy ratio with the mention text and exceeds the specified match ratio.\n",
    "        \"\"\"\n",
    "\n",
    "        match_key1 = \"\"\n",
    "        match_fuzzy = 0\n",
    "        for i in mapping_dict.keys():\n",
    "            if fuzz.ratio(str(i), str(mention_text)) > match_fuzzy:\n",
    "                match_key1 = i\n",
    "                match_fuzzy = fuzz.ratio(str(i), str(mention_text))\n",
    "        return match_key1\n",
    "\n",
    "    for entity in json_dict.entities:\n",
    "        if entity.type_ in update_entity:\n",
    "            match_key = calculate_similarity_ratio(\n",
    "                mapping_dict, entity.mention_text, 0.95\n",
    "            )\n",
    "            if match_key != \"\":\n",
    "                entity.mention_text = mapping_dict[match_key]\n",
    "                if not entity.normalized_value:\n",
    "                    entity.normalized_value.text = mapping_dict[match_key]\n",
    "                else:\n",
    "                    entity.normalized_value = {\"text\": mapping_dict[match_key]}\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92fc24-a980-46fc-a62c-58be13b007ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_list, file_dict = utilities.file_names(gcs_input_path)\n",
    "mapping_dict = get_mapping_dict(excel_path, column_key, column_value)\n",
    "for filename, filepath in tqdm(file_dict.items(), desc=\"Progress\"):\n",
    "    input_bucket_name = gcs_input_path.split(\"/\")[2]\n",
    "    if \".json\" in filepath:\n",
    "        json_dict = utilities.documentai_json_proto_downloader(\n",
    "            input_bucket_name, filepath\n",
    "        )\n",
    "        json_dict_updated = mapping_entities_dict(\n",
    "            json_dict, update_entity, mapping_dict\n",
    "        )\n",
    "\n",
    "        output_bucket_name = gcs_output_path.split(\"/\")[2]\n",
    "        output_path_within_bucket = \"/\".join(gcs_output_path.split(\"/\")[3:]) + filename\n",
    "        utilities.store_document_as_json(\n",
    "            documentai.Document.to_json(json_dict_updated),\n",
    "            output_bucket_name,\n",
    "            output_path_within_bucket,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62aa873d-f9be-46dc-b188-23e0d4d95dd0",
   "metadata": {},
   "source": [
    "### 4.Output\n",
    "\n",
    "The post processed json field can be found in the storage path provided by you during the script execution that is output_bucket."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23790c47-8448-48ee-b594-3f9d6648111b",
   "metadata": {},
   "source": [
    "<img src=\"./Images/currency_output.png\" width=800 height=400></img>"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m104"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
