{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12ccafbd-d094-4604-9f85-975f709f7038",
   "metadata": {},
   "source": [
    "# Pre and Post HITL Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b84a9-28f8-4e8b-9dd4-8b8363e59282",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270ddad0-5d76-4dd2-a863-74c3eb4effba",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the DocAI Incubator Team. No guarantees of performance are implied.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f231a-bd30-4ee3-a617-c12bf2261d57",
   "metadata": {},
   "source": [
    "## Purpose of the script\n",
    "This tool uses Pre-HITL JSON files (Parsed from a processor) and Post HITL JSON files(Updated through HITL) from GCS bucket as input, compares the Json files and differences are shown in an Excel with bounding boxes added images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30079506-4bc3-462b-aecb-dd95a1f1958a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisite\n",
    " * Vertex AI Notebook\n",
    " * Pre HITL and Post HITL Json files (filename should be same) in GCS Folders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download utilities module for incubator-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download incubator-tools utilities module to present-working-directory\n",
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418be9ca-916f-41a1-9196-800401bddd9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step by Step procedure \n",
    "### 1. Setup the required inputs\n",
    "#### Execute the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb227a56-08d7-4feb-82fb-c52dadf6dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"<Project-ID>\"\n",
    "pre_HITL_output_URI = \"gs://<bucket-name>/<folder_pre>\"\n",
    "post_HITL_output_URI = \"gs://<bucket-name>/<folder_post>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d561b9d-d183-41f3-9d08-337a4e6c0bb8",
   "metadata": {},
   "source": [
    " * **project_id**: provide the project id \n",
    " * **Pre_HITL_Output_URI:** provide the gcs path of pre HITL jsons (processed jsons) \n",
    " * **Post_HITL_Output_URI:** provide the gcs path of post HITL jsons (Jsons processed through HITL) \n",
    "\n",
    "**NOTE:** The Name of Post-HITL Json will not be the same as the original file name by default. This has to be updated manually before using this tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae5bee-4d39-460b-a7ef-5071e4d140ca",
   "metadata": {},
   "source": [
    "**2. Output** \n",
    "\n",
    "The output of the tool will be in an Excel format showing the entities which are updated in HITL and unchanged as well with images of labeled docs (both pre and post HITL).\n",
    "\n",
    "The Excel sheet which is created will have a summary of all the file files in “Consolidated_Data” and comparison in a separate sheet for each file.\n",
    "\n",
    "Each Excel sheet created will have  a batch of 20 files in it.\n",
    "\n",
    "![](https://screenshot.googleplex.com/6nL7E3hrRSEi6ST.png)\n",
    "\n",
    "The Excel file will have all the details of Pre-HITL text, Post-HITL text and whether the entity is updated in HITL in the form YES and NO as shown below .\n",
    "\n",
    "![](https://screenshot.googleplex.com/8wqPTMyUY5ASKZA.png)\n",
    "\n",
    "There will be a list of documents for which either the required confidence threshold is met or no HITL output is created yet is updated as “NO POST HITL OUTPUT AVAILABLE” at the end of excel in consolidated sheets.\n",
    "\n",
    "![](https://screenshot.googleplex.com/8tpFZsVfFdTBoKA.png)\n",
    "\n",
    "\n",
    "Blue Bounding Box⇒ Entities in Pre-HITL Json\n",
    "Red Bounding Box⇒ Entities updated in HITL\n",
    "Green Bounding Box⇒ Entities deleted in HITL( Entities which are detected by parser are deleted in HITL)\n",
    "\n",
    "**Bounding box color coding in images**\n",
    "\n",
    "![](https://screenshot.googleplex.com/9aph7w2N2vywPFP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a8f42-9d73-40f1-a356-39de0853cf33",
   "metadata": {},
   "source": [
    "Pre Post Bounding Box Mismatch\n",
    "**Sample Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5352a2-cc8c-480e-8336-0e886b4cac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install below libraries for one time\n",
    "#!pip install configparser\n",
    "#!pip install google.cloud\n",
    "#!pip install ast\n",
    "#!pip install openpyxl\n",
    "\n",
    "# installing libraries\n",
    "import pandas as pd\n",
    "import operator\n",
    "import difflib\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from google.cloud import storage\n",
    "from google.cloud import documentai_v1beta3\n",
    "from PIL import Image\n",
    "from typing import (\n",
    "    Container,\n",
    "    Iterable,\n",
    "    Iterator,\n",
    "    List,\n",
    "    Mapping,\n",
    "    Optional,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    Union,\n",
    ")\n",
    "from PyPDF2 import PdfFileReader\n",
    "import configparser\n",
    "import ast\n",
    "import numpy\n",
    "import io\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import openpyxl\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "\n",
    "\n",
    "import utilities\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "def find_excel_name():\n",
    "    i = 1\n",
    "    excel_file_name = \"HITL_VISUAL\" + str(i) + \".xlsx\"\n",
    "    comapare_analysis = compare_merged.drop(\n",
    "        [\"pre_bbox\", \"post_bbox\", \"page1\", \"page2\"], axis=1\n",
    "    )\n",
    "    try:\n",
    "        workbook = openpyxl.load_workbook(excel_file_name)\n",
    "        num_sheets = len(workbook.sheetnames)\n",
    "        # print(num_sheets)\n",
    "        if num_sheets > 20:\n",
    "            excel_file = \"HITL_VISUAL\" + str(i + 1) + \".xlsx\"\n",
    "            comapare_analysis.to_excel(excel_file, sheet_name=\"Consolidated_Data\")\n",
    "        else:\n",
    "            excel_file = \"HITL_VISUAL\" + str(i) + \".xlsx\"\n",
    "    except FileNotFoundError:\n",
    "        excel_file = \"HITL_VISUAL\" + str(i) + \".xlsx\"\n",
    "        comapare_analysis.to_excel(excel_file, sheet_name=\"Consolidated_Data\")\n",
    "    return excel_file\n",
    "\n",
    "\n",
    "def get_visualization_excel(pre_HITL_output_URI, compare_merged, relation_dict):\n",
    "    # compare_merged.to_excel(\"HITL_VISUAL1.xlsx\",sheet_name='Consolidated_Data')\n",
    "    pre_HITL_bucket = pre_HITL_output_URI.split(\"/\")[2]\n",
    "    pre_HITL_output_files, pre_HITL_output_dict = utilities.file_names(\n",
    "        pre_HITL_output_URI\n",
    "    )\n",
    "    for file in pre_HITL_output_dict:\n",
    "        excel_file = find_excel_name()\n",
    "        df = compare_merged.drop([\"pre_bbox\", \"post_bbox\", \"page1\", \"page2\"], axis=1)\n",
    "        if file in relation_dict.keys():\n",
    "            df_file = df[df[\"File Name\"] == file]\n",
    "            with pd.ExcelWriter(excel_file, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "                df_file.to_excel(writer, sheet_name=str(file))\n",
    "\n",
    "            # path=\"gs://\"+pre_HITL_bucket+'/'+pre_HITL_output_dict[file]\n",
    "            GT_json = utilities.documentai_json_proto_downloader(\n",
    "                pre_HITL_bucket, pre_HITL_output_dict[file]\n",
    "            )\n",
    "            pdf_bytes, synthesized_images = utilities.create_pdf_bytes_from_json(\n",
    "                documentai.Document.to_dict(GT_json)\n",
    "            )\n",
    "            list_bbox_no = {}\n",
    "            list_bbox_yes_changed = {}\n",
    "            list_bbox_yes_old = {}\n",
    "            for row in compare_merged.values:\n",
    "                if row[0] == file:\n",
    "                    if row[8] == \"NO\":\n",
    "                        if type(row[4]) == list and row[4] != []:\n",
    "                            try:\n",
    "                                if row[6] in list_bbox_no.keys():\n",
    "                                    list_bbox_no[row[6]].append(row[4])\n",
    "                                else:\n",
    "                                    list_bbox_no[row[6]] = [row[4]]\n",
    "                                # print({row[6]:row[4]})\n",
    "                            except:\n",
    "                                pass\n",
    "                    elif row[8] == \"YES\":\n",
    "                        if type(row[5]) == list and row[5] != []:\n",
    "                            try:\n",
    "                                if row[7] in list_bbox_yes_changed.keys():\n",
    "                                    list_bbox_yes_changed[row[7]].append(row[5])\n",
    "                                else:\n",
    "                                    list_bbox_yes_changed[row[7]] = [row[5]]\n",
    "\n",
    "                            except:\n",
    "                                pass\n",
    "                        elif type(row[4]) == list and row[4] != []:\n",
    "                            if row[6] in list_bbox_yes_old.keys():\n",
    "                                list_bbox_yes_old[row[6]].append(row[4])\n",
    "                            else:\n",
    "                                list_bbox_yes_old[row[6]] = [row[4]]\n",
    "\n",
    "            open_cv_image = {}\n",
    "            for i in range(len(synthesized_images)):\n",
    "                open_cv_image[i] = numpy.array(synthesized_images[i].convert(\"RGB\"))\n",
    "            # print(list_bbox_yes_changed)\n",
    "            img_list = []\n",
    "            list_bbox_no = {str(key): value for key, value in list_bbox_no.items()}\n",
    "            list_bbox_yes_changed = {\n",
    "                str(key): value for key, value in list_bbox_yes_changed.items()\n",
    "            }\n",
    "            list_bbox_yes_old = {\n",
    "                str(key): value for key, value in list_bbox_yes_old.items()\n",
    "            }\n",
    "\n",
    "            for i in range(len(open_cv_image)):\n",
    "                size = open_cv_image[i].shape\n",
    "                try:\n",
    "                    for bbox in list_bbox_no[str(i)]:\n",
    "                        x1 = int(bbox[0] * size[1])\n",
    "                        x2 = int(bbox[2] * size[1])\n",
    "                        y1 = int(bbox[1] * size[0])\n",
    "                        y2 = int(bbox[3] * size[0])\n",
    "                        cv2.rectangle(\n",
    "                            open_cv_image[i], (x1, y1), (x2, y2), (0, 0, 255), 2\n",
    "                        )\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    for bbox in list_bbox_yes_changed[str(i)]:\n",
    "                        x1 = int(bbox[0] * size[1])\n",
    "                        x2 = int(bbox[2] * size[1])\n",
    "                        y1 = int(bbox[1] * size[0])\n",
    "                        y2 = int(bbox[3] * size[0])\n",
    "                        cv2.rectangle(\n",
    "                            open_cv_image[i], (x1, y1), (x2, y2), (255, 0, 0), 2\n",
    "                        )\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    for bbox in list_bbox_yes_old[str(i)]:\n",
    "                        x1 = int(bbox[0] * size[1])\n",
    "                        x2 = int(bbox[2] * size[1])\n",
    "                        y1 = int(bbox[1] * size[0])\n",
    "                        y2 = int(bbox[3] * size[0])\n",
    "                        cv2.rectangle(\n",
    "                            open_cv_image[i], (x1, y1), (x2, y2), (0, 255, 0), 2\n",
    "                        )\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                img1 = Image.fromarray(open_cv_image[i])\n",
    "                import openpyxl\n",
    "\n",
    "                workbook = openpyxl.load_workbook(excel_file)\n",
    "                worksheet = workbook[str(file)]\n",
    "\n",
    "                img1.save(f\"open_cv_image[i].png\", \"PNG\")\n",
    "                img = openpyxl.drawing.image.Image(f\"open_cv_image[i].png\")\n",
    "                img.anchor = \"K\" + str(1 + int(i) * 50)\n",
    "                worksheet.add_image(img)\n",
    "                img.width = 500\n",
    "                img.height = 700\n",
    "                workbook.save(excel_file)\n",
    "\n",
    "\n",
    "try:\n",
    "    # creating temperary buckets\n",
    "    import datetime\n",
    "\n",
    "    now = str(datetime.datetime.now())\n",
    "    now = re.sub(\"\\W+\", \"\", now)\n",
    "\n",
    "    print(\"Creating temporary buckets\")\n",
    "    pre_HITL_bucket_name_temp = \"pre_hitl_output\" + \"_\" + now\n",
    "    post_HITL_bucket_name_temp = \"post_hitl_output_temp\" + \"_\" + now\n",
    "    # bucket name and prefix\n",
    "    pre_HITL_bucket = pre_HITL_output_URI.split(\"/\")[2]\n",
    "    post_HITL_bucket = post_HITL_output_URI.split(\"/\")[2]\n",
    "    # getting all files and copying to temporary folder\n",
    "\n",
    "    try:\n",
    "        utilities.check_create_bucket(pre_HITL_bucket_name_temp)\n",
    "        utilities.check_create_bucket(post_HITL_bucket_name_temp)\n",
    "    except Exception as e:\n",
    "        print(\"unable to create bucket because of exception : \", e)\n",
    "\n",
    "    try:\n",
    "        pre_HITL_output_files, pre_HITL_output_dict = utilities.file_names(\n",
    "            pre_HITL_output_URI\n",
    "        )\n",
    "        post_HITL_output_files, post_HITL_output_dict = utilities.file_names(\n",
    "            post_HITL_output_URI\n",
    "        )\n",
    "        print(\"copying files to temporary bucket\")\n",
    "        for i in pre_HITL_output_files:\n",
    "            utilities.copy_blob(\n",
    "                pre_HITL_bucket, pre_HITL_output_dict[i], pre_HITL_bucket_name_temp, i\n",
    "            )\n",
    "        for i in post_HITL_output_files:\n",
    "            utilities.copy_blob(\n",
    "                post_HITL_bucket,\n",
    "                post_HITL_output_dict[i],\n",
    "                post_HITL_bucket_name_temp,\n",
    "                i,\n",
    "            )\n",
    "        pre_HITL_files_list = utilities.list_blobs(pre_HITL_bucket_name_temp)\n",
    "        post_HITL_files_list = utilities.list_blobs(post_HITL_bucket_name_temp)\n",
    "    except Exception as e:\n",
    "        print(\"unable to get list of files in buckets because : \", e)\n",
    "    # processing the files and saving the files in temporary gCP bucket\n",
    "    relation_dict, non_relation_dict = utilities.matching_files_two_buckets(\n",
    "        pre_HITL_bucket_name_temp, post_HITL_bucket_name_temp\n",
    "    )\n",
    "    compare_merged = pd.DataFrame()\n",
    "    accuracy_docs = []\n",
    "    print(\"comparing the PRE-HITL Jsons and POST-HITL jsons ....Wait for Summary \")\n",
    "    for i in relation_dict:\n",
    "        pre_HITL_json = utilities.documentai_json_proto_downloader(\n",
    "            pre_HITL_bucket_name_temp, i\n",
    "        )\n",
    "        post_HITL_json = utilities.documentai_json_proto_downloader(\n",
    "            post_HITL_bucket_name_temp, relation_dict[i]\n",
    "        )\n",
    "        compare_output = utilities.compare_pre_hitl_and_post_hitl_output(\n",
    "            pre_HITL_json, post_HITL_json\n",
    "        )[0]\n",
    "        column = [relation_dict[i]] * compare_output.shape[0]\n",
    "        compare_output.insert(loc=0, column=\"File Name\", value=column)\n",
    "\n",
    "        compare_output.insert(loc=8, column=\"hitl_update\", value=\" \")\n",
    "        for j in range(len(compare_output)):\n",
    "            if compare_output[\"Fuzzy Ratio\"][j] != 1.0:\n",
    "                if (\n",
    "                    compare_output[\"Pre_HITL_Output\"][j] == \"Entity not found.\"\n",
    "                    and compare_output[\"Post_HITL_Output\"][j] == \"Entity not found.\"\n",
    "                ):\n",
    "                    compare_output[\"hitl_update\"][j] = \"NO\"\n",
    "                else:\n",
    "                    compare_output[\"hitl_update\"][j] = \"YES\"\n",
    "            else:\n",
    "                compare_output[\"hitl_update\"][j] = \"NO\"\n",
    "        for k in range(len(compare_output)):\n",
    "            if compare_output[\"Fuzzy Ratio\"][k] != 1.0:\n",
    "                hitl_update = \"HITL UPDATED\"\n",
    "                break\n",
    "            else:\n",
    "                compare_output[\"hitl_update\"][k] = \"NO\"\n",
    "        frames = [compare_merged, compare_output]\n",
    "        compare_merged = pd.concat(frames)\n",
    "    try:\n",
    "        utilities.bucket_delete(pre_HITL_bucket_name_temp)\n",
    "        print(\"Deleting temperary buckets created\")\n",
    "        utilities.bucket_delete(post_HITL_bucket_name_temp)\n",
    "    except:\n",
    "        pass\n",
    "    compare_merged.drop([\"Match\", \"Fuzzy Ratio\"], axis=1, inplace=True)\n",
    "\n",
    "    def highlight(s):\n",
    "        if s.hitl_update == \"YES\":\n",
    "            return [\"background-color: yellow\"] * len(s)\n",
    "        else:\n",
    "            return [\"background-color: white\"] * len(s)\n",
    "\n",
    "    for k in non_relation_dict:\n",
    "        new_row = pd.Series(\n",
    "            [k, \"-\", \"-\", \"-\", \"\", \"\", \"\", \"\", non_relation_dict[k]],\n",
    "            index=compare_merged.columns,\n",
    "        )\n",
    "        compare_merged = compare_merged.append(new_row, ignore_index=True)\n",
    "        comapare_analysis1 = compare_merged.drop(\n",
    "            [\"pre_bbox\", \"post_bbox\", \"page1\", \"page2\"], axis=1\n",
    "        )\n",
    "    # comapare_analysis1.to_csv('compare_analysis.csv')\n",
    "    entity_change = compare_merged.loc[compare_merged[\"hitl_update\"] == \"YES\"]\n",
    "    compare_merged_style = compare_merged.style.apply(highlight, axis=1)\n",
    "    import traceback\n",
    "\n",
    "    try:\n",
    "        print(\"HITL Comparision excel is getting prepared\")\n",
    "        get_visualization_excel(pre_HITL_output_URI, compare_merged, relation_dict)\n",
    "        print(\"Completed creating the HITL Comparision Excel\")\n",
    "    except Exception as e:\n",
    "        print(\"Unable to create HITL comparison excel because of:\", e)\n",
    "        print(traceback.format_exc())\n",
    "except Exception as e:\n",
    "    try:\n",
    "        utilities.bucket_delete(pre_HITL_bucket_name_temp)\n",
    "        utilities.bucket_delete(post_HITL_bucket_name_temp)\n",
    "        print(\"unable to process the file   : \", e)\n",
    "    except:\n",
    "        print(\"unable to process the file   : \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95823f2c-a91b-4bb9-85aa-5d90f17fff05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m104"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
