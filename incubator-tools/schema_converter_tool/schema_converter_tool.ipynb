{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83ef9fd-f2a6-48b3-a381-7688ea128d8f",
   "metadata": {},
   "source": [
    "# Schema Converter Tool User’s Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ef8ffd-2e94-4529-bf84-755fe92a4c76",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ac1c2-cc63-4bbf-a270-b54765ea90b4",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the **DocAI Incubator Team**. No guarantees of performance are implied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2004da7-69ee-40d8-b295-ea2b73c8101e",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This tool converts the old type schema to New type schema using “Base processor schema” and old schema in json format as input. This new schema can be used for up-training the processor.\n",
    "\n",
    "**Old Processor Schema**: It is a JSON file which holds schema of specific processor_version of DocAI Processor which is different from current processor. Refer [public documentaion](https://cloud.google.com/python/docs/reference/documentai/latest/google.cloud.documentai_v1beta3.services.document_service.DocumentServiceClient#google_cloud_documentai_v1beta3_services_document_service_DocumentServiceClient_get_dataset_schema)\n",
    " to download base processor schema. This schema is refered as `old_schema` in this tool\n",
    " \n",
    "**Base Processor Schema**: It is a JSON file which holds schema of specific processor_version of DocAI Processor. Refer [public documentaion](https://cloud.google.com/python/docs/reference/documentai/latest/google.cloud.documentai_v1beta3.services.document_service.DocumentServiceClient#google_cloud_documentai_v1beta3_services_document_service_DocumentServiceClient_get_dataset_schema)\n",
    " to download base processor schema\n",
    " Before up-training you need to have latest/new schema\n",
    " \n",
    "**New Schema**: It is a JSON file `new_schema` which holds data about schema of old processor schema and base processor schema and entities whic are exist in both base processor schema & old schema(Intersection of these two) and entities old processor\n",
    "\n",
    "<img src=\"./images/new_schema_json.png\">  \n",
    "\n",
    "In below screenshot\n",
    "* **both**: entity exists in both old processor & base processor schema\n",
    "* **custom schema only**: entity from old processor schema\n",
    "<img src=\"./images/new_schema_dataframe.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98536f-ac9c-44de-bf1d-5314691fff43",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "\n",
    "1.Knowledge of Python, and IO Operations. \n",
    "\n",
    "2.Python : Jupyter notebook (Vertex) or Google Colab \n",
    "\n",
    "3.No permissions, reference or access to any Google project is needed.\n",
    "\n",
    "4.To get processor schema in json format refer documentation [get_dataset_schema](https://cloud.google.com/python/docs/reference/documentai/latest/google.cloud.documentai_v1beta3.services.document_service.DocumentServiceClient#google_cloud_documentai_v1beta3_services_document_service_DocumentServiceClient_get_dataset_schema)\n",
    "\n",
    "5.Current Up-training Schema in old format (json file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed4a86c-433c-4e16-ae01-30de753c406c",
   "metadata": {},
   "source": [
    "## Tool Installation Procedure\n",
    "\n",
    "The tool consists of some Python code. It can be loaded and run via: \n",
    "\n",
    "1.From Google Colab - make your own copy of this template,      \n",
    "                                      or       \n",
    "2.The code can also be copied from the appendix of this document and copied into a Google Colab or Vertex Notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc28b63d-9f0e-4773-8b74-e0de66e0bbde",
   "metadata": {},
   "source": [
    "## Tool Operation Procedure\n",
    "\n",
    "1. Copy the path of your old  schema json file and paste in the old_schema_path as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b58c9-90d4-4a02-9ae8-2df762cbb261",
   "metadata": {},
   "source": [
    "2. Copy the path of your Base processor schema json file and paste in the base _schema_json_path as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5cdbe9-11b8-4a39-b50b-0b804c97ed60",
   "metadata": {},
   "source": [
    "3. After updating the paths, run the entire code and the new schema json file should be created in your current working  directory, which can be used for uptraining the processor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab258ea-107a-4bf0-8c86-07e8d92c0bf1",
   "metadata": {},
   "source": [
    "# Run the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ebbf40-acc9-4b16-a111-af354c75e41c",
   "metadata": {},
   "source": [
    "### Installing Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be790463-37e4-4591-b43c-46df64f99e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0dbc36-b480-44be-b0ae-c73961f7e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_schema_path = \"old_schema.json\"\n",
    "with open(old_schema_path, \"r\") as f:\n",
    "    old_schema = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43fc3705-19a3-4ec8-bd58-e24bfd7d500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_SCHEMA_JSON_PATH = \"base_processor_version_info.json\"\n",
    "with open(BASE_SCHEMA_JSON_PATH, \"r\") as f:\n",
    "    base_processor_version = json.loads(f.read())[\n",
    "        \"documentSchema\"\n",
    "    ]  # If base processor version is available\n",
    "    # base_processor_version=json.loads(f.read()) # If directly schema is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "092efc79-9caf-4b4b-86cc-bb9bc5ec5322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'displayName': 'my schema name', 'description': 'my new schema for uptrain', 'metadata': {'prefixedNamingOnProperties': True}, 'entityTypes': [{'name': 'invoice_document_type', 'baseTypes': ['document'], 'properties': [{'name': 'line_item', 'valueType': 'line_item', 'occurrenceType': 'OPTIONAL_MULTIPLE'}, {'name': 'total_amount', 'valueType': 'money', 'occurrenceType': 'OPTIONAL_ONCE'}, {'name': 'purchase_order_date', 'valueType': 'datetime', 'occurrenceType': 'OPTIONAL_ONCE'}, {'name': 'purchase_order_id', 'valueType': 'string', 'occurrenceType': 'OPTIONAL_ONCE'}, {'name': 'ship_to_address', 'valueType': 'address', 'occurrenceType': 'OPTIONAL_ONCE'}, {'name': 'ship_to_name', 'valueType': 'string', 'occurrenceType': 'OPTIONAL_ONCE'}, {'name': 'delivery_date', 'valueType': 'datetime', 'occurrenceType': 'OPTIONAL_ONCE'}]}, {'name': 'line_item', 'baseTypes': ['object'], 'properties': [{'name': 'line_item/amount', 'valueType': 'money', 'occurrenceType': 'OPTIONAL_ONCE'}, {'name': 'line_item/description', 'valueType': 'string', 'occurrenceType': 'OPTIONAL_ONCE'}, {'name': 'line_item/quantity', 'valueType': 'number', 'occurrenceType': 'OPTIONAL_ONCE'}, {'name': 'line_item/unit_of_measure', 'valueType': 'string', 'occurrenceType': 'OPTIONAL_ONCE'}, {'name': 'line_item/unit_price', 'valueType': 'money', 'occurrenceType': 'OPTIONAL_ONCE'}, {'name': 'line_item/product_code', 'valueType': 'string', 'occurrenceType': 'OPTIONAL_ONCE'}, {'name': 'line_item/upc_code', 'valueType': 'string', 'occurrenceType': 'OPTIONAL_ONCE'}, {'name': 'line_item/customer_item_no', 'valueType': 'string', 'occurrenceType': 'OPTIONAL_ONCE'}]}]}\n"
     ]
    }
   ],
   "source": [
    "def schema_detect(s):\n",
    "    flag = False\n",
    "    # checking whether schema is old or new type and converting to pandas dataframe\n",
    "    df1 = pd.DataFrame()\n",
    "    df_new2 = None\n",
    "    for i in range(len(s[\"entityTypes\"])):\n",
    "        if \"properties\" in s[\"entityTypes\"][i].keys():\n",
    "            flag = True\n",
    "            break\n",
    "    if flag:\n",
    "        # print('New Type Schema')\n",
    "        for i in range(len(s[\"entityTypes\"])):\n",
    "            if \"properties\" in s[\"entityTypes\"][i].keys():\n",
    "                for j in range(len(s[\"entityTypes\"][i][\"properties\"])):\n",
    "                    s[\"entityTypes\"][i][\"properties\"][j] = {\n",
    "                        (\"\".join(e for e in k if e.isalnum())).lower(): v\n",
    "                        for k, v in s[\"entityTypes\"][i][\"properties\"][j].items()\n",
    "                    }\n",
    "                    # print(s['entityTypes'][i]['properties'])\n",
    "                for j in range(len(s[\"entityTypes\"][i][\"properties\"])):\n",
    "                    if df_new2 is not None:\n",
    "                        df1 = pd.concat([df1, df_new2])\n",
    "                        df_new2 = None\n",
    "                    else:\n",
    "                        df_new2 = pd.DataFrame(s[\"entityTypes\"][i][\"properties\"])\n",
    "        if \"propertymetadata\" in df1.columns:\n",
    "            df1.drop([\"propertymetadata\"], axis=1, inplace=True)\n",
    "        df1.rename(columns={\"name\": \"type_schema\"}, inplace=True)\n",
    "        df1.drop_duplicates(inplace=True, ignore_index=True)\n",
    "        # print(df1.head())\n",
    "    else:\n",
    "        for i in range(len(s[\"entityTypes\"])):\n",
    "            s[\"entityTypes\"][i] = {\n",
    "                (\"\".join(e for e in k if e.isalnum())).lower(): v\n",
    "                for k, v in s[\"entityTypes\"][i].items()\n",
    "            }\n",
    "        df1 = pd.DataFrame(s[\"entityTypes\"])\n",
    "        df1.rename(columns={\"type\": \"type_schema\"}, inplace=True)\n",
    "        print(\"      Old Type Schema\")\n",
    "    return df1\n",
    "\n",
    "\n",
    "def custom_style1(row):\n",
    "    if row.values[-1] == \"both\" and (\n",
    "        row.values[-2] != row.values[-4] or row.values[-3] != row.values[-5]\n",
    "    ):\n",
    "        color = \"lightpink\"\n",
    "    elif row.values[-1] != \"both\":\n",
    "        color = \"lightyellow\"\n",
    "    else:\n",
    "        color = \"lightgreen\"\n",
    "    return [\"color:black;background-color: %s\" % color] * len(row.values)\n",
    "\n",
    "\n",
    "base_schema_df1 = schema_detect(base_processor_version)\n",
    "base_schema_dict = base_schema_df1.set_index(\"type_schema\").T.to_dict()\n",
    "\n",
    "new_schema = dict()\n",
    "new_schema[\"displayName\"] = old_schema[\"displayName\"]\n",
    "new_schema[\"description\"] = old_schema[\"description\"]\n",
    "new_schema[\"metadata\"] = base_processor_version[\"metadata\"]\n",
    "new_schema[\"entityTypes\"] = [\n",
    "    {\n",
    "        \"name\": base_processor_version[\"entityTypes\"][0][\"name\"],\n",
    "        \"baseTypes\": base_processor_version[\"entityTypes\"][0][\"baseTypes\"],\n",
    "        \"properties\": list(),\n",
    "    }\n",
    "]\n",
    "entityTypes = [base_processor_version[\"entityTypes\"][0][\"name\"]]\n",
    "for i in old_schema[\"entityTypes\"]:\n",
    "    if \"/\" in i[\"type\"]:\n",
    "        if i[\"type\"].split(\"/\")[0] not in entityTypes:\n",
    "            temp = dict()\n",
    "            temp[\"name\"] = i[\"type\"].split(\"/\")[0]\n",
    "            temp[\"baseTypes\"] = [\"object\"]\n",
    "            temp[\"properties\"] = list()\n",
    "            new_schema[\"entityTypes\"].append(temp)\n",
    "            entityTypes.append(i[\"type\"].split(\"/\")[0])\n",
    "            temp2 = dict()\n",
    "            temp2[\"name\"] = i[\"type\"].split(\"/\")[0]\n",
    "            temp2[\"valueType\"] = i[\"type\"].split(\"/\")[0]\n",
    "            temp2[\"occurrenceType\"] = \"OPTIONAL_MULTIPLE\"\n",
    "            new_schema[\"entityTypes\"][0][\"properties\"].append(temp2)\n",
    "for i in new_schema[\"entityTypes\"]:\n",
    "    for j in old_schema[\"entityTypes\"]:\n",
    "        if (\n",
    "            \"/\" not in j[\"type\"]\n",
    "            and i[\"name\"] == base_processor_version[\"entityTypes\"][0][\"name\"]\n",
    "        ):\n",
    "            temp = {}\n",
    "            temp[\"name\"] = j[\"type\"]\n",
    "            if j[\"type\"] in base_schema_dict.keys():\n",
    "                temp[\"valueType\"] = base_schema_dict[j[\"type\"]][\"valuetype\"]\n",
    "                temp[\"occurrenceType\"] = base_schema_dict[j[\"type\"]][\"occurrencetype\"]\n",
    "            else:\n",
    "                temp[\"valueType\"] = j[\"baseType\"]\n",
    "                temp[\"occurrenceType\"] = j[\"occurrenceType\"]\n",
    "\n",
    "            i[\"properties\"].append(temp)\n",
    "        else:\n",
    "            if i[\"name\"] == j[\"type\"].split(\"/\")[0]:\n",
    "                temp = {}\n",
    "                temp[\"name\"] = j[\"type\"]\n",
    "                if j[\"type\"] in base_schema_dict.keys():\n",
    "                    temp[\"valueType\"] = base_schema_dict[j[\"type\"]][\"valuetype\"]\n",
    "                    temp[\"occurrenceType\"] = base_schema_dict[j[\"type\"]][\n",
    "                        \"occurrencetype\"\n",
    "                    ]\n",
    "                else:\n",
    "                    temp[\"valueType\"] = j[\"baseType\"]\n",
    "                    temp[\"occurrenceType\"] = \"OPTIONAL_ONCE\"\n",
    "                i[\"properties\"].append(temp)\n",
    "new_schema2 = copy.deepcopy(new_schema)\n",
    "my_schema_df2 = schema_detect(new_schema)\n",
    "# Merging both the data frame and getting differences\n",
    "compare = base_schema_df1.merge(\n",
    "    my_schema_df2,\n",
    "    on=\"type_schema\",\n",
    "    how=\"outer\",\n",
    "    suffixes=[\"_base\", \"_2\"],\n",
    "    indicator=True,\n",
    ")\n",
    "compare[\"_merge\"] = compare[\"_merge\"].replace(\n",
    "    \"right_only\", \"custom schema only \", regex=True\n",
    ")\n",
    "compare[\"_merge\"] = compare[\"_merge\"].replace(\n",
    "    \"left_only\", \"base schema only \", regex=True\n",
    ")\n",
    "compare.rename(columns={\"_merge\": \"entity_exists_in\"}, inplace=True)\n",
    "compare.style.apply(custom_style1, axis=1)\n",
    "new_schema_file_name = \"new_schema.json\"\n",
    "with open(new_schema_file_name, \"w\") as f:\n",
    "    f.write(json.dumps(new_schema2, ensure_ascii=False))\n",
    "print(new_schema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ee49ff-3a60-4f0b-bc7b-2e2c5630b3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
