{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83ef9fd-f2a6-48b3-a381-7688ea128d8f",
   "metadata": {},
   "source": [
    "# Schema Converter Tool User’s Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ef8ffd-2e94-4529-bf84-755fe92a4c76",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ac1c2-cc63-4bbf-a270-b54765ea90b4",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the **DocAI Incubator Team**. No guarantees of performance are implied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2004da7-69ee-40d8-b295-ea2b73c8101e",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This tool converts the old type schema to New type schema using “Base processor schema” and old schema in json format as input. This new schema can be used for up-training the processor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98536f-ac9c-44de-bf1d-5314691fff43",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "\n",
    "1.Knowledge of Python, and IO Operations. \n",
    "\n",
    "2.Python : Jupyter notebook (Vertex) or Google Colab \n",
    "\n",
    "3.No permissions, reference or access to any Google project is needed.\n",
    "\n",
    "4.Base Processor Schema in json format (To generate base processor schema follow instructions as per [go/incubation-get-base-processor-schema](https://docs.google.com/document/d/1wrN41GTr43CmO3WZVQONPkz2-9z39I_fjwoR4wDfvFc/edit?resourcekey=0-XQV-Fcral2Qy-7NhixJ4lw&tab=t.0#heading=h.a97nzegucz05)).\n",
    "\n",
    "5.Current Up-training Schema in old format (json file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed4a86c-433c-4e16-ae01-30de753c406c",
   "metadata": {},
   "source": [
    "## Tool Installation Procedure\n",
    "\n",
    "The tool consists of some Python code. It can be loaded and run via: \n",
    "\n",
    "1.From Google Colab - make your own copy of this template,      \n",
    "                                      or       \n",
    "2.The code can also be copied from the appendix of this document and copied into a Google Colab or Vertex Notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc28b63d-9f0e-4773-8b74-e0de66e0bbde",
   "metadata": {},
   "source": [
    "## Tool Operation Procedure\n",
    "\n",
    "1. **Copy the path of your old  schema json file and paste in the old_schema_path as shown below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b58c9-90d4-4a02-9ae8-2df762cbb261",
   "metadata": {},
   "source": [
    "2. **Copy the path of your Base processor schema json file and paste in the base _schema_json_path as shown below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5cdbe9-11b8-4a39-b50b-0b804c97ed60",
   "metadata": {},
   "source": [
    "3. **After updating the paths, run the entire code and the new schema json file should be created in your current working  directory, which can be used for uptraining the processor.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab258ea-107a-4bf0-8c86-07e8d92c0bf1",
   "metadata": {},
   "source": [
    "# Run the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ebbf40-acc9-4b16-a111-af354c75e41c",
   "metadata": {},
   "source": [
    "### Installing Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be790463-37e4-4591-b43c-46df64f99e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0dbc36-b480-44be-b0ae-c73961f7e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_schema_path = \"old_schema.json\"\n",
    "with open(old_schema_path, \"r\") as f:\n",
    "    old_schema = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc3705-19a3-4ec8-bd58-e24bfd7d500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_SCHEMA_JSON_PATH = \"base_processor_version_info.json\"\n",
    "with open(\"old_base_processor_version_info.json\", \"r\") as f:\n",
    "    base_processor_version = json.loads(f.read())[\n",
    "        \"documentSchema\"\n",
    "    ]  # If base processor version is available\n",
    "    # base_processor_version=json.loads(f.read()) # If directly schema is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092efc79-9caf-4b4b-86cc-bb9bc5ec5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schema_detect(s):\n",
    "    flag = False\n",
    "    # checking whether schema is old or new type and converting to pandas dataframe\n",
    "    df1 = pd.DataFrame()\n",
    "    df_new2 = None\n",
    "    for i in range(len(s[\"entityTypes\"])):\n",
    "        if \"properties\" in s[\"entityTypes\"][i].keys():\n",
    "            flag = True\n",
    "            break\n",
    "    if flag:\n",
    "        # print('New Type Schema')\n",
    "        for i in range(len(s[\"entityTypes\"])):\n",
    "            if \"properties\" in s[\"entityTypes\"][i].keys():\n",
    "                for j in range(len(s[\"entityTypes\"][i][\"properties\"])):\n",
    "                    s[\"entityTypes\"][i][\"properties\"][j] = {\n",
    "                        (\"\".join(e for e in k if e.isalnum())).lower(): v\n",
    "                        for k, v in s[\"entityTypes\"][i][\"properties\"][j].items()\n",
    "                    }\n",
    "                    # print(s['entityTypes'][i]['properties'])\n",
    "                for j in range(len(s[\"entityTypes\"][i][\"properties\"])):\n",
    "                    if df_new2 is not None:\n",
    "                        df1 = pd.concat([df1, df_new2])\n",
    "                        df_new2 = None\n",
    "                    else:\n",
    "                        df_new2 = pd.DataFrame(s[\"entityTypes\"][i][\"properties\"])\n",
    "        if \"propertymetadata\" in df1.columns:\n",
    "            df1.drop([\"propertymetadata\"], axis=1, inplace=True)\n",
    "        df1.rename(columns={\"name\": \"type_schema\"}, inplace=True)\n",
    "        df1.drop_duplicates(inplace=True, ignore_index=True)\n",
    "        # print(df1.head())\n",
    "    else:\n",
    "        for i in range(len(s[\"entityTypes\"])):\n",
    "            s[\"entityTypes\"][i] = {\n",
    "                (\"\".join(e for e in k if e.isalnum())).lower(): v\n",
    "                for k, v in s[\"entityTypes\"][i].items()\n",
    "            }\n",
    "        df1 = pd.DataFrame(s[\"entityTypes\"])\n",
    "        df1.rename(columns={\"type\": \"type_schema\"}, inplace=True)\n",
    "        print(\"      Old Type Schema\")\n",
    "    return df1\n",
    "\n",
    "\n",
    "def custom_style1(row):\n",
    "    if row.values[-1] == \"both\" and (\n",
    "        row.values[-2] != row.values[-4] or row.values[-3] != row.values[-5]\n",
    "    ):\n",
    "        color = \"lightpink\"\n",
    "    elif row.values[-1] != \"both\":\n",
    "        color = \"lightyellow\"\n",
    "    else:\n",
    "        color = \"lightgreen\"\n",
    "    return [\"color:black;background-color: %s\" % color] * len(row.values)\n",
    "\n",
    "\n",
    "base_schema_df1 = schema_detect(base_processor_version)\n",
    "base_schema_dict = base_schema_df1.set_index(\"type_schema\").T.to_dict()\n",
    "\n",
    "new_schema = dict()\n",
    "new_schema[\"displayName\"] = old_schema[\"displayName\"]\n",
    "new_schema[\"description\"] = old_schema[\"description\"]\n",
    "new_schema[\"metadata\"] = base_processor_version[\"metadata\"]\n",
    "new_schema[\"entityTypes\"] = [\n",
    "    {\n",
    "        \"name\": base_processor_version[\"entityTypes\"][0][\"name\"],\n",
    "        \"baseTypes\": base_processor_version[\"entityTypes\"][0][\"baseTypes\"],\n",
    "        \"properties\": list(),\n",
    "    }\n",
    "]\n",
    "entityTypes = [base_processor_version[\"entityTypes\"][0][\"name\"]]\n",
    "for i in old_schema[\"entityTypes\"]:\n",
    "    if \"/\" in i[\"type\"]:\n",
    "        if i[\"type\"].split(\"/\")[0] not in entityTypes:\n",
    "            temp = dict()\n",
    "            temp[\"name\"] = i[\"type\"].split(\"/\")[0]\n",
    "            temp[\"baseTypes\"] = [\"object\"]\n",
    "            temp[\"properties\"] = list()\n",
    "            new_schema[\"entityTypes\"].append(temp)\n",
    "            entityTypes.append(i[\"type\"].split(\"/\")[0])\n",
    "            temp2 = dict()\n",
    "            temp2[\"name\"] = i[\"type\"].split(\"/\")[0]\n",
    "            temp2[\"valueType\"] = i[\"type\"].split(\"/\")[0]\n",
    "            temp2[\"occurrenceType\"] = \"OPTIONAL_MULTIPLE\"\n",
    "            new_schema[\"entityTypes\"][0][\"properties\"].append(temp2)\n",
    "for i in new_schema[\"entityTypes\"]:\n",
    "    for j in old_schema[\"entityTypes\"]:\n",
    "        if (\n",
    "            \"/\" not in j[\"type\"]\n",
    "            and i[\"name\"] == base_processor_version[\"entityTypes\"][0][\"name\"]\n",
    "        ):\n",
    "            temp = {}\n",
    "            temp[\"name\"] = j[\"type\"]\n",
    "            if j[\"type\"] in base_schema_dict.keys():\n",
    "                temp[\"valueType\"] = base_schema_dict[j[\"type\"]][\"valuetype\"]\n",
    "                temp[\"occurrenceType\"] = base_schema_dict[j[\"type\"]][\"occurrencetype\"]\n",
    "            else:\n",
    "                temp[\"valueType\"] = j[\"baseType\"]\n",
    "                temp[\"occurrenceType\"] = j[\"occurrenceType\"]\n",
    "\n",
    "            i[\"properties\"].append(temp)\n",
    "        else:\n",
    "            if i[\"name\"] == j[\"type\"].split(\"/\")[0]:\n",
    "                temp = {}\n",
    "                temp[\"name\"] = j[\"type\"]\n",
    "                if j[\"type\"] in base_schema_dict.keys():\n",
    "                    temp[\"valueType\"] = base_schema_dict[j[\"type\"]][\"valuetype\"]\n",
    "                    temp[\"occurrenceType\"] = base_schema_dict[j[\"type\"]][\n",
    "                        \"occurrencetype\"\n",
    "                    ]\n",
    "                else:\n",
    "                    temp[\"valueType\"] = j[\"baseType\"]\n",
    "                    temp[\"occurrenceType\"] = \"OPTIONAL_ONCE\"\n",
    "                i[\"properties\"].append(temp)\n",
    "new_schema2 = copy.deepcopy(new_schema)\n",
    "my_schema_df2 = schema_detect(new_schema)\n",
    "# Merging both the data frame and getting differences\n",
    "compare = base_schema_df1.merge(\n",
    "    my_schema_df2,\n",
    "    on=\"type_schema\",\n",
    "    how=\"outer\",\n",
    "    suffixes=[\"_base\", \"_2\"],\n",
    "    indicator=True,\n",
    ")\n",
    "compare[\"_merge\"] = compare[\"_merge\"].replace(\n",
    "    \"right_only\", \"custom schema only \", regex=True\n",
    ")\n",
    "compare[\"_merge\"] = compare[\"_merge\"].replace(\n",
    "    \"left_only\", \"base schema only \", regex=True\n",
    ")\n",
    "compare.rename(columns={\"_merge\": \"entity_exists_in\"}, inplace=True)\n",
    "compare.style.apply(custom_style1, axis=1)\n",
    "new_schema_file_name = \"new_schema.json\"\n",
    "with open(new_schema_file_name, \"w\") as f:\n",
    "    f.write(json.dumps(new_schema2, ensure_ascii=False))\n",
    "print(new_schema2)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
