{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6589fc93-39d1-4d10-be1f-e7eb33fe4087",
   "metadata": {},
   "source": [
    "# PII Data Redaction Tool\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf22bf7-4a47-4f3a-9eef-6f19348a5250",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f188e-fe11-4a49-b7c8-080e0e69ce7a",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the DocAI Incubator Team. No guarantees of performance are implied. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1036937a-0221-48eb-862e-3fa0b8e646a8",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This tool uses parsed json files and a list of entities which have PII data and converts the json into pdf after redacting the entities provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a4e82-5e83-468a-b0e5-097ca14f15d5",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* Vertex AI Notebook Or Colab (If using Colab, use authentication)\n",
    "* Storage Bucket for storing input and output json files\n",
    "* Permission For Google Storage and Vertex AI Notebook.\n",
    "* list of entities to be redacted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81de40-5c62-4c0b-adea-937f957b1a6e",
   "metadata": {},
   "source": [
    "## Step by Step procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142123d3-37b1-4aa8-841c-40c3bd52d70c",
   "metadata": {},
   "source": [
    "### 1. Importing Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99666f0-f4e7-485a-9e99-238e2557d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy google-cloud-storage google-cloud-documentai==2.16.0 PyPDF2 configparser\n",
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e03bc5-ab41-4521-96ab-c32a07d2f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from typing import (\n",
    "    Container,\n",
    "    Iterable,\n",
    "    Iterator,\n",
    "    List,\n",
    "    Mapping,\n",
    "    Optional,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    Union,\n",
    ")\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy\n",
    "import cv2\n",
    "from utilities import *\n",
    "from typing import Tuple, List, Dict, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c8c4c-68b8-413c-b4bc-c66f044d3b7a",
   "metadata": {},
   "source": [
    "### 2. Input and Output Paths\n",
    "* In the list of entities, provide the entities which have to be redacted. If there is a child item to be redacted please specify as parent item type/child item type  even though the child item does not have the parent name in type. Example: line_item/amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b3ca3-e486-4614-81c2-da8e1f695666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input details\n",
    "gcs_input_path = \"gs://xxxx/xxxx/xx\"  # GCS path where doc ai parsed files saved\n",
    "gcs_output_path = \"gs://xxx/xxx/xx/\"  # GCS path to save the redacted pdfs\n",
    "pii_entities = [\n",
    "    \"customer_account_name\",\n",
    "    \"supplier_name\",\n",
    "    \"line_item/quantity\",\n",
    "]  # List of entities to be redacted ,sample given"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d4909-e00c-4704-a43b-6534f7403872",
   "metadata": {},
   "source": [
    "**`gcs_input_path`** : GCS Input Path. It should contain DocAI processed output json files.      \n",
    "**`gcs_output_path`** : GCS Output Path. The updated synthesized data in the pdf.       \n",
    "**`pii_entities`** : Entities for which the mentiontext has to be redacted and replaced with synthetic data given in the excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737d1c70-fef5-49e3-a266-695bf8076a54",
   "metadata": {},
   "source": [
    "### 3. Run the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22bfdd-abdc-4d1c-8f7c-86164e7c4103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "\n",
    "def get_page_bbox(entity: documentai.Document.Entity) -> Tuple[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Extract the page number and bounding box from a given Document AI entity.\n",
    "\n",
    "    Args:\n",
    "        entity (documentai.Document.Entity): The Document AI entity.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, List[float]]: A tuple containing the page number and bounding box [min_x, min_y, max_x, max_y].\n",
    "    \"\"\"\n",
    "    bound_poly = entity.page_anchor.page_refs\n",
    "    norm_ver = bound_poly[0].bounding_poly.normalized_vertices\n",
    "    x_1 = []\n",
    "    y_1 = []\n",
    "    for xy in norm_ver:\n",
    "        x_1.append(xy.x)\n",
    "        y_1.append(xy.y)\n",
    "    bbox = [min(x_1), min(y_1), max(x_1), max(y_1)]\n",
    "    try:\n",
    "        page = bound_poly[0].bounding_poly.page\n",
    "    except:\n",
    "        page = \"0\"\n",
    "\n",
    "    return page, bbox\n",
    "\n",
    "\n",
    "def get_bbox_page_wise(\n",
    "    json_data: documentai.Document, pii_entities: List[str]\n",
    ") -> Dict[str, List[List[Union[float, str]]]]:\n",
    "    \"\"\"\n",
    "    Extract page-wise bounding boxes of specified PII entities from Document AI output.\n",
    "\n",
    "    Args:\n",
    "        json_data (documentai.Document): The Document AI output.\n",
    "        pii_entities (List[str]): List of PII entities to extract.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[List[Union[float, str]]]]: A dictionary containing page-wise bounding boxes of PII entities.\n",
    "    \"\"\"\n",
    "    page_wise_bbox = {}\n",
    "    for pii_ent in pii_entities:\n",
    "        for entity in json_data.entities:\n",
    "            if \"/\" not in pii_ent:\n",
    "                if entity.type_ == pii_ent:\n",
    "                    page, bbox = get_page_bbox(entity)\n",
    "                    if page in page_wise_bbox.keys():\n",
    "                        page_wise_bbox[page].append(bbox)\n",
    "                    else:\n",
    "                        page_wise_bbox[page] = [bbox]\n",
    "            else:\n",
    "                parent_name = pii_ent.split(\"/\")[0]\n",
    "                if entity.properties:\n",
    "                    if entity.type_ == parent_name:\n",
    "                        for sub_ent in entity.properties:\n",
    "                            if (\n",
    "                                sub_ent.type_ == pii_ent.split(\"/\")[-1]\n",
    "                                or sub_ent.type_ == pii_ent\n",
    "                            ):\n",
    "                                page, bbox = get_page_bbox(sub_ent)\n",
    "                                if page in page_wise_bbox.keys():\n",
    "                                    page_wise_bbox[page].append(bbox)\n",
    "                                else:\n",
    "                                    page_wise_bbox[page] = [bbox]\n",
    "    return page_wise_bbox\n",
    "\n",
    "\n",
    "def get_synthesized_images(json_data: documentai.Document) -> List[Image.Image]:\n",
    "    \"\"\"\n",
    "    Convert JSON data representing images into a list of PIL Image objects.\n",
    "\n",
    "    Args:\n",
    "        json_data (documentai.Document): The Document AI output containing image data.\n",
    "\n",
    "    Returns:\n",
    "        List[Image.Image]: A list of PIL Image objects.\n",
    "    \"\"\"\n",
    "    synthesized_images = []\n",
    "\n",
    "    def decode_image(image_bytes: bytes) -> Image.Image:\n",
    "        with io.BytesIO(image_bytes) as image_file:\n",
    "            image = Image.open(image_file)\n",
    "            image.load()\n",
    "        return image\n",
    "\n",
    "    for i in range(len(json_data.pages)):\n",
    "        synthesized_images.append(decode_image(json_data.pages[i].image.content))\n",
    "\n",
    "    return synthesized_images\n",
    "\n",
    "\n",
    "def draw_black_box(\n",
    "    synthesized_images: List[Image.Image],\n",
    "    page_wise_bbox: Dict[str, List[List[Union[float, str]]]],\n",
    ") -> io.BytesIO:\n",
    "    \"\"\"\n",
    "    Draw black boxes on images for specified PII entity bounding boxes and compile into a PDF.\n",
    "\n",
    "    Args:\n",
    "        synthesized_images (List[Image.Image]): List of PIL Image objects.\n",
    "        page_wise_bbox (Dict[str, List[List[Union[float, str]]]]): Page-wise bounding boxes for PII entities.\n",
    "\n",
    "    Returns:\n",
    "        io.BytesIO: PDF stream containing images with black boxes drawn.\n",
    "    \"\"\"\n",
    "    open_cv_image = {}\n",
    "    for i in range(len(synthesized_images)):\n",
    "        open_cv_image[i] = numpy.array(synthesized_images[i].convert(\"RGB\"))\n",
    "    img_final = []\n",
    "    for i in range(len(open_cv_image)):\n",
    "        size = open_cv_image[i].shape\n",
    "        for page, bbox_list in page_wise_bbox.items():\n",
    "            if str(i) == page:\n",
    "                for bbox in bbox_list:\n",
    "                    x1 = int(bbox[0] * size[1])\n",
    "                    y1 = int(bbox[1] * size[0])\n",
    "                    x2 = int(bbox[2] * size[1])\n",
    "                    y2 = int(bbox[3] * size[0])\n",
    "                    cv2.rectangle(\n",
    "                        open_cv_image[i],\n",
    "                        (x1, y1),\n",
    "                        (x2, y2),\n",
    "                        (0, 0, 0),\n",
    "                        thickness=cv2.FILLED,\n",
    "                    )\n",
    "        img_temp = Image.fromarray(open_cv_image[i])\n",
    "        img_final.append(img_temp)\n",
    "    pdf_stream = io.BytesIO()\n",
    "    img_final[0].save(\n",
    "        pdf_stream,\n",
    "        save_all=True,\n",
    "        append_images=img_final[1:],\n",
    "        resolution=100.0,\n",
    "        quality=95,\n",
    "        optimize=True,\n",
    "        format=\"PDF\",\n",
    "    )\n",
    "\n",
    "    return pdf_stream\n",
    "\n",
    "\n",
    "def store_blob(pdf_stream, output_path, file_name):\n",
    "    \"\"\"\n",
    "    Store files in cloud storage.\n",
    "    \"\"\"\n",
    "    from google.cloud import storage\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    path_ = output_path.split(\"/\")\n",
    "    result_bucket = storage_client.bucket(path_[2])\n",
    "\n",
    "    output_prefix = \"/\".join(path_[3:])\n",
    "    filename = file_name.split(\".\")[0] + \".pdf\"\n",
    "\n",
    "    blob = result_bucket.blob(f\"{output_prefix}{filename}\")\n",
    "    pdfbytes = pdf_stream.getvalue()\n",
    "    blob.upload_from_string(pdfbytes, content_type=\"application/pdf\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Calling the functions\"\"\"\n",
    "    file_names_list, file_names_dict = file_names(gcs_input_path)\n",
    "    for filename, filepath in tqdm(file_names_dict.items(), desc=\"Progress\"):\n",
    "        if \".json\" in filename:\n",
    "            print(filename)\n",
    "            try:\n",
    "                json_data = documentai_json_proto_downloader(\n",
    "                    gcs_input_path.split(\"/\")[2], filepath\n",
    "                )\n",
    "                page_wise_bbox = get_bbox_page_wise(json_data, pii_entities)\n",
    "                synthesized_images = get_synthesized_images(json_data)\n",
    "                pdf_stream = draw_black_box(synthesized_images, page_wise_bbox)\n",
    "                store_blob(pdf_stream, gcs_output_path, filename)\n",
    "            except Exception as e:\n",
    "                print(\"unable to redact the file: {filename}\", filename)\n",
    "                continue\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aa873d-f9be-46dc-b188-23e0d4d95dd0",
   "metadata": {},
   "source": [
    "### 4.Output\n",
    "\n",
    "* The New pdf documents with synthesized data will be saved in gcs_output_path\n",
    "\n",
    "* Entities will be redacted and pdf will be saved in the GCS output folder provided.\n",
    "\n",
    "<img src=\"./Images/Output.png\" width=800 height=400></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1993b45-49ff-43ec-9e52-8acdb0fcaa4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
