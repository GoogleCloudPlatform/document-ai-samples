{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb7884ac-88a2-4adb-8240-95642aca0255",
   "metadata": {},
   "source": [
    "# Document AI Processor Visual Assessment Tool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d50f0e9-4ee1-40bb-a493-c1295fef99db",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8c290ae-a76b-4177-ab74-c27fc485f046",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the DocAI Incubator Team. No guarantees of performance are implied."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bfb20e7-48c3-45a3-89d8-a621d4203cd7",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The Python script is designed to produce an Excel report from the provided PDFs using a chosen Document AI processor. This report offers a snapshot of the entity extraction by the processor from the PDFs and visually presents the bounding boxes within the images in the Excel sheet. \n",
    "For the Form Parser, the report will detail the key-value pairs and the table structures. For other processors, the report will showcase the predicted entity types paired with the corresponding mention text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b61ea0e-53ba-4989-8b1f-919f3b4101d7",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "   * Python : Jupyter notebook (Vertex AI)\n",
    "   * Permission to the Google project is needed and ccess to Document AI processor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9df98c33-e247-400c-a38b-57b873232549",
   "metadata": {},
   "source": [
    "## Step by step procedure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "581f2c1c-73f7-47cb-84ec-899b0a371f2b",
   "metadata": {},
   "source": [
    "### Install the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a0650-8583-4790-949b-eb34466579ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to download utilities module\n",
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a00072-45b4-47ec-9b34-315a9dcc50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install pillow\n",
    "!pip install opencv-python\n",
    "!pip install google-cloud-documentai==2.16.0\n",
    "!pip install google-cloud-storage\n",
    "!pip install xlsxwriter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f0be02f-57b4-4480-ae91-f752ffa62387",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb97eb44-6006-4b5a-b4a4-886a78c0c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import io\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import base64\n",
    "import tempfile\n",
    "from os.path import splitext\n",
    "import numpy as np\n",
    "from google.cloud import documentai_v1beta3\n",
    "from google.cloud import storage\n",
    "from typing import List, Sequence, Dict, Any, Tuple, Optional\n",
    "from pprint import pprint\n",
    "import utilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae240a6b-2c4b-4328-8b11-04572ee0557f",
   "metadata": {},
   "source": [
    "### Setup the required inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67f5ca-9981-4e6d-ac1f-3fa2883567ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"<your-project-id>\"\n",
    "processor_id = \"<your-processor-id>\"\n",
    "bucket_name = \"<bucket-name>\"\n",
    "input_pdfs_path = \"gs://<bucket-name>/<subfolder-name>\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eec0e04b-e00e-49eb-b8e8-730cfda491b7",
   "metadata": {},
   "source": [
    " * `project_id`: The ID of the project where your Document AI processor and storage bucket are located.\n",
    " * `processor_id`: The ID of the processor you intend to use for evaluation.\n",
    " * `bucket_name`: The name of the bucket where batch processing results will be stored.\n",
    " * `input_pdfs_path`: The Google Cloud Storage (gs) path for the PDFs you wish to process with the Document AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9597c414-826f-4a28-8190-bc5a1999bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processor_type(project_id_: str, processor_id_: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Retrieves the display name and type of a specific Document AI processor.\n",
    "\n",
    "    Args:\n",
    "    project_id_ (str): The project ID in Google Cloud.\n",
    "    processor_id_ (str): The ID of the processor within the specified project.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[str, str]: A tuple containing the display name and type of the processor.\n",
    "    \"\"\"\n",
    "    client = documentai_v1beta3.DocumentProcessorServiceClient()\n",
    "    request = documentai_v1beta3.GetProcessorRequest(\n",
    "        name=f\"projects/{project_id_}/locations/us/processors/{processor_id_}\",\n",
    "    )\n",
    "    response = client.get_processor(request=request)\n",
    "    return response.display_name, response.type_\n",
    "\n",
    "\n",
    "def convert_base64_to_image(base64_text):\n",
    "    \"\"\"\n",
    "    Converts a base64 encoded text to an image.\n",
    "\n",
    "    Args:\n",
    "    base64_text (str): A string containing the base64 encoded data of an image.\n",
    "                      It can optionally start with 'data:image/png;base64,'.\n",
    "\n",
    "    Returns:\n",
    "    Image: An image object created from the base64 encoded data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(base64_text))\n",
    "        return image\n",
    "    except IOError:\n",
    "        print(\"Error in loading the image. The image data might be corrupted.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def draw_cells(\n",
    "    cells: List[Any], image: Image, draw: ImageDraw, color: str, border_width: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draws borders around specified cells on an image.\n",
    "\n",
    "    Args:\n",
    "    cells (List[Any]): A list of cell objects, each containing layout information.\n",
    "    image (Image): The image object on which the cells will be drawn.\n",
    "    draw (ImageDraw): An ImageDraw object to draw on the image.\n",
    "    color (str): The color of the border.\n",
    "    border_width (int): The width of the border around each cell.\n",
    "\n",
    "    The function does not return anything but modifies the given ImageDraw object.\n",
    "    \"\"\"\n",
    "    for cell in cells:\n",
    "        try:\n",
    "            # Extract vertices assuming they are provided in a normalized form\n",
    "            vertices = [\n",
    "                (v.x * image.width, v.y * image.height)\n",
    "                for v in cell.layout.bounding_poly.normalized_vertices\n",
    "            ]\n",
    "\n",
    "            # Draw borders of specified width\n",
    "            for i in range(border_width):\n",
    "                border_vertices = [(v[0] - i - 1, v[1] - i - 1) for v in vertices]\n",
    "                draw.polygon(border_vertices, outline=color)\n",
    "        except AttributeError:\n",
    "            # Skip if the necessary attributes are not present\n",
    "            pass\n",
    "\n",
    "\n",
    "def draw_kvp(\n",
    "    kvp: Any, image: Image, draw: ImageDraw, color: str, border_width: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draws a polygon around the provided key-value pair (KVP) on an image.\n",
    "\n",
    "    Args:\n",
    "    kvp (Any): An object representing a key-value pair, containing bounding polygon vertices.\n",
    "    image (Image): The image object on which the KVP will be drawn.\n",
    "    draw (ImageDraw): An ImageDraw object to draw on the image.\n",
    "    color (str): The color of the polygon's outline.\n",
    "    border_width (int): The width of the polygon's outline.\n",
    "\n",
    "    The function does not return anything but modifies the given ImageDraw object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract vertices assuming they are provided in a normalized form\n",
    "        vertices = [\n",
    "            (v.x * image.width, v.y * image.height)\n",
    "            for v in kvp.bounding_poly.normalized_vertices\n",
    "        ]\n",
    "\n",
    "        # Draw the polygon with the specified color and border width\n",
    "        draw.polygon(vertices, outline=color, width=border_width)\n",
    "    except AttributeError:\n",
    "        # Skip if the necessary attributes are not present\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_kvp_data(kvp_fields: List[Any], text: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Extracts key-value pair data from a list of fields and returns it as a dictionary.\n",
    "\n",
    "    Args:\n",
    "    kvp_fields (List[Any]): A list of objects, each representing a key-value pair.\n",
    "                            Each object contains 'field_name' and 'field_value' properties.\n",
    "    text (str): The text in which these key-value pairs are found.\n",
    "\n",
    "    Returns:\n",
    "    Dict[str, str]: A dictionary where each key is the name of the field and its value is the corresponding field value.\n",
    "    \"\"\"\n",
    "    kvp_dict = {}\n",
    "\n",
    "    for field in kvp_fields:\n",
    "        name = text_anchor_to_text(field.field_name.text_anchor, text).strip()\n",
    "        value = text_anchor_to_text(field.field_value.text_anchor, text).strip()\n",
    "        kvp_dict[name] = value\n",
    "    return kvp_dict\n",
    "\n",
    "\n",
    "def get_table_data(rows: Sequence[Any], text: str) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Extracts and organizes text data from table rows.\n",
    "\n",
    "    Args:\n",
    "    rows (Sequence[Any]): A sequence of row objects, each containing cells with layout information.\n",
    "    text (str): The text in which the table data is found.\n",
    "\n",
    "    Returns:\n",
    "    List[List[str]]: A list of lists, where each inner list contains the text data of a single row in the table.\n",
    "    \"\"\"\n",
    "    all_values: List[List[str]] = []\n",
    "    for row in rows:\n",
    "        current_row_values: List[str] = []\n",
    "        for cell in row.cells:\n",
    "            current_row_values.append(\n",
    "                text_anchor_to_text(cell.layout.text_anchor, text)\n",
    "            )\n",
    "        all_values.append(current_row_values)\n",
    "    return all_values\n",
    "\n",
    "\n",
    "def text_anchor_to_text(text_anchor: Any, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts offsets in a text anchor to a string.\n",
    "\n",
    "    Args:\n",
    "    text_anchor (Any): An object representing a text anchor with text segments.\n",
    "    text (str): The complete text from which to extract the specified range.\n",
    "\n",
    "    Returns:\n",
    "    str: The extracted text corresponding to the range specified in the text anchor.\n",
    "         Newline characters in the extracted text are replaced with spaces.\n",
    "    \"\"\"\n",
    "    response = \"\"\n",
    "    text_segments = text_anchor.text_segments\n",
    "    for segment in text_segments:\n",
    "        start_index = segment.start_index if hasattr(segment, \"start_index\") else 0\n",
    "        end_index = segment.end_index\n",
    "        response += text[start_index:end_index]\n",
    "    return response.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "def draw_bounding_box(\n",
    "    draw: ImageDraw,\n",
    "    vertices: List[Tuple[float, float]],\n",
    "    image: Image,\n",
    "    color: str = \"blue\",\n",
    "    scale_factor: float = 1.05,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draws a bounding box or polygon based on the provided vertices on an image.\n",
    "\n",
    "    Args:\n",
    "    draw (ImageDraw): The ImageDraw instance to draw on the image.\n",
    "    vertices (List[Tuple[float, float]]): List of tuples representing normalized coordinates (x, y) of the vertices.\n",
    "    image (Image): The image on which to draw the bounding box or polygon.\n",
    "    color (str, optional): The color of the bounding box or polygon. Defaults to \"blue\".\n",
    "    scale_factor (float, optional): Factor to scale the bounding box or polygon. Defaults to 1.05.\n",
    "\n",
    "    The function doesn't return anything but modifies the ImageDraw object to include the bounding box or polygon.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    scaled_vertices = [\n",
    "        (x * width * scale_factor, y * height * scale_factor) for x, y in vertices\n",
    "    ]\n",
    "\n",
    "    if len(scaled_vertices) > 2:\n",
    "        # Draw polygon if more than 2 vertices\n",
    "        draw.polygon(scaled_vertices, outline=color, width=3)\n",
    "    elif len(scaled_vertices) == 2:\n",
    "        # Draw rectangle if exactly 2 vertices\n",
    "        draw.rectangle(scaled_vertices, outline=color, width=3)\n",
    "    else:\n",
    "        # Handle cases with invalid number of vertices\n",
    "        pass  # Or log a warning message\n",
    "\n",
    "\n",
    "def generate_data_for_file(\n",
    "    document_object: Any, blob_name: str, writer: pd.ExcelWriter\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes the content of a provided document object and generates data for an Excel file.\n",
    "    This function is specifically tailored for visualizing results from a form parser,\n",
    "    which includes key-value pairs and tables. It generates images with highlighted areas\n",
    "    corresponding to these elements and inserts them into the Excel file.\n",
    "\n",
    "    Args:\n",
    "    - document_object (Any): The document object containing parsed data from the form parser.\n",
    "    - blob_name (str): The name of the blob (file) being processed.\n",
    "    - writer (pd.ExcelWriter): An Excel writer object for writing data to an Excel file.\n",
    "\n",
    "    This function processes tables and key-value pairs (KVP) in the document,\n",
    "    creating a DataFrame for each and appending them to an Excel sheet. It also generates\n",
    "    images with bounding boxes around detected entities (both KVP and table cells),\n",
    "    which are then inserted into the Excel file.\n",
    "    \"\"\"\n",
    "    file_path = blob_name\n",
    "\n",
    "    # Create a list to store flattened DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Initialize variables to keep track of page and table numbers\n",
    "    page_number = 1\n",
    "\n",
    "    # Flatten and append tables to the list with titles and gaps\n",
    "    for page in document_object.pages:\n",
    "        tables = page.tables\n",
    "        table_number = 1  # Reset table number for each page\n",
    "        for index, table in enumerate(tables):\n",
    "            body_rows = list(table.body_rows)\n",
    "            header_rows = list(table.header_rows)\n",
    "\n",
    "            # print(type(header_rows))\n",
    "            # Combine header and body rows\n",
    "            all_rows = header_rows + body_rows\n",
    "\n",
    "            # print(all_rows)\n",
    "            # Extract cell values from rows\n",
    "            table_data = [\n",
    "                get_table_data([row], document_object.text)[0] for row in all_rows\n",
    "            ]\n",
    "            df = pd.DataFrame(data=table_data)\n",
    "\n",
    "            # Insert table title as the first row in the DataFrame\n",
    "            table_title = f\"Table {table_number} Page {page_number}\"\n",
    "            df.loc[-1] = [table_title] + [\"\"] * (df.shape[1] - 1)\n",
    "            df.index = df.index + 1\n",
    "            df = df.sort_index()\n",
    "\n",
    "            dfs.append(df)\n",
    "\n",
    "            table_number += 1\n",
    "\n",
    "        page_number += 1\n",
    "\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Handle KVP\n",
    "    all_kvp_data = []\n",
    "    page_number = 1  # Initialize page number\n",
    "    for page in document_object.pages:\n",
    "        kvp_fields = page.form_fields\n",
    "        if kvp_fields:\n",
    "            kvp_fields_values = get_kvp_data(kvp_fields, document_object.text)\n",
    "            # Add page number to each KVP entry\n",
    "            for item in kvp_fields_values.items():\n",
    "                all_kvp_data.append((item[0], item[1], page_number))\n",
    "        page_number += 1  # Increment page number for the next iteration\n",
    "\n",
    "    kvp_df = pd.DataFrame(all_kvp_data, columns=[\"Name\", \"Value\", \"Page Number\"])\n",
    "\n",
    "    colors = [\"red\", \"blue\", \"green\", \"orange\", \"purple\"]\n",
    "    color_idx = 0\n",
    "    border_width = 5\n",
    "    temp_image_files = []\n",
    "\n",
    "    for index, page in enumerate(document_object.pages):\n",
    "        # print(f\"Processing page index: {index}\")\n",
    "        base64_text = page.image.content\n",
    "        # print(base64_text)\n",
    "        image = convert_base64_to_image(base64_text)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        # DRAW KVP\n",
    "        color = \"black\"\n",
    "        kvp_fields = page.form_fields\n",
    "        if kvp_fields:  # Check if kvp_fields is not empty\n",
    "            for kvp in kvp_fields:\n",
    "                draw_kvp(kvp.field_name, image, draw, color, border_width)\n",
    "                draw_kvp(kvp.field_value, image, draw, color, border_width)\n",
    "\n",
    "        tables = page.tables\n",
    "        for table in page.tables:\n",
    "            color = colors[color_idx]\n",
    "            color_idx = (color_idx + 1) % len(colors)\n",
    "\n",
    "            # DRAW TABLES\n",
    "            for row_type in [\"body_rows\", \"header_rows\"]:\n",
    "                rows = getattr(\n",
    "                    table, row_type\n",
    "                )  # Use getattr to dynamically access the attribute\n",
    "                for row in rows:\n",
    "                    draw_cells(row.cells, image, draw, color, border_width)\n",
    "        # Save the image to a temporary file\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as f:\n",
    "            temp_image_filename = f.name\n",
    "            image.save(f, \"PNG\")\n",
    "            temp_image_files.append(temp_image_filename)  # Store path for later\n",
    "\n",
    "    # Add data to the Excel writer\n",
    "    sheet_name = os.path.splitext(os.path.basename(file_path))[0][:31]\n",
    "    kvp_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "    bold_format = workbook.add_format({\"bold\": True})\n",
    "    border_format = workbook.add_format({\"border\": 1})\n",
    "    start_row = len(kvp_df) + 2 if not kvp_df.empty else 0\n",
    "    combined_df.to_excel(\n",
    "        writer, sheet_name=sheet_name, startrow=start_row, index=False, header=False\n",
    "    )\n",
    "\n",
    "    row_num = start_row\n",
    "    for idx, row in combined_df.iterrows():\n",
    "        if \"Table\" in str(row[0]):  # Table title row\n",
    "            worksheet.write(row_num, 0, row[0], bold_format)\n",
    "            row_num += 1\n",
    "            continue  # skip to the next row\n",
    "\n",
    "        if all(pd.isna(cell) for cell in row):  # If the entire row is NaN (gap row)\n",
    "            for col_num, cell_value in enumerate(row):\n",
    "                worksheet.write(\n",
    "                    row_num, col_num, \"\", workbook.add_format()\n",
    "                )  # Overwrite with an empty format\n",
    "            row_num += 1\n",
    "            continue\n",
    "\n",
    "        for col_num, cell_value in enumerate(row):\n",
    "            if pd.notna(cell_value):\n",
    "                worksheet.write(row_num, col_num, cell_value, border_format)\n",
    "        row_num += 1\n",
    "\n",
    "    # Starting row for images\n",
    "    image_row = 0\n",
    "    for temp_image_filename in temp_image_files:\n",
    "        worksheet.insert_image(\n",
    "            image_row, 10, temp_image_filename, {\"x_scale\": 0.3, \"y_scale\": 0.3}\n",
    "        )\n",
    "        # Assuming the image takes up about 20 rows after resizing, adjust as needed\n",
    "        image_row += 30\n",
    "\n",
    "\n",
    "def generate_data_for_file_normal(\n",
    "    document_object: Any, blob_name: str, writer: pd.ExcelWriter\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes the provided file content from a document object and generates data for an Excel file.\n",
    "    Additionally, it creates images with bounding boxes for entities found in the document,\n",
    "    and inserts these images into the Excel file.\n",
    "\n",
    "    Args:\n",
    "    - document_object (Document): The Document AI object containing entities and page information.\n",
    "    - blob_name (str): The name of the blob file being processed.\n",
    "    - writer (pd.ExcelWriter): An Excel writer object used to write data to an Excel file.\n",
    "\n",
    "    The function processes entities within the document, sorts them by page,\n",
    "    and writes this data to an Excel sheet. For each page in the document,\n",
    "    it generates an image with bounding boxes around the detected entities.\n",
    "    These images are then inserted into the Excel file.\n",
    "    \"\"\"\n",
    "    file_path = blob_name\n",
    "\n",
    "    entities_list = []\n",
    "\n",
    "    for entity in document_object.entities:\n",
    "        if entity.properties:\n",
    "            for prop in entity.properties:\n",
    "                mentionText_prop = prop.mention_text\n",
    "                type_prop = prop.type_\n",
    "                page_prop = (\n",
    "                    prop.page_anchor.page_refs[0].page\n",
    "                    if prop.page_anchor.page_refs\n",
    "                    else 0\n",
    "                )\n",
    "\n",
    "                entities_list.append([type_prop, mentionText_prop, page_prop])\n",
    "        else:\n",
    "            mentionText = entity.mention_text\n",
    "            entity_type = entity.type_\n",
    "            page = (\n",
    "                entity.page_anchor.page_refs[0].page\n",
    "                if entity.page_anchor.page_refs\n",
    "                else 0\n",
    "            )\n",
    "\n",
    "            entities_list.append([entity_type, mentionText, page])\n",
    "\n",
    "    df = pd.DataFrame(entities_list, columns=[\"Type\", \"MentionText\", \"Page\"])\n",
    "    df[\"Page\"] = df[\"Page\"].astype(int)\n",
    "    df_sorted = df.sort_values(by=\"Page\")\n",
    "\n",
    "    temp_image_files = []\n",
    "\n",
    "    # Iterate over each page in the document\n",
    "    for page_index, page in enumerate(document_object.pages):\n",
    "        # Assuming 'page' has an attribute 'image' which is a base64-encoded string\n",
    "        base64_text = page.image.content\n",
    "        image = convert_base64_to_image(base64_text)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        # Draw bounding boxes for entities associated with the current page\n",
    "        for entity in document_object.entities:\n",
    "            entity_page = (\n",
    "                entity.page_anchor.page_refs[0].page\n",
    "                if entity.page_anchor.page_refs\n",
    "                else 0\n",
    "            )\n",
    "\n",
    "            if entity_page == page_index:\n",
    "                vertices = [\n",
    "                    (v.x, v.y)\n",
    "                    for v in entity.page_anchor.page_refs[\n",
    "                        0\n",
    "                    ].bounding_poly.normalized_vertices\n",
    "                ]\n",
    "                draw_bounding_box(draw, vertices, image, color=\"blue\")\n",
    "\n",
    "                # Properties (child entities)\n",
    "                for prop in entity.properties:\n",
    "                    prop_vertices = [\n",
    "                        (v.x, v.y)\n",
    "                        for v in prop.page_anchor.page_refs[\n",
    "                            0\n",
    "                        ].bounding_poly.normalized_vertices\n",
    "                    ]\n",
    "                    draw_bounding_box(draw, prop_vertices, image)\n",
    "\n",
    "        # Save the image to a temporary file\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as f:\n",
    "            temp_image_filename = f.name\n",
    "            image.save(f, \"PNG\")\n",
    "            temp_image_files.append(temp_image_filename)\n",
    "\n",
    "    # Add data to the Excel writer\n",
    "    sheet_name = os.path.splitext(os.path.basename(file_path))[0][:31]\n",
    "    df_sorted.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "    image_row = 0\n",
    "    for temp_image_filename in temp_image_files:\n",
    "        worksheet.insert_image(\n",
    "            image_row, 10, temp_image_filename, {\"x_scale\": 0.3, \"y_scale\": 0.3}\n",
    "        )\n",
    "        image_row += 30\n",
    "\n",
    "\n",
    "def generate_parser_viz_for_folder(bucket_path, processor_type):\n",
    "    storage_client = storage.Client()\n",
    "    # Parsing bucket name and prefix from the bucket path\n",
    "    if bucket_path.startswith(\"gs://\"):\n",
    "        bucket_path = bucket_path[5:]\n",
    "    bucket_name, prefix = bucket_path.split(\"/\", 1)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    with pd.ExcelWriter(f\"{processor_type}_report.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "        for blob in bucket.list_blobs(prefix=prefix):\n",
    "            try:\n",
    "                if blob.name.endswith(\".json\"):\n",
    "                    file_content = blob.download_as_text()\n",
    "                    json_data = json.loads(file_content)\n",
    "                    document_object = documentai_v1beta3.Document.from_json(\n",
    "                        json.dumps(json_data)\n",
    "                    )\n",
    "                    # print(type(document_object))\n",
    "                    if processor_type == \"FORM_PARSER_PROCESSOR\":\n",
    "                        generate_data_for_file(document_object, blob.name, writer)\n",
    "                    else:\n",
    "                        generate_data_for_file_normal(\n",
    "                            document_object, blob.name, writer\n",
    "                        )\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(f\"Skipped - {blob.name}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "processor_display_name, processor_type = get_processor_type(project_id, processor_id)\n",
    "current_time = time.strftime(\"%Y%m%d%H%M%S\")\n",
    "folder_path = f\"gs://{bucket_name}/{processor_display_name}_{current_time}\"\n",
    "xlsx_file_name = f\"{processor_display_name}_{current_time}.xlsx\"\n",
    "print(\n",
    "    f\"Batch Processing the Documents with the {processor_display_name} - {processor_type}\"\n",
    ")\n",
    "res = utilities.batch_process_documents_sample(\n",
    "    project_id=project_id,\n",
    "    location=\"us\",\n",
    "    processor_id=processor_id,\n",
    "    gcs_input_uri=input_pdfs_path,\n",
    "    gcs_output_uri=f\"{folder_path}/batch_process_outputs\",  # Concatenating the prefix here\n",
    ")\n",
    "print(\"Batch Process Completed\")\n",
    "try:\n",
    "    if processor_type == \"FORM_PARSER_PROCESSOR\":\n",
    "        print(\n",
    "            f\"{processor_type} Detected \\nVisualizing the key-value pairs and the table structures\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{processor_type} Detected \\nVisualizing the entities\")\n",
    "    generate_parser_viz_for_folder(folder_path, processor_type)\n",
    "    print(\n",
    "        f\"Report is generated. Please find the Visualization in {processor_type}_report.xlsx\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "\n",
    "    # Print an error message\n",
    "    print(\"Issue occurred. Please check the input field and JSON\")\n",
    "\n",
    "    # Print the traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7b4983c-ca22-4fa9-aee8-33eca9a3aa87",
   "metadata": {},
   "source": [
    "### Visualization Output  \n",
    "\n",
    "<img src=\"./images/invoice_out.png\" width=1000 height=800> </img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35819ee1-d756-476c-8e27-50ef446e30c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
