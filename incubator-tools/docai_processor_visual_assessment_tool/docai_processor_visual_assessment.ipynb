{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb7884ac-88a2-4adb-8240-95642aca0255",
   "metadata": {},
   "source": [
    "# Document AI Processor Visual Assessment Tool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d50f0e9-4ee1-40bb-a493-c1295fef99db",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8c290ae-a76b-4177-ab74-c27fc485f046",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the DocAI Incubator Team. No guarantees of performance are implied."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bfb20e7-48c3-45a3-89d8-a621d4203cd7",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The Python script is designed to produce an Excel report from the provided PDFs using a chosen Document AI processor. This report offers a snapshot of the entity extraction by the processor from the PDFs and visually presents the bounding boxes within the images in the Excel sheet. \n",
    "For the Form Parser, the report will detail the key-value pairs and the table structures. For other processors, the report will showcase the predicted entity types paired with the corresponding mention text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b61ea0e-53ba-4989-8b1f-919f3b4101d7",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "   * Python : Jupyter notebook (Vertex AI)\n",
    "   * Permission to the Google project is needed and ccess to Document AI processor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9df98c33-e247-400c-a38b-57b873232549",
   "metadata": {},
   "source": [
    "## Step by step procedure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "581f2c1c-73f7-47cb-84ec-899b0a371f2b",
   "metadata": {},
   "source": [
    "### Install the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a0650-8583-4790-949b-eb34466579ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to download utilities module\n",
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a00072-45b4-47ec-9b34-315a9dcc50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install pillow\n",
    "!pip install opencv-python\n",
    "!pip install google-cloud-documentai==2.16.0\n",
    "!pip install google-cloud-storage\n",
    "!pip install xlsxwriter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f0be02f-57b4-4480-ae91-f752ffa62387",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb97eb44-6006-4b5a-b4a4-886a78c0c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import io\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import base64\n",
    "import tempfile\n",
    "from os.path import splitext\n",
    "import numpy as np\n",
    "from google.cloud import documentai_v1beta3\n",
    "from google.cloud import storage\n",
    "from typing import List, Sequence, Dict, Any, Tuple, Optional\n",
    "from pprint import pprint\n",
    "import utilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae240a6b-2c4b-4328-8b11-04572ee0557f",
   "metadata": {},
   "source": [
    "### Setup the required inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67f5ca-9981-4e6d-ac1f-3fa2883567ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"<your-project-id>\"\n",
    "processor_id = \"<your-processor-id>\"\n",
    "bucket_name = \"<bucket-name>\"\n",
    "input_pdfs_path = \"gs://<bucket-name>/<subfolder-name>\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eec0e04b-e00e-49eb-b8e8-730cfda491b7",
   "metadata": {},
   "source": [
    " * `project_id`: The ID of the project where your Document AI processor and storage bucket are located.\n",
    " * `processor_id`: The ID of the processor you intend to use for evaluation.\n",
    " * `bucket_name`: The name of the bucket where batch processing results will be stored.\n",
    " * `input_pdfs_path`: The Google Cloud Storage (gs) path for the PDFs you wish to process with the Document AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9597c414-826f-4a28-8190-bc5a1999bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processor_type(project_id_: str, processor_id_: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Retrieves the display name and type of a specific Document AI processor.\n",
    "\n",
    "    Args:\n",
    "    project_id_ (str): The project ID in Google Cloud.\n",
    "    processor_id_ (str): The ID of the processor within the specified project.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[str, str]: A tuple containing the display name and type of the processor.\n",
    "    \"\"\"\n",
    "    client = documentai_v1beta3.DocumentProcessorServiceClient()\n",
    "    request = documentai_v1beta3.GetProcessorRequest(\n",
    "        name=f\"projects/{project_id_}/locations/us/processors/{processor_id_}\",\n",
    "    )\n",
    "    response = client.get_processor(request=request)\n",
    "    return response.display_name, response.type_\n",
    "\n",
    "\n",
    "def convert_base64_to_image(base64_text):\n",
    "    \"\"\"\n",
    "    Converts a base64 encoded text to an image.\n",
    "\n",
    "    Args:\n",
    "    base64_text (str): A string containing the base64 encoded data of an image.\n",
    "                      It can optionally start with 'data:image/png;base64,'.\n",
    "\n",
    "    Returns:\n",
    "    Image: An image object created from the base64 encoded data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(base64_text))\n",
    "        return image\n",
    "    except IOError:\n",
    "        print(\"Error in loading the image. The image data might be corrupted.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def draw_cells(\n",
    "    cells: List[Any], image: Image, draw: ImageDraw, color: str, border_width: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draws borders around specified cells on an image.\n",
    "\n",
    "    Args:\n",
    "    cells (List[Any]): A list of cell objects, each containing layout information.\n",
    "    image (Image): The image object on which the cells will be drawn.\n",
    "    draw (ImageDraw): An ImageDraw object to draw on the image.\n",
    "    color (str): The color of the border.\n",
    "    border_width (int): The width of the border around each cell.\n",
    "\n",
    "    The function does not return anything but modifies the given ImageDraw object.\n",
    "    \"\"\"\n",
    "    for cell in cells:\n",
    "        try:\n",
    "            # Extract vertices assuming they are provided in a normalized form\n",
    "            vertices = [\n",
    "                (v.x * image.width, v.y * image.height)\n",
    "                for v in cell.layout.bounding_poly.normalized_vertices\n",
    "            ]\n",
    "\n",
    "            # Draw borders of specified width\n",
    "            for i in range(border_width):\n",
    "                border_vertices = [(v[0] - i - 1, v[1] - i - 1) for v in vertices]\n",
    "                draw.polygon(border_vertices, outline=color)\n",
    "        except AttributeError:\n",
    "            # Skip if the necessary attributes are not present\n",
    "            pass\n",
    "\n",
    "\n",
    "def draw_kvp(\n",
    "    kvp: Any, image: Image, draw: ImageDraw, color: str, border_width: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draws a polygon around the provided key-value pair (KVP) on an image.\n",
    "\n",
    "    Args:\n",
    "    kvp (Any): An object representing a key-value pair, containing bounding polygon vertices.\n",
    "    image (Image): The image object on which the KVP will be drawn.\n",
    "    draw (ImageDraw): An ImageDraw object to draw on the image.\n",
    "    color (str): The color of the polygon's outline.\n",
    "    border_width (int): The width of the polygon's outline.\n",
    "\n",
    "    The function does not return anything but modifies the given ImageDraw object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract vertices assuming they are provided in a normalized form\n",
    "        vertices = [\n",
    "            (v.x * image.width, v.y * image.height)\n",
    "            for v in kvp.bounding_poly.normalized_vertices\n",
    "        ]\n",
    "\n",
    "        # Draw the polygon with the specified color and border width\n",
    "        draw.polygon(vertices, outline=color, width=border_width)\n",
    "    except AttributeError:\n",
    "        # Skip if the necessary attributes are not present\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_kvp_data(kvp_fields: List[Any], text: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Extracts key-value pair data from a list of fields and returns it as a dictionary.\n",
    "\n",
    "    Args:\n",
    "    kvp_fields (List[Any]): A list of objects, each representing a key-value pair.\n",
    "                            Each object contains 'field_name' and 'field_value' properties.\n",
    "    text (str): The text in which these key-value pairs are found.\n",
    "\n",
    "    Returns:\n",
    "    Dict[str, str]: A dictionary where each key is the name of the field and its value is the corresponding field value.\n",
    "    \"\"\"\n",
    "    kvp_dict = {}\n",
    "\n",
    "    for field in kvp_fields:\n",
    "        name = text_anchor_to_text(field.field_name.text_anchor, text).strip()\n",
    "        value = text_anchor_to_text(field.field_value.text_anchor, text).strip()\n",
    "        kvp_dict[name] = value\n",
    "    return kvp_dict\n",
    "\n",
    "\n",
    "def get_table_data(rows: Sequence[Any], text: str) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Extracts and organizes text data from table rows.\n",
    "\n",
    "    Args:\n",
    "    rows (Sequence[Any]): A sequence of row objects, each containing cells with layout information.\n",
    "    text (str): The text in which the table data is found.\n",
    "\n",
    "    Returns:\n",
    "    List[List[str]]: A list of lists, where each inner list contains the text data of a single row in the table.\n",
    "    \"\"\"\n",
    "    all_values: List[List[str]] = []\n",
    "    for row in rows:\n",
    "        current_row_values: List[str] = []\n",
    "        for cell in row.cells:\n",
    "            current_row_values.append(\n",
    "                text_anchor_to_text(cell.layout.text_anchor, text)\n",
    "            )\n",
    "        all_values.append(current_row_values)\n",
    "    return all_values\n",
    "\n",
    "\n",
    "def text_anchor_to_text(text_anchor: Any, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts offsets in a text anchor to a string.\n",
    "\n",
    "    Args:\n",
    "    text_anchor (Any): An object representing a text anchor with text segments.\n",
    "    text (str): The complete text from which to extract the specified range.\n",
    "\n",
    "    Returns:\n",
    "    str: The extracted text corresponding to the range specified in the text anchor.\n",
    "         Newline characters in the extracted text are replaced with spaces.\n",
    "    \"\"\"\n",
    "    response = \"\"\n",
    "    text_segments = text_anchor.text_segments\n",
    "    for segment in text_segments:\n",
    "        start_index = segment.start_index if hasattr(segment, \"start_index\") else 0\n",
    "        end_index = segment.end_index\n",
    "        response += text[start_index:end_index]\n",
    "    return response.strip().replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "def draw_bounding_box(\n",
    "    draw: ImageDraw,\n",
    "    vertices: List[Tuple[float, float]],\n",
    "    image: Image,\n",
    "    color: str = \"blue\",\n",
    "    scale_factor: float = 1.05,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draws a bounding box or polygon based on the provided vertices on an image.\n",
    "\n",
    "    Args:\n",
    "    draw (ImageDraw): The ImageDraw instance to draw on the image.\n",
    "    vertices (List[Tuple[float, float]]): List of tuples representing normalized coordinates (x, y) of the vertices.\n",
    "    image (Image): The image on which to draw the bounding box or polygon.\n",
    "    color (str, optional): The color of the bounding box or polygon. Defaults to \"blue\".\n",
    "    scale_factor (float, optional): Factor to scale the bounding box or polygon. Defaults to 1.05.\n",
    "\n",
    "    The function doesn't return anything but modifies the ImageDraw object to include the bounding box or polygon.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    scaled_vertices = [\n",
    "        (x * width * scale_factor, y * height * scale_factor) for x, y in vertices\n",
    "    ]\n",
    "\n",
    "    if len(scaled_vertices) > 2:\n",
    "        # Draw polygon if more than 2 vertices\n",
    "        draw.polygon(scaled_vertices, outline=color, width=3)\n",
    "    elif len(scaled_vertices) == 2:\n",
    "        # Draw rectangle if exactly 2 vertices\n",
    "        draw.rectangle(scaled_vertices, outline=color, width=3)\n",
    "    else:\n",
    "        # Handle cases with invalid number of vertices\n",
    "        pass  # Or log a warning message\n",
    "\n",
    "\n",
    "def process_form_parser_processor(document_object, writer, file_path):\n",
    "    \"\"\"\n",
    "    Processes the document object for a form parser processor and writes data to an Excel file.\n",
    "\n",
    "    This function processes tables and key-value pairs (KVP) found in the document object,\n",
    "    creating a DataFrame for each. It then writes these DataFrames to the provided Excel writer.\n",
    "    Additionally, it assigns a sheet name based on the file path.\n",
    "\n",
    "    Args:\n",
    "    - document_object (Any): The document object containing parsed data from the form parser.\n",
    "    - writer (pd.ExcelWriter): An Excel writer object for writing data to an Excel file.\n",
    "    - file_path (str): The file path of the blob being processed, used for naming the Excel sheet.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[pd.DataFrame, pd.DataFrame, str]: A tuple containing the DataFrame for KVPs,\n",
    "      the combined DataFrame for all tables, and the sheet name.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    page_number = 1\n",
    "    for page in document_object.pages:\n",
    "        tables = page.tables\n",
    "        table_number = 1\n",
    "        for index, table in enumerate(tables):\n",
    "            all_rows = list(table.header_rows) + list(table.body_rows)\n",
    "            table_data = [\n",
    "                get_table_data([row], document_object.text)[0] for row in all_rows\n",
    "            ]\n",
    "            df = pd.DataFrame(data=table_data)\n",
    "            table_title = f\"Table {table_number} Page {page_number}\"\n",
    "            df.loc[-1] = [table_title] + [\"\"] * (df.shape[1] - 1)\n",
    "            df.index = df.index + 1\n",
    "            df = df.sort_index()\n",
    "            dfs.append(df)\n",
    "            table_number += 1\n",
    "        page_number += 1\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    all_kvp_data = []\n",
    "    page_number = 1\n",
    "    for page in document_object.pages:\n",
    "        kvp_fields = page.form_fields\n",
    "        if kvp_fields:\n",
    "            kvp_fields_values = get_kvp_data(kvp_fields, document_object.text)\n",
    "            for item in kvp_fields_values.items():\n",
    "                all_kvp_data.append((item[0], item[1], page_number))\n",
    "        page_number += 1\n",
    "    kvp_df = pd.DataFrame(all_kvp_data, columns=[\"Name\", \"Value\", \"Page Number\"])\n",
    "\n",
    "    sheet_name = os.path.splitext(os.path.basename(file_path))[0][:31]\n",
    "    kvp_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    return kvp_df, combined_df, sheet_name\n",
    "\n",
    "\n",
    "def process_other_processor(document_object, writer, file_path):\n",
    "    \"\"\"\n",
    "    Processes entities in the document object for processors other than form parser and writes data to an Excel file.\n",
    "\n",
    "    This function extracts entities from the document object, organizes them into a DataFrame,\n",
    "    and writes this DataFrame to the provided Excel writer. It also generates a sheet name based on the file path.\n",
    "\n",
    "    Args:\n",
    "    - document_object (Any): The Document AI object containing entities and page information.\n",
    "    - writer (pd.ExcelWriter): An Excel writer object used to write data to an Excel file.\n",
    "    - file_path (str): The file path of the blob being processed, used for naming the Excel sheet.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[pd.DataFrame, str]: A tuple containing the sorted DataFrame of entities and the sheet name.\n",
    "    \"\"\"\n",
    "    entities_list = []\n",
    "    for entity in document_object.entities:\n",
    "        page = (\n",
    "            entity.page_anchor.page_refs[0].page if entity.page_anchor.page_refs else 0\n",
    "        )\n",
    "        entities_list.append([entity.type_, entity.mention_text, page])\n",
    "    df = pd.DataFrame(entities_list, columns=[\"Type\", \"MentionText\", \"Page\"])\n",
    "    df[\"Page\"] = df[\"Page\"].astype(int)\n",
    "    df_sorted = df.sort_values(by=\"Page\")\n",
    "\n",
    "    sheet_name = os.path.splitext(os.path.basename(file_path))[0][:31]\n",
    "    df_sorted.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    return df_sorted, sheet_name\n",
    "\n",
    "\n",
    "def process_images(document_object, processor_type, temp_image_files):\n",
    "    \"\"\"\n",
    "    Processes and generates images with annotations (bounding boxes) based on the document object and processor type.\n",
    "\n",
    "    This function iterates through the pages of the document object, generates images from the page content,\n",
    "    and draws bounding boxes around entities or form fields, depending on the processor type.\n",
    "    The generated images are saved to temporary files, and their file names are appended to a list.\n",
    "\n",
    "    Args:\n",
    "    - document_object (Any): The document object containing parsed data and images.\n",
    "    - processor_type (str): Type of processor (\"FORM_PARSER_PROCESSOR\" or others).\n",
    "    - temp_image_files (List[str]): A list to store the file paths of the generated images.\n",
    "\n",
    "    This function does not return anything but updates the temp_image_files list with the paths of generated images.\n",
    "    \"\"\"\n",
    "    colors = [\"red\", \"blue\", \"green\", \"orange\", \"purple\"]\n",
    "    color_idx = 0\n",
    "    border_width = 5\n",
    "    for index, page in enumerate(document_object.pages):\n",
    "        base64_text = page.image.content\n",
    "        image = convert_base64_to_image(base64_text)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        if processor_type == \"FORM_PARSER_PROCESSOR\":\n",
    "            process_form_parser_images(\n",
    "                page, image, draw, colors, color_idx, border_width\n",
    "            )\n",
    "        else:\n",
    "            process_other_processor_images(document_object, index, image, draw)\n",
    "\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as f:\n",
    "            temp_image_filename = f.name\n",
    "            image.save(f, \"PNG\")\n",
    "            temp_image_files.append(temp_image_filename)\n",
    "\n",
    "\n",
    "def process_form_parser_images(page, image, draw, colors, color_idx, border_width):\n",
    "    \"\"\"\n",
    "    Processes a single page from a form parser document and draws bounding boxes for key-value pairs and tables.\n",
    "\n",
    "    This function iterates over the key-value pairs and tables in the provided page, drawing bounding boxes around them.\n",
    "    It uses different colors for different tables for better distinction.\n",
    "\n",
    "    Args:\n",
    "    - page (Any): A single page from the document object containing form fields and tables.\n",
    "    - image (Image): The PIL Image object for the current page.\n",
    "    - draw (ImageDraw.Draw): The drawing context for the PIL Image.\n",
    "    - colors (List[str]): A list of colors used for drawing bounding boxes.\n",
    "    - color_idx (int): The current index in the colors list.\n",
    "    - border_width (int): The width of the border for the bounding boxes.\n",
    "\n",
    "    This function does not return anything but modifies the provided image by drawing bounding boxes on it.\n",
    "    \"\"\"\n",
    "    color = \"black\"\n",
    "    kvp_fields = page.form_fields\n",
    "    if kvp_fields:\n",
    "        for kvp in kvp_fields:\n",
    "            draw_kvp(kvp.field_name, image, draw, color, border_width)\n",
    "            draw_kvp(kvp.field_value, image, draw, color, border_width)\n",
    "\n",
    "    for table in page.tables:\n",
    "        color = colors[color_idx]\n",
    "        color_idx = (color_idx + 1) % len(colors)\n",
    "        for row_type in [\"body_rows\", \"header_rows\"]:\n",
    "            rows = getattr(table, row_type)\n",
    "            for row in rows:\n",
    "                draw_cells(row.cells, image, draw, color, border_width)\n",
    "\n",
    "\n",
    "def process_other_processor_images(document_object, page_index, image, draw):\n",
    "    \"\"\"\n",
    "    Processes a single page from a document processed by a processor other than form parser, drawing bounding boxes around entities.\n",
    "\n",
    "    This function iterates over entities in the document object, checking if they belong to the specified page.\n",
    "    If so, it draws bounding boxes around these entities.\n",
    "\n",
    "    Args:\n",
    "    - document_object (Any): The Document AI object containing entities and page information.\n",
    "    - page_index (int): The index of the current page being processed.\n",
    "    - image (Image): The PIL Image object for the current page.\n",
    "    - draw (ImageDraw.Draw): The drawing context for the PIL Image.\n",
    "\n",
    "    This function does not return anything but modifies the provided image by drawing bounding boxes on it.\n",
    "    \"\"\"\n",
    "    for entity in document_object.entities:\n",
    "        entity_page = (\n",
    "            entity.page_anchor.page_refs[0].page if entity.page_anchor.page_refs else 0\n",
    "        )\n",
    "        if entity_page == page_index:\n",
    "            vertices = [\n",
    "                (v.x, v.y)\n",
    "                for v in entity.page_anchor.page_refs[\n",
    "                    0\n",
    "                ].bounding_poly.normalized_vertices\n",
    "            ]\n",
    "            draw_bounding_box(draw, vertices, image, color=\"blue\")\n",
    "\n",
    "            for prop in entity.properties:\n",
    "                prop_vertices = [\n",
    "                    (v.x, v.y)\n",
    "                    for v in prop.page_anchor.page_refs[\n",
    "                        0\n",
    "                    ].bounding_poly.normalized_vertices\n",
    "                ]\n",
    "                draw_bounding_box(draw, prop_vertices, image)\n",
    "\n",
    "\n",
    "def insert_images_to_excel(writer, temp_image_files, sheet_name):\n",
    "    \"\"\"\n",
    "    Inserts generated images into the specified Excel sheet.\n",
    "\n",
    "    This function iterates over the list of temporary image files and inserts each image into the Excel sheet.\n",
    "    Images are resized before insertion.\n",
    "\n",
    "    Args:\n",
    "    - writer (pd.ExcelWriter): An Excel writer object used to write data to an Excel file.\n",
    "    - temp_image_files (List[str]): A list containing the file paths of generated images.\n",
    "    - sheet_name (str): The name of the sheet in the Excel file where images will be inserted.\n",
    "\n",
    "    This function does not return anything but modifies the Excel sheet by inserting images into it.\n",
    "    \"\"\"\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    image_row = 0\n",
    "    for temp_image_filename in temp_image_files:\n",
    "        worksheet.insert_image(\n",
    "            image_row, 10, temp_image_filename, {\"x_scale\": 0.3, \"y_scale\": 0.3}\n",
    "        )\n",
    "        image_row += 30\n",
    "\n",
    "\n",
    "def generate_data_for_file_combined(\n",
    "    document_object: Any, blob_name: str, writer: pd.ExcelWriter, processor_type: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a document object based on the processor type, writes data to an Excel file,\n",
    "    and inserts annotated images into the file.\n",
    "\n",
    "    This function differentiates between form parser processor and other processors,\n",
    "    processing the document object accordingly. It writes the extracted data to the provided\n",
    "    Excel writer and inserts images with annotations (bounding boxes) relevant to the data.\n",
    "\n",
    "    Args:\n",
    "    - document_object (Any): The document object containing parsed data from the document.\n",
    "    - blob_name (str): The name of the blob (file) being processed.\n",
    "    - writer (pd.ExcelWriter): An Excel writer object for writing data to an Excel file.\n",
    "    - processor_type (str): The type of processor (\"FORM_PARSER_PROCESSOR\" or others).\n",
    "\n",
    "    This function does not return anything but writes data and images to the specified Excel file.\n",
    "    \"\"\"\n",
    "    file_path = blob_name\n",
    "    temp_image_files = []\n",
    "\n",
    "    if processor_type == \"FORM_PARSER_PROCESSOR\":\n",
    "        kvp_df, combined_df, sheet_name = process_form_parser_processor(\n",
    "            document_object, writer, file_path\n",
    "        )\n",
    "    else:\n",
    "        df_sorted, sheet_name = process_other_processor(\n",
    "            document_object, writer, file_path\n",
    "        )\n",
    "\n",
    "    process_images(document_object, processor_type, temp_image_files)\n",
    "\n",
    "    if processor_type == \"FORM_PARSER_PROCESSOR\":\n",
    "        write_form_parser_excel(writer, combined_df, kvp_df, sheet_name)\n",
    "\n",
    "    insert_images_to_excel(writer, temp_image_files, sheet_name)\n",
    "\n",
    "\n",
    "def write_form_parser_excel(writer, combined_df, kvp_df, sheet_name):\n",
    "    \"\"\"\n",
    "    Writes the data from a form parser processor to an Excel sheet and formats the cells.\n",
    "\n",
    "    This function takes the combined DataFrame for tables and the DataFrame for key-value pairs (KVP),\n",
    "    and writes them to the specified Excel sheet. It formats the table headers as bold and adds borders\n",
    "    to the cells. The function also handles the placement of the KVP and table data within the sheet.\n",
    "\n",
    "    Args:\n",
    "    - writer (pd.ExcelWriter): An Excel writer object used for writing data to an Excel file.\n",
    "    - combined_df (pd.DataFrame): The combined DataFrame containing table data.\n",
    "    - kvp_df (pd.DataFrame): The DataFrame containing key-value pair data.\n",
    "    - sheet_name (str): The name of the Excel sheet where data will be written.\n",
    "\n",
    "    This function does not return anything but modifies the Excel sheet by writing and formatting data.\n",
    "    \"\"\"\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    start_row = len(kvp_df) + 2 if not kvp_df.empty else 0\n",
    "    combined_df.to_excel(\n",
    "        writer, sheet_name=sheet_name, startrow=start_row, index=False, header=False\n",
    "    )\n",
    "\n",
    "    row_num = start_row\n",
    "    for idx, row in combined_df.iterrows():\n",
    "        if \"Table\" in str(row[0]):\n",
    "            worksheet.write(row_num, 0, row[0], workbook.add_format({\"bold\": True}))\n",
    "            row_num += 1\n",
    "        else:\n",
    "            for col_num, cell_value in enumerate(row):\n",
    "                if pd.notna(cell_value):\n",
    "                    worksheet.write(\n",
    "                        row_num, col_num, cell_value, workbook.add_format({\"border\": 1})\n",
    "                    )\n",
    "            row_num += 1\n",
    "\n",
    "\n",
    "def generate_parser_viz_for_folder(bucket_path, processor_type):\n",
    "    \"\"\"\n",
    "    Processes files in a specified Google Cloud Storage bucket and generates an Excel report.\n",
    "    The function handles files based on the provided processor type, applying different processing\n",
    "    logic for form parsers and other types of processors. It creates visualizations for parsed\n",
    "    document data and incorporates them into the generated Excel report.\n",
    "\n",
    "    Args:\n",
    "    - bucket_path (str): The Google Cloud Storage bucket path where the files are stored.\n",
    "    - processor_type (str): The type of processor used for document parsing,\n",
    "                            such as 'FORM_PARSER_PROCESSOR'.\n",
    "    \"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    # Parsing bucket name and prefix from the bucket path\n",
    "    if bucket_path.startswith(\"gs://\"):\n",
    "        bucket_path = bucket_path[5:]\n",
    "    bucket_name, prefix = bucket_path.split(\"/\", 1)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    with pd.ExcelWriter(f\"{processor_type}_report.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "        for blob in bucket.list_blobs(prefix=prefix):\n",
    "            try:\n",
    "                if blob.name.endswith(\".json\"):\n",
    "                    file_content = blob.download_as_text()\n",
    "                    json_data = json.loads(file_content)\n",
    "                    document_object = documentai_v1beta3.Document.from_json(\n",
    "                        json.dumps(json_data)\n",
    "                    )\n",
    "                    generate_data_for_file_combined(\n",
    "                        document_object, blob.name, writer, processor_type\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(f\"Skipped - {blob.name}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "processor_display_name, processor_type = get_processor_type(project_id, processor_id)\n",
    "current_time = time.strftime(\"%Y%m%d%H%M%S\")\n",
    "folder_path = f\"gs://{bucket_name}/{processor_display_name}_{current_time}\"\n",
    "xlsx_file_name = f\"{processor_display_name}_{current_time}.xlsx\"\n",
    "print(\n",
    "    f\"Batch Processing the Documents with the {processor_display_name} - {processor_type}\"\n",
    ")\n",
    "res = utilities.batch_process_documents_sample(\n",
    "    project_id=project_id,\n",
    "    location=\"us\",\n",
    "    processor_id=processor_id,\n",
    "    gcs_input_uri=input_pdfs_path,\n",
    "    gcs_output_uri=f\"{folder_path}/batch_process_outputs\",  # Concatenating the prefix here\n",
    ")\n",
    "print(\"Batch Process Completed\")\n",
    "try:\n",
    "    if processor_type == \"FORM_PARSER_PROCESSOR\":\n",
    "        print(\n",
    "            f\"{processor_type} Detected \\nVisualizing the key-value pairs and the table structures\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{processor_type} Detected \\nVisualizing the entities\")\n",
    "    generate_parser_viz_for_folder(folder_path, processor_type)\n",
    "    print(\n",
    "        f\"Report is generated. Please find the Visualization in {processor_type}_report.xlsx\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "\n",
    "    # Print an error message\n",
    "    print(\"Issue occurred. Please check the input field and JSON\")\n",
    "    # Print the traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7b4983c-ca22-4fa9-aee8-33eca9a3aa87",
   "metadata": {},
   "source": [
    "### Visualization Output  \n",
    "\n",
    "<img src=\"./images/invoice_out.png\" width=1000 height=800> </img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35819ee1-d756-476c-8e27-50ef446e30c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
