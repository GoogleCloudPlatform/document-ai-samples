{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260f33cb-4ce6-4b68-be35-c4684b98740e",
   "metadata": {},
   "source": [
    "# DocAI Preparing and Exporting labeled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddcb487-75fd-4354-85ca-aa24e3112772",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b843197-544c-493b-b083-327e1b64c7e0",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the **DocAI Incubator Team**. No guarantees of performance are implied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dbf937-9728-4d8d-a364-263a50047cd0",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "The labeled documents that are exported from a Document AI processor are saved in individual parent folders. The purpose of the python code is used to generate a CSV file that maps the labeled documents with its parent folder name. The first column of the generated CSV file contains the name of the parent folder, while the second column lists the files present within that parent folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6745e1c-2f61-40ef-9489-1af23d33a86e",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "* A basic knowledge of Python.       \n",
    "* Python : Jupyter notebook - Vertex AI        \n",
    "* Permission to Google project is needed to access the files and to [Document AI](https://cloud.google.com/document-ai/docs/overview)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32e997-33b4-4639-9e24-628a227d5ab6",
   "metadata": {},
   "source": [
    "## Steps to prepare labeled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105a19a3-ad82-42bf-be7f-db1f51e9a9a6",
   "metadata": {},
   "source": [
    "### 1. Create Processor\n",
    "\n",
    "* Create a DocAI Processor as per your requirement.\n",
    "* Further read:[Creating and managing processors](https://cloud.google.com/document-ai/docs/create-processor#create-processor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082199f6-8a79-4f52-b02f-164906935bea",
   "metadata": {},
   "source": [
    "<img src=\"./Images/create_processor.png\" width=800 height=400></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cfc301-0764-405f-975b-1592362b0972",
   "metadata": {},
   "source": [
    "### 2. Dataset Location\n",
    "\n",
    "Once the processor is created, set the dataset location in the train tab. The location of the dataset folder must be empty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7041cd2a-21d3-440a-b385-6278d0217245",
   "metadata": {},
   "source": [
    "<img src=\"./Images/create_dataset.png\" width=800 height=400></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9714f213-0226-4256-b5da-480335548bc5",
   "metadata": {},
   "source": [
    "### 3. Import Dataset\n",
    "Import the PDF files which needs to be labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb37d8a8-2cfb-4045-9f9e-2b9fc836f0e1",
   "metadata": {},
   "source": [
    "<img src=\"./Images/import_documents_1.png\" width=800 height=400></img>\n",
    "<img src=\"./Images/import_documents_2.png\" width=800 height=400></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3987b0-36be-4850-b6ce-60994befbc13",
   "metadata": {},
   "source": [
    "### 4. Add Schema\n",
    "\n",
    "Click on the button “Edit Schema” and add the required entities that need to be labeled in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35460e47-ec75-46d1-8fcd-255e2b8d0b7c",
   "metadata": {},
   "source": [
    "<img src=\"./Images/edit_schema.png\" width=800 height=400></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b10461-276d-4904-a133-616b227aeaea",
   "metadata": {},
   "source": [
    "<img src=\"./Images/edit_schema_1.png\" width=800 height=400></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22680058-8797-4f07-ad0a-e67da66f66c0",
   "metadata": {},
   "source": [
    "### 5. Label the dataset\n",
    "Label the entities and click on the button “Mark as labeled”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48523746-8b70-419d-b09d-f04f5932cc5a",
   "metadata": {},
   "source": [
    "<img src=\"./Images/labeled_data.png\" width=800 height=400></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a499b82a-4cff-4b95-9adf-1f76eee98bb9",
   "metadata": {},
   "source": [
    "### 6. Export the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fba7f6-7874-4902-ac04-f21c5a9ba80f",
   "metadata": {},
   "source": [
    "<img src=\"./Images/export_dataset.png\" width=800 height=400></img>\n",
    "\n",
    "#### The dataset that has been exported is stored in individual folders, as shown below.\n",
    "\n",
    "\n",
    "<img src=\"./Images/individual_folders.png\" width=800 height=400></img>\n",
    "\n",
    "* **Note**: Once the dataset is exported, each labeled JSON file is stored in an individual folder with a unique, randomly generated name. Therefore, please follow the next steps to map the folder name with the file name and move all the files from the individual folder to a single folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954c76e-611d-49b3-a034-82a3393b570d",
   "metadata": {},
   "source": [
    "### 7. Run the code\n",
    "\n",
    "### Code to map the folder name\n",
    "\n",
    "Replace the parameters for  `project_id`, `bucket_name`, `folder_name` with your actual project ID, bucket name and folder name.\n",
    "* `project_id`: provide the project id\n",
    "* `bucket_name`: provide the name of the bucket\n",
    "* `folder_name`:  provide the name of the folder path without prefixing the bucket name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27005ef1-ace5-49c1-a2fb-1d551dbcdd36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from google.cloud import storage\n",
    "\n",
    "# Modify the below parameters as per your requirements\n",
    "project_id = \"<your-project-name>\"\n",
    "bucket_name = \"<your-bucket-name>\"\n",
    "folder_name = \"<your-folder-name>\"\n",
    "\n",
    "storage_client = storage.Client(project=project_id)\n",
    "blobs = storage_client.list_blobs(bucket_name, prefix=folder_name)\n",
    "csv_file = open(\"report.csv\", \"w\", newline=\"\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"Folder Name\", \"File Name\"])\n",
    "\n",
    "for blob in blobs:\n",
    "    parent_folder = blob.name.split(\"/\")[-2]\n",
    "    file_name = blob.name.split(\"/\")[-1]\n",
    "    csv_writer.writerow([parent_folder, file_name])\n",
    "\n",
    "csv_file.close()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0373fba6-1c26-4c05-9f63-eebea4d16657",
   "metadata": {},
   "source": [
    "The above code generates a CSV file containing the name of the parent folder, while the second column lists the files present within that parent folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d81c3-15fc-4532-8e49-e54b0012f6a7",
   "metadata": {},
   "source": [
    "### 8. Command to copy files from multiple subfolders into a single folder\n",
    "\n",
    "The following gsutil command is utilized to copy files from various subfolders into a single folder. \n",
    "\n",
    "Please change `<source-folder>` and `<destination-folder>` and run in a cloud shell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd90653-d195-4b35-8955-c032f8e406cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsutil -m cp gs://<source-folder>/*/*.json gs://<destination-folder>"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
