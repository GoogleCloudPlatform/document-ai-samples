{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72fd064f-24f5-4d61-b0ad-2b2f3fe9427d",
   "metadata": {},
   "source": [
    "# OCR Confidence Score Calculation Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5756f1a-631f-4c8a-bba0-98c6821d31a9",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1d12ef-55dd-4fbd-8389-db14ed038eb1",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the DocAI Incubator Team. No guarantees of performance are implied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94527514-1ae2-470b-96e2-0f48e4aa5e81",
   "metadata": {},
   "source": [
    "## Purpose and Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf4462a-fc0d-477f-9c39-4fec383ba4ca",
   "metadata": {},
   "source": [
    "The objective of this tool is to get the confidence score of individual tokens and then compare it with the text segments of the entities. By doing this, the tool aims to identify the minimum OCR confidence among these comparisons. \n",
    "The tool associates the lowest confidence value with the respective entity. This resulting confidence value is stored as the \"ocr_confidence_score.\" Every entity, including both parent and child entities, it possess its own OCR confidence score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8783f52-627b-4efa-b5d9-664ae2ca2564",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Vertex AI Notebook\n",
    "2. Input Json Files\n",
    "3. GCS bucket for processing of  the input json and writing the output.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc5540-deb1-4449-8278-716488c54e5c",
   "metadata": {},
   "source": [
    "## Step by Step procedure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f5b2d-f7fd-4403-a175-b95cc804f6ba",
   "metadata": {},
   "source": [
    "### 1. Input details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d9fe7-26fe-42b5-8898-bcff7dd4c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-cloud-storage\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef3a7a-e8ea-4045-8f54-ffe5dd4c4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89120af5-c5f4-4897-a640-4ad9c5ce4739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tqdm\n",
    "from google.cloud import storage\n",
    "\n",
    "# Replace with your Google Cloud Storage bucket and folder paths\n",
    "source_bucket_name = \"<input_bucket_name>\"\n",
    "source_folder_path = \"<folder_path_without_bucket_name>\"  # Folder containing jsons\n",
    "destination_bucket_name = \"<ouput_bucket_name>\"\n",
    "destination_folder_path = \"<folder_path_without_bucket_name>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84356940-95a8-4489-bfc3-b85611f9558a",
   "metadata": {},
   "source": [
    "### 2. Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bbd310-8401-4e1c-aacc-f7ddf04e47e7",
   "metadata": {},
   "source": [
    "<img src=\"./Images/ocr_confidence_output_1.png\" width=800 height=400 alt=\"Entity confidence output image\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875bf6af-61ef-4875-b921-edfa3c5156f6",
   "metadata": {},
   "source": [
    "<img src=\"./Images/ocr_confidence_output_2.png\" width=800 height=400 alt=\"Child Entity confidence output image\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fa4328-3d99-4de4-a5eb-0f2033d78b79",
   "metadata": {},
   "source": [
    "### 3. Run the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf3f2d-f882-4461-b52b-9df0ad0e340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_range(jsonData: dict):\n",
    "    \"\"\"To get the token range from the json content.\n",
    "\n",
    "    Args:\n",
    "        jsonData: The document converted into json format.\n",
    "\n",
    "    Returns:\n",
    "        The token range of the tokens from the OCR data (start index, end index) hash map.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenRange = {}\n",
    "    for i in range(0, len(jsonData[\"pages\"])):\n",
    "        for j in range(0, len(jsonData[\"pages\"][i][\"tokens\"])):\n",
    "            pageNumber = i\n",
    "            tokenNumber = j\n",
    "            try:\n",
    "                startIndex = int(\n",
    "                    jsonData[\"pages\"][i][\"tokens\"][j][\"layout\"][\"textAnchor\"][\n",
    "                        \"textSegments\"\n",
    "                    ][0][\"startIndex\"]\n",
    "                )\n",
    "            except:\n",
    "                startIndex = 0\n",
    "            endIndex = int(\n",
    "                jsonData[\"pages\"][i][\"tokens\"][j][\"layout\"][\"textAnchor\"][\n",
    "                    \"textSegments\"\n",
    "                ][0][\"endIndex\"]\n",
    "            )\n",
    "            confidence = jsonData[\"pages\"][i][\"tokens\"][j][\"layout\"][\"confidence\"]\n",
    "            full_text = jsonData[\"text\"]\n",
    "            text_in_range = full_text[startIndex : endIndex + 1]\n",
    "            tokenRange[range(startIndex, endIndex)] = {\n",
    "                \"token_text\": text_in_range,\n",
    "                \"confidence\": confidence,\n",
    "            }\n",
    "    return tokenRange\n",
    "\n",
    "\n",
    "def find_min_confidence(token_ranges: dict, start_end_indices: list):\n",
    "    \"\"\"To get the minimum confidence score of tokens.\n",
    "\n",
    "    Args:\n",
    "        token_ranges: The start_index and the end_index as the dictonary.\n",
    "        start_end_indices :\n",
    "\n",
    "    Returns:\n",
    "        The token range of the tokens from the OCR data (start index, end index) hash map.\n",
    "    \"\"\"\n",
    "\n",
    "    min_confidence = float(\"inf\")\n",
    "\n",
    "    for start, end in start_end_indices:\n",
    "        for rng, info in token_ranges.items():\n",
    "            if rng.start < int(end) and rng.stop > int(start):\n",
    "                intersection_start = max(rng.start, int(start))\n",
    "                intersection_end = min(rng.stop, int(end))\n",
    "                min_confidence = min(min_confidence, info[\"confidence\"])\n",
    "    return min_confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c2216-4282-4433-9a74-cd503d874dad",
   "metadata": {},
   "source": [
    "### 4. Run the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb1c938-a960-4009-a480-e7a97b5dce33",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f5f569\"><b>NOTE:</b> Please note that you can change the default confidence score generated by the processor by changing the \"ocr_confidence_score\" to \"confidence\".</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c791be-7b0e-4339-93f1-60fbccf3667b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Google Cloud Storage client\n",
    "client = storage.Client()\n",
    "\n",
    "# List all JSON files in the source folder\n",
    "source_bucket = client.get_bucket(source_bucket_name)\n",
    "blobs = source_bucket.list_blobs(prefix=source_folder_path)\n",
    "json_files = [blob.name for blob in blobs if blob.name.endswith(\".json\")]\n",
    "\n",
    "# Process each JSON file\n",
    "for json_file_path in json_files:\n",
    "    blob = source_bucket.blob(json_file_path)\n",
    "    json_data = json.loads(blob.download_as_text())\n",
    "\n",
    "    text_data = json_data[\"text\"]\n",
    "    entities = json_data[\"entities\"]\n",
    "    token_ranges = get_token_range(json_data)\n",
    "\n",
    "    # Iterate through entities\n",
    "    for entity in entities:\n",
    "        try:\n",
    "            text_segments = entity[\"textAnchor\"][\"textSegments\"]\n",
    "            segment_indices = [\n",
    "                (text_segment[\"startIndex\"], text_segment[\"endIndex\"])\n",
    "                for text_segment in text_segments\n",
    "            ]\n",
    "            min_confidence = find_min_confidence(token_ranges, segment_indices)\n",
    "            entity[\"ocr_confidence_score\"] = min_confidence\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            lt_props = entity[\"properties\"]\n",
    "            for lt in lt_props:\n",
    "                lt_text_segments = lt[\"textAnchor\"][\"textSegments\"]\n",
    "                segment_indices = [\n",
    "                    (text_segment[\"startIndex\"], text_segment[\"endIndex\"])\n",
    "                    for text_segment in lt_text_segments\n",
    "                ]\n",
    "                min_confidence = find_min_confidence(token_ranges, segment_indices)\n",
    "                lt[\"ocr_confidence_score\"] = min_confidence\n",
    "        except KeyError:\n",
    "            pass\n",
    "    # Save modified JSON with added confidence scores\n",
    "    output_filename = json_file_path.replace(\n",
    "        source_folder_path, destination_folder_path\n",
    "    )\n",
    "    output_blob = client.bucket(destination_bucket_name).blob(output_filename)\n",
    "    output_blob.upload_from_string(\n",
    "        json.dumps(json_data, ensure_ascii=False).encode(\"utf-8\"),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    "    print(f\"Done: {output_filename}\")\n",
    "print(\"Completed\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m104"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
