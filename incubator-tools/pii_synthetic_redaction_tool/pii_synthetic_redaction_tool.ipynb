{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6589fc93-39d1-4d10-be1f-e7eb33fe4087",
   "metadata": {},
   "source": [
    "# PII Redaction with Synthetic Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf22bf7-4a47-4f3a-9eef-6f19348a5250",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f188e-fe11-4a49-b7c8-080e0e69ce7a",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the DocAI Incubator Team. No guarantees of performance are implied. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1036937a-0221-48eb-862e-3fa0b8e646a8",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This document guides to replace the PII data with synthetic data using parsed jsons and entity types to be redacted as input and gives a pdf document with synthetic data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a4e82-5e83-468a-b0e5-097ca14f15d5",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* Vertex AI Notebook Or Colab (If using Colab, use authentication)\n",
    "* Storage Bucket for storing input and output json files\n",
    "* Permission For Google Storage and Vertex AI Notebook.\n",
    "* Excel file which contains Synthetic data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81de40-5c62-4c0b-adea-937f957b1a6e",
   "metadata": {},
   "source": [
    "## Step by Step procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142123d3-37b1-4aa8-841c-40c3bd52d70c",
   "metadata": {},
   "source": [
    "### 1. Importing Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f546d2-b3be-4e97-8099-bf5e3db067c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy google-cloud-storage google-cloud-documentai==2.16.0 PyPDF2 configparser\n",
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e03bc5-ab41-4521-96ab-c32a07d2f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from typing import (\n",
    "    Container,\n",
    "    Iterable,\n",
    "    Iterator,\n",
    "    List,\n",
    "    Mapping,\n",
    "    Optional,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    Union,\n",
    ")\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy\n",
    "import cv2\n",
    "from utilities import *\n",
    "from typing import Tuple, List, Dict, Union, Any\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c8c4c-68b8-413c-b4bc-c66f044d3b7a",
   "metadata": {},
   "source": [
    "### 2. Input and Output Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d9b3ca3-e486-4614-81c2-da8e1f695666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input details\n",
    "gcs_input_path = \"gs://test_vb1/translation_14th_sep/english_jsons_1/\"  # GCS path where doc ai parsed files saved\n",
    "gcs_output_path = (\n",
    "    \"gs://test_vb1/synthetic_data_feb20/\"  # GCS path to save the redacted pdfs\n",
    ")\n",
    "pii_entities = [\n",
    "    \"receiver_address\",\n",
    "    \"receiver_email\",\n",
    "    \"receiver_name\",\n",
    "    \"receiver_phone\",\n",
    "    \"receiver_tax_id\",\n",
    "    \"receiver_website\",\n",
    "    \"remit_to_address\",\n",
    "    \"remit_to_name\",\n",
    "    \"ship_from_address\",\n",
    "    \"ship_from_name\",\n",
    "    \"ship_to_address\",\n",
    "    \"ship_to_name\",\n",
    "    \"supplier_address\",\n",
    "    \"supplier_email\",\n",
    "    \"supplier_iban\",\n",
    "    \"supplier_name\",\n",
    "    \"supplier_payment_ref\",\n",
    "    \"supplier_phone\",\n",
    "    \"supplier_registration\",\n",
    "    \"supplier_tax_id\",\n",
    "    \"supplier_website\",\n",
    "]  # List of entities to be redacted ,sample given\n",
    "redact_text = [\n",
    "    \"Machine translated by google\"\n",
    "]  # only to redact the text and cannot be replaced with any synthetic data , sample given, change the data\n",
    "\n",
    "synthetic_data_path = \"ACN Synthetic Data .xlsx\"  # synthetic data path in xlsx format\n",
    "sheet_name = \"data\"  # sheet name where the synthetic data is present\n",
    "\n",
    "redact_only = False  # Change this Flag to `True` to Only Redact the entities with Black Bounding boxes without any Synthetic values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d4909-e00c-4704-a43b-6534f7403872",
   "metadata": {},
   "source": [
    "**`gcs_input_path`** : GCS Input Path. It should contain DocAI processed output json files.        \n",
    "**`gcs_output_path`** : GCS Output Path. The updated synthesized data in the pdf.         \n",
    "**`project_id`** : It should contains the project id of your current project.         \n",
    "**`pii_entities`** : Entities for which the mentiontext has to be redacted and replaced with synthetic data given in the excel     \n",
    "**`redact_text`** : Redacting text with text as input                 \n",
    "**`synthetic_data_path`** : xlsx file which has synthetic data , column names matching entity type and corresponding values having synthetic data like below.          \n",
    "**`sheet_name`** : Sheet name where the synthetic data is present         \n",
    "**Synthetic data will be chosen randomly.    \n",
    "\n",
    "\n",
    "<img src=\"./Images/synthetic_data.png\" width=800 height=400></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737d1c70-fef5-49e3-a266-695bf8076a54",
   "metadata": {},
   "source": [
    "### 3. Run the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22bfdd-abdc-4d1c-8f7c-86164e7c4103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "\n",
    "def get_page_bbox(entity: documentai.Document.Entity) -> Tuple[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Extract the page number and bounding box from a given Document AI entity.\n",
    "\n",
    "    Args:\n",
    "        entity (documentai.Document.Entity): The Document AI entity.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, List[float]]: A tuple containing the page number and bounding box [min_x, min_y, max_x, max_y].\n",
    "    \"\"\"\n",
    "    bound_poly = entity.page_anchor.page_refs\n",
    "    norm_ver = bound_poly[0].bounding_poly.normalized_vertices\n",
    "    x_1 = []\n",
    "    y_1 = []\n",
    "    for xy in norm_ver:\n",
    "        x_1.append(xy.x)\n",
    "        y_1.append(xy.y)\n",
    "    bbox = [min(x_1), min(y_1), max(x_1), max(y_1)]\n",
    "    try:\n",
    "        page = bound_poly[0].bounding_poly.page\n",
    "    except:\n",
    "        page = \"0\"\n",
    "\n",
    "    return page, bbox\n",
    "\n",
    "\n",
    "def get_bbox_page_wise(\n",
    "    json_data: documentai.Document, pii_entities: List[str]\n",
    ") -> Dict[str, List[List[Union[float, str]]]]:\n",
    "    \"\"\"\n",
    "    Extract page-wise bounding boxes of specified PII entities from Document AI output.\n",
    "\n",
    "    Args:\n",
    "        json_data (documentai.Document): The Document AI output.\n",
    "        pii_entities (List[str]): List of PII entities to extract.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[List[Union[float, str]]]]: A dictionary containing page-wise bounding boxes of PII entities.\n",
    "    \"\"\"\n",
    "    page_wise_bbox = {}\n",
    "    entity_wise_bbox = {}\n",
    "    for pii_ent in pii_entities:\n",
    "        for entity in json_data.entities:\n",
    "            if \"/\" not in pii_ent:\n",
    "                if entity.type_ == pii_ent:\n",
    "                    page, bbox = get_page_bbox(entity)\n",
    "                    if page in page_wise_bbox.keys():\n",
    "                        page_wise_bbox[page].append(bbox)\n",
    "                        if entity.type in entity_wise_bbox.keys():\n",
    "                            entity_wise_bbox[entity.type].append(\n",
    "                                {\n",
    "                                    \"page\": page,\n",
    "                                    \"bbox\": bbox,\n",
    "                                    \"old_text\": entity.mention_text,\n",
    "                                }\n",
    "                            )\n",
    "                        else:\n",
    "                            entity_wise_bbox[entity.type] = [\n",
    "                                {\n",
    "                                    \"page\": page,\n",
    "                                    \"bbox\": bbox,\n",
    "                                    \"old_text\": entity.mention_text,\n",
    "                                }\n",
    "                            ]\n",
    "                    else:\n",
    "                        page_wise_bbox[page] = [bbox]\n",
    "                        if entity.type in entity_wise_bbox.keys():\n",
    "                            entity_wise_bbox[entity.type].append(\n",
    "                                {\n",
    "                                    \"page\": page,\n",
    "                                    \"bbox\": bbox,\n",
    "                                    \"old_text\": entity.mention_text,\n",
    "                                }\n",
    "                            )\n",
    "                        else:\n",
    "                            entity_wise_bbox[entity.type] = [\n",
    "                                {\n",
    "                                    \"page\": page,\n",
    "                                    \"bbox\": bbox,\n",
    "                                    \"old_text\": entity.mention_text,\n",
    "                                }\n",
    "                            ]\n",
    "            else:\n",
    "                parent_name = pii_ent.split(\"/\")[0]\n",
    "                if entity.properties:\n",
    "                    if entity.type_ == parent_name:\n",
    "                        for sub_ent in entity.properties:\n",
    "                            if (\n",
    "                                sub_ent.type_ == pii_ent.split(\"/\")[-1]\n",
    "                                or sub_ent.type_ == pii_ent\n",
    "                            ):\n",
    "                                page, bbox = get_page_bbox(sub_ent)\n",
    "                                if page in page_wise_bbox.keys():\n",
    "                                    page_wise_bbox[page].append(bbox)\n",
    "                                    if sub_ent.type in entity_wise_bbox.keys():\n",
    "                                        entity_wise_bbox[sub_ent.type].append(\n",
    "                                            {\n",
    "                                                \"page\": page,\n",
    "                                                \"bbox\": bbox,\n",
    "                                                \"old_text\": sub_ent.mention_text,\n",
    "                                            }\n",
    "                                        )\n",
    "                                    else:\n",
    "                                        entity_wise_bbox[sub_ent.type] = [\n",
    "                                            {\n",
    "                                                \"page\": page,\n",
    "                                                \"bbox\": bbox,\n",
    "                                                \"old_text\": sub_ent.mention_text,\n",
    "                                            }\n",
    "                                        ]\n",
    "                                else:\n",
    "                                    page_wise_bbox[page] = [bbox]\n",
    "                                    if sub_ent.type in entity_wise_bbox.keys():\n",
    "                                        entity_wise_bbox[sub_ent.type].append(\n",
    "                                            {\n",
    "                                                \"page\": page,\n",
    "                                                \"bbox\": bbox,\n",
    "                                                \"old_text\": sub_ent.mention_text,\n",
    "                                            }\n",
    "                                        )\n",
    "                                    else:\n",
    "                                        entity_wise_bbox[sub_ent.type] = [\n",
    "                                            {\n",
    "                                                \"page\": page,\n",
    "                                                \"bbox\": bbox,\n",
    "                                                \"old_text\": sub_ent.mention_text,\n",
    "                                            }\n",
    "                                        ]\n",
    "    return page_wise_bbox, entity_wise_bbox\n",
    "\n",
    "\n",
    "def get_synthesized_images(json_data: documentai.Document) -> List[Image.Image]:\n",
    "    \"\"\"\n",
    "    Convert JSON data representing images into a list of PIL Image objects.\n",
    "\n",
    "    Args:\n",
    "        json_data (documentai.Document): The Document AI output containing image data.\n",
    "\n",
    "    Returns:\n",
    "        List[Image.Image]: A list of PIL Image objects.\n",
    "    \"\"\"\n",
    "    synthesized_images = []\n",
    "\n",
    "    def decode_image(image_bytes: bytes) -> Image.Image:\n",
    "        with io.BytesIO(image_bytes) as image_file:\n",
    "            image = Image.open(image_file)\n",
    "            image.load()\n",
    "        return image\n",
    "\n",
    "    for i in range(len(json_data.pages)):\n",
    "        synthesized_images.append(decode_image(json_data.pages[i].image.content))\n",
    "\n",
    "    return synthesized_images\n",
    "\n",
    "\n",
    "def add_synthetic_data(entity_bbox, synthesize_data, open_cv_image, bbox_synthesize):\n",
    "    import random\n",
    "\n",
    "    for en_name, coords in entity_bbox.items():\n",
    "        for bb2 in coords:\n",
    "            if (\n",
    "                bbox_synthesize[\"page\"] == bb2[\"page\"]\n",
    "                and bbox_synthesize[\"bbox\"] == bb2[\"bbox\"]\n",
    "            ):\n",
    "                x1 = bbox_synthesize[\"bbox\"][0]\n",
    "                y1 = bbox_synthesize[\"bbox\"][1]\n",
    "                x2 = bbox_synthesize[\"bbox\"][2]\n",
    "                y2 = bbox_synthesize[\"bbox\"][3]\n",
    "\n",
    "                if en_name in synthesize_data.keys():\n",
    "                    synthesize_text = random.choice(synthesize_data[en_name])\n",
    "\n",
    "                    if \"\\n\" in bb2[\"old_text\"]:\n",
    "                        length = len(synthesize_text)\n",
    "                        num_parts = bb2[\"old_text\"].count(\"\\n\") + 1\n",
    "                        part_size = length // num_parts\n",
    "                        parts = [\n",
    "                            synthesize_text[i * part_size : (i + 1) * part_size]\n",
    "                            for i in range(num_parts)\n",
    "                        ]\n",
    "                    else:\n",
    "                        parts = [synthesize_text]\n",
    "\n",
    "                    bbox_width = x2 - x1\n",
    "                    bbox_height = y2 - y1\n",
    "                    font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "                    font_thickness = 1\n",
    "                    font_color = (0, 0, 0)\n",
    "                    line_spacing_factor = 1.2  # You can adjust this value based on your desired line spacing\n",
    "\n",
    "                    for i, part in enumerate(parts):\n",
    "                        font_scale = min(bbox_width, bbox_height) / len(str(part))\n",
    "\n",
    "                        # Get the size of the text bounding box\n",
    "                        text_size, _ = cv2.getTextSize(\n",
    "                            str(part), font, font_scale, font_thickness\n",
    "                        )\n",
    "\n",
    "                        # Calculate the position to center the text within the bounding box\n",
    "                        text_x = x1 + (bbox_width - text_size[0]) // 2\n",
    "                        text_y = (\n",
    "                            y1\n",
    "                            + (bbox_height + text_size[1]) // 2\n",
    "                            + i * int(line_spacing_factor * text_size[1])\n",
    "                        )\n",
    "\n",
    "                        text_size, baseline = cv2.getTextSize(\n",
    "                            str(part), font, font_scale, font_thickness\n",
    "                        )\n",
    "\n",
    "                        while text_size[0] > (x2 - x1) or text_size[1] > (y2 - y1):\n",
    "                            font_scale -= 0.01\n",
    "                            text_size, baseline = cv2.getTextSize(\n",
    "                                str(part), font, font_scale, font_thickness\n",
    "                            )\n",
    "                        if font_scale < 0.5:\n",
    "                            font_scale = 0.5\n",
    "                        # Calculate the position to center the text within the bounding box\n",
    "                        text_x = x1 + (x2 - x1 - text_size[0]) // 2\n",
    "                        text_y = (\n",
    "                            y1\n",
    "                            + (y2 - y1 + text_size[1]) // 2\n",
    "                            + i * int(line_spacing_factor * text_size[1])\n",
    "                        )\n",
    "\n",
    "                        # Draw the new text on the image with the adjusted font size\n",
    "                        cv2.putText(\n",
    "                            open_cv_image,\n",
    "                            str(part),\n",
    "                            (text_x, text_y),\n",
    "                            font,\n",
    "                            font_scale,\n",
    "                            font_color,\n",
    "                            font_thickness,\n",
    "                            cv2.LINE_AA,\n",
    "                        )\n",
    "\n",
    "    return open_cv_image\n",
    "\n",
    "\n",
    "def draw_black_box(\n",
    "    synthesized_images: List[Image.Image],\n",
    "    page_wise_bbox: Dict[str, List[List[float]]],\n",
    "    entity_wise_bbox: Dict[str, List[Dict[str, Any]]],\n",
    "    synthesize_data: Dict[str, List[str]],\n",
    "    redact_only: bool = False,  # New parameter to control behavior\n",
    ") -> io.BytesIO:\n",
    "    \"\"\"\n",
    "    Draw black or white boxes for PII entities and optionally add synthetic data within those boxes.\n",
    "\n",
    "    Parameters:\n",
    "        synthesized_images (List[Image.Image]): List of synthesized images.\n",
    "        page_wise_bbox (Dict[str, List[List[float]]]): Dictionary containing page-wise bounding boxes.\n",
    "        entity_wise_bbox (Dict[str, List[Dict[str, Any]]]): Dictionary containing entity-wise bounding boxes.\n",
    "        synthesize_data (Dict[str, List[str]]): Dictionary containing synthetic data for each entity.\n",
    "        redact_only (bool): If True, redact entities with a black box; otherwise, add synthetic data.\n",
    "\n",
    "    Returns:\n",
    "        io.BytesIO: PDF stream containing the images with boxes and optionally synthetic data.\n",
    "    \"\"\"\n",
    "    open_cv_image = {}\n",
    "    for i in range(len(synthesized_images)):\n",
    "        open_cv_image[i] = numpy.array(synthesized_images[i].convert(\"RGB\"))\n",
    "    img_final = []\n",
    "    for i in range(len(open_cv_image)):\n",
    "        size = open_cv_image[i].shape\n",
    "        for page, bbox_list in page_wise_bbox.items():\n",
    "            if str(i) == page:\n",
    "                for bbox in bbox_list:\n",
    "                    x1 = int(bbox[0] * size[1])\n",
    "                    y1 = int(bbox[1] * size[0])\n",
    "                    x2 = int(bbox[2] * size[1])\n",
    "                    y2 = int(bbox[3] * size[0])\n",
    "                    if redact_only:\n",
    "                        # Draw a black box for redaction\n",
    "                        cv2.rectangle(\n",
    "                            open_cv_image[i],\n",
    "                            (x1, y1),\n",
    "                            (x2, y2),\n",
    "                            (0, 0, 0),\n",
    "                            thickness=cv2.FILLED,\n",
    "                        )\n",
    "                    else:\n",
    "                        # Draw a white box and add synthetic data\n",
    "                        cv2.rectangle(\n",
    "                            open_cv_image[i],\n",
    "                            (x1, y1),\n",
    "                            (x2, y2),\n",
    "                            (255, 255, 255),\n",
    "                            thickness=cv2.FILLED,\n",
    "                        )\n",
    "                        bbox_synthesize = {\"page\": page, \"bbox\": [x1, y1, x2, y2]}\n",
    "                        open_cv_image[i] = add_synthetic_data(\n",
    "                            entity_wise_bbox,\n",
    "                            synthesize_data,\n",
    "                            open_cv_image[i],\n",
    "                            bbox_synthesize,\n",
    "                        )\n",
    "        img_temp = Image.fromarray(open_cv_image[i])\n",
    "        img_final.append(img_temp)\n",
    "\n",
    "    pdf_stream = io.BytesIO()\n",
    "    img_final[0].save(\n",
    "        pdf_stream,\n",
    "        save_all=True,\n",
    "        append_images=img_final[1:],\n",
    "        resolution=100.0,\n",
    "        quality=95,\n",
    "        optimize=True,\n",
    "        format=\"PDF\",\n",
    "    )\n",
    "\n",
    "    return pdf_stream\n",
    "\n",
    "\n",
    "def store_blob(pdf_stream, output_path, file_name):\n",
    "    \"\"\"\n",
    "    Store files in cloud storage.\n",
    "    \"\"\"\n",
    "    from google.cloud import storage\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    path_ = output_path.split(\"/\")\n",
    "    result_bucket = storage_client.bucket(path_[2])\n",
    "\n",
    "    output_prefix = \"/\".join(path_[3:])\n",
    "    filename = file_name.split(\".\")[0] + \".pdf\"\n",
    "\n",
    "    blob = result_bucket.blob(f\"{output_prefix}{filename}\")\n",
    "    pdfbytes = pdf_stream.getvalue()\n",
    "    blob.upload_from_string(pdfbytes, content_type=\"application/pdf\")\n",
    "\n",
    "\n",
    "def get_redact_bbox_from_text(\n",
    "    text_redact: str, full_text: str, json_data: dict\n",
    ") -> Dict[str, list]:\n",
    "    \"\"\"\n",
    "    Get the bounding box coordinates for redacting specified text in a document.\n",
    "\n",
    "    Args:\n",
    "        text_redact (str): The text to be redacted.\n",
    "        full_text (str): The full text of the document.\n",
    "        json_data (dict): The JSON representation of the document.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, list]: A dictionary mapping page numbers to lists of bounding box coordinates.\n",
    "    \"\"\"\n",
    "    from fuzzywuzzy import fuzz\n",
    "    import re\n",
    "\n",
    "    pattern = r\"{}.*{}\".format(\n",
    "        re.escape(text_redact.split(\" \")[0]), re.escape(text_redact.split(\" \")[-1])\n",
    "    )\n",
    "    match = re.search(pattern, full_text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    start = match.start()\n",
    "\n",
    "    end_temp = full_text[start : start + 50].find(text_redact.split(\" \")[-1])\n",
    "    end = start + end_temp + len(text_redact.split(\" \")[-1])\n",
    "    page_anc = {\"x\": [], \"y\": []}\n",
    "    page_num = 0\n",
    "\n",
    "    for page in json_data.pages:\n",
    "        for token in page.tokens:\n",
    "            text_anch = token.layout.text_anchor.text_segments\n",
    "            for an in text_anch:\n",
    "                start_temp_token = an.start_index\n",
    "                end_temp_token = an.end_index\n",
    "                if (\n",
    "                    int(start_temp_token) >= int(start)\n",
    "                    and int(end_temp_token) <= int(end) + 2\n",
    "                ):\n",
    "                    norm_ver = token.layout.bounding_poly.normalized_vertices\n",
    "                    for ver in norm_ver:\n",
    "                        page_anc[\"x\"].append(ver.x)\n",
    "                        page_anc[\"y\"].append(ver.y)\n",
    "                    page = page_num\n",
    "        page_num = page_num + 1\n",
    "    redact_bbox = {\n",
    "        str(page): [\n",
    "            [\n",
    "                min(page_anc[\"x\"]),\n",
    "                min(page_anc[\"y\"]),\n",
    "                max(page_anc[\"x\"]),\n",
    "                max(page_anc[\"y\"]),\n",
    "            ]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return redact_bbox\n",
    "\n",
    "\n",
    "def read_excel_to_dict(file_path: str, sheet_name: str = \"data\") -> dict:\n",
    "    \"\"\"\n",
    "    Read the specified sheet from the Excel file into a dictionary.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the Excel file.\n",
    "        sheet_name (str, optional): Name of the sheet to read. Defaults to 'data'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with column names as keys and lists of column data as values.\n",
    "    \"\"\"\n",
    "    # Read the specified sheet from the Excel file into a pandas DataFrame\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "    # Convert DataFrame to a dictionary with columns as keys and lists of column data as values\n",
    "    data_dict = {column: df[column].tolist() for column in df.columns}\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def de_normalize_bbox(entity_bbox: dict, synthesized_images: list) -> dict:\n",
    "    \"\"\"\n",
    "    De-normalize bounding box coordinates based on the original image size.\n",
    "\n",
    "    Args:\n",
    "        entity_bbox (dict): A dictionary containing entity bounding box information.\n",
    "        synthesized_images (list): List of synthesized images.\n",
    "\n",
    "    Returns:\n",
    "        dict: De-normalized entity bounding box coordinates.\n",
    "    \"\"\"\n",
    "    open_cv_image = {}\n",
    "    for i in range(len(synthesized_images)):\n",
    "        open_cv_image[i] = numpy.array(synthesized_images[i].convert(\"RGB\"))\n",
    "    for j in range(len(open_cv_image)):\n",
    "        size = open_cv_image[j].shape\n",
    "        for en_name1, coords1 in entity_bbox.items():\n",
    "            for bbox1 in coords1:\n",
    "                if str(j) == bbox1[\"page\"]:\n",
    "                    bbox1[\"bbox\"] = [\n",
    "                        int(bbox1[\"bbox\"][0] * size[1]),\n",
    "                        int(bbox1[\"bbox\"][1] * size[0]),\n",
    "                        int(bbox1[\"bbox\"][2] * size[1]),\n",
    "                        int(bbox1[\"bbox\"][3] * size[0]),\n",
    "                    ]\n",
    "\n",
    "    return entity_bbox\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Calling the functions\"\"\"\n",
    "    file_names_list, file_names_dict = file_names(gcs_input_path)\n",
    "\n",
    "    file_path = synthetic_data_path\n",
    "    synthesize_data = read_excel_to_dict(file_path, sheet_name=sheet_name)\n",
    "\n",
    "    for filename, filepath in tqdm(file_names_dict.items(), desc=\"Progress\"):\n",
    "        if \".json\" in filename:\n",
    "            print(filename)\n",
    "            # try:\n",
    "            json_data = documentai_json_proto_downloader(\n",
    "                gcs_input_path.split(\"/\")[2], filepath\n",
    "            )\n",
    "            redact_bbox = {}\n",
    "            try:\n",
    "                page_wise_bbox, entity_wise_bbox = get_bbox_page_wise(\n",
    "                    json_data, pii_entities\n",
    "                )\n",
    "                for p2, b2 in page_wise_bbox.items():\n",
    "                    if p2 in redact_bbox.keys():\n",
    "                        redact_bbox[p2].extend(b2)\n",
    "                    else:\n",
    "                        redact_bbox[p2] = b2\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if len(redact_text) > 0:\n",
    "                    redact_bbox_text = {}\n",
    "                    for t1 in redact_text:\n",
    "                        page_wise_bbox_text = get_redact_bbox_from_text(\n",
    "                            t1, json_data.text, json_data\n",
    "                        )\n",
    "                        for p1, b1 in page_wise_bbox_text.items():\n",
    "                            if p1 in redact_bbox.keys():\n",
    "                                redact_bbox[p1].extend(b1)\n",
    "                            else:\n",
    "                                redact_bbox[p1] = b1\n",
    "\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "\n",
    "            synthesized_images = get_synthesized_images(json_data)\n",
    "            updated_entity_wise_bbox = de_normalize_bbox(\n",
    "                entity_wise_bbox, synthesized_images\n",
    "            )\n",
    "\n",
    "            pdf_stream = draw_black_box(\n",
    "                synthesized_images,\n",
    "                redact_bbox,\n",
    "                updated_entity_wise_bbox,\n",
    "                synthesize_data,\n",
    "                redact_only,\n",
    "            )\n",
    "            import io\n",
    "            from pdf2image import convert_from_bytes\n",
    "            from IPython.display import display\n",
    "\n",
    "            pdf_stream.seek(0)  # Go to the beginning of the stream\n",
    "            images = convert_from_bytes(pdf_stream.read())\n",
    "\n",
    "            # # Display images\n",
    "            # for image in images:\n",
    "            #     display(image)\n",
    "\n",
    "            store_blob(pdf_stream, gcs_output_path, filename)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aa873d-f9be-46dc-b188-23e0d4d95dd0",
   "metadata": {},
   "source": [
    "### 4.Output\n",
    "\n",
    "The New pdf documents with synthesized data will be saved in gcs_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189bc23-c7dd-4ae6-a271-98d2bfe3c4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
