{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc20446b-7444-4262-ab55-afdd1f11160d",
   "metadata": {},
   "source": [
    "# Extracting Embedded links in PDF "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46b2c1-65eb-46c1-92ef-d16a5a354b99",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3887d3d1-7e45-4b3e-97e7-54fe44fd97d5",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the DocAI Incubator Team. No guarantees of performance are implied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68524e50-7f8a-4d84-a420-8fdf23948a24",
   "metadata": {},
   "source": [
    "## Purpose and Description\n",
    "This document guides  to extract hyperlinks from PDF files stored in a Google Cloud Storage (GCS) bucket and save the extracted hyperlinks along with associated information (such as page number and hyperlink text) into an Excel workbook.The Excel workbooks contain a worksheet named file_name  where each row represents a hyperlink found in the PDF file, along with its associated page number and text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989ce04-a88b-4fba-b160-e562549c5087",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Access to vertex AI Notebook or Google Colab\n",
    "2. Python\n",
    "3. Access to the google storage bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd2da5-ee1a-451e-9e9e-3f64107c3c1b",
   "metadata": {},
   "source": [
    "## Step by Step procedure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efc6aae-1850-422f-b511-0060cf523bc1",
   "metadata": {},
   "source": [
    "### 1. Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f47cbcfb-2131-46c6-8643-9cbe770ec121",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: PyMuPDF in /opt/conda/lib/python3.7/site-packages (1.22.5)\n",
      "\u001b[33mWARNING: Error parsing requirements for fastjsonschema: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/fastjsonschema-2.18.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xlsxwriter in /opt/conda/lib/python3.7/site-packages (3.1.9)\n",
      "\u001b[33mWARNING: Error parsing requirements for fastjsonschema: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/fastjsonschema-2.18.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.7/site-packages (2.11.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.28.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.17.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.6.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.60.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media>=2.6.0->google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.2.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.5.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for fastjsonschema: [Errno 2] No such file or directory: '/opt/conda/lib/python3.7/site-packages/fastjsonschema-2.18.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-datastore (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF\n",
    "!pip install xlsxwriter\n",
    "!pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb546882-3c1d-4648-addd-c954d8046f45",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-12 09:22:12--  https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29735 (29K) [text/plain]\n",
      "Saving to: ‘utilities.py’\n",
      "\n",
      "utilities.py        100%[===================>]  29.04K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2024-06-12 09:22:12 (18.7 MB/s) - ‘utilities.py’ saved [29735/29735]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edacf9c8-264b-4c40-be28-247063a91726",
   "metadata": {},
   "source": [
    "### 2. Import the required libraries/Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c91c8b1-4af5-4c3d-9723-ddd6b19439e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from utilities import file_names\n",
    "import io\n",
    "import xlsxwriter\n",
    "import fitz\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87c281-74d2-4aac-be20-6904a39e5a10",
   "metadata": {},
   "source": [
    "### 3. Input Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82caa8d-bd2d-4a4c-9218-8df52d28cc5d",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>input_path : </b>It is input GCS folder path which contains pdf files</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c50e51c-d0a5-4a05-8666-8b5b07b495d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"gs://bucket_name/path_to_folders/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa544623-1ccb-490a-bda8-3dbb73f41b0f",
   "metadata": {},
   "source": [
    "### 4.Execute the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81f61b58-503e-4a9f-b279-799748493613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperlinks saved to 'hyperlinks_combined.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "def extract_hyperlinks_from_gcs(bucket_name, pdf_paths, excel_file):\n",
    "    client = storage.Client()\n",
    "    workbook = xlsxwriter.Workbook(excel_file)\n",
    "\n",
    "    for pdf_path in pdf_paths:\n",
    "        bucket = client.get_bucket(bucket_name)\n",
    "        blob = bucket.blob(pdf_path)\n",
    "        pdf_data = blob.download_as_string()\n",
    "        pdf_content = io.BytesIO(pdf_data)\n",
    "        reader = fitz.open(stream=pdf_content, filetype=\"pdf\")\n",
    "\n",
    "        worksheet_name = os.path.splitext(os.path.basename(pdf_path))[0][-30:]\n",
    "        worksheet = workbook.add_worksheet(worksheet_name)\n",
    "\n",
    "        row = 0\n",
    "        col = 0\n",
    "        worksheet.write(row, col, \"Page Number\")\n",
    "        worksheet.write(row, col + 1, \"HyperlinkText\")\n",
    "        worksheet.write(row, col + 2, \"Hyperlink\")\n",
    "        row += 1\n",
    "\n",
    "        for page_num in range(len(reader)):\n",
    "            page = reader[page_num]\n",
    "\n",
    "            links = page.links()\n",
    "            for link in links:\n",
    "                if \"uri\" in link:\n",
    "                    uri = link[\"uri\"]\n",
    "                    link_rect = fitz.Rect(link[\"from\"])\n",
    "                    text = page.get_textbox(link_rect)\n",
    "                    worksheet.write(row, col, page_num)\n",
    "                    worksheet.write(row, col + 1, text)\n",
    "                    worksheet.write(row, col + 2, uri)\n",
    "                    row += 1\n",
    "    workbook.close()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_storage_bucket_name = input_path.split(\"/\")[2]\n",
    "pdf_files = file_names(input_path)[1].values()\n",
    "pdf_paths = [i for i in list(pdf_files) if i.endswith(\".pdf\")]\n",
    "# List of PDF paths in the bucket\n",
    "excel_file = \"hyperlinks_combined.xlsx\"\n",
    "extract_hyperlinks_from_gcs(input_storage_bucket_name, pdf_paths, excel_file)\n",
    "print(f\"Hyperlinks saved to '{excel_file}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e60426-6b2b-4176-ae0e-83002fa3bb86",
   "metadata": {},
   "source": [
    "### 5.Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db365c0d-c879-42a4-be8d-31ce3ab8913e",
   "metadata": {},
   "source": [
    "the extracted hyperlinks along with associated information (such as page number and hyperlink text) into an Excel workbook.The Excel workbooks contain a worksheet named file_name  where each row represents a hyperlink found in the PDF file, along with its associated page number and text.\n",
    ". <br><hr>\n",
    "\n",
    "<b>Output File example</b><br><br>\n",
    "<img src=\"./images/Excel_image.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c893b2c-be48-40a4-ac0a-375a53cd9900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
