{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09323902-0b58-4ddf-8cfb-0317da6fc9e3",
   "metadata": {},
   "source": [
    "# CDE HITL Line Item Prefix Issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e2fadb-9ce5-4871-bcb2-ff9c3073defd",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c656e9a9-bac0-4fbc-b2ce-2732308474f6",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the **DocAI Incubator Team**. No guarantees of performance are implied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d772eb88-15b9-455c-8ebd-e65c621ab0ad",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This document is to deal with the CDE trained using invoices and has issues in updating the child items in HITL because of the prefix of child items. The code snippet adds the prefix to child items (similar to invoice parser output) and triggers HITL using invoice parser HITL endpoint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1be5be-0cc9-4728-b8b3-9c522d655f96",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* Vertex AI Notebook\n",
    "* CDE parser output\n",
    "* Invoice parser( if schema of standard invoice parser varies from CDE then invoice parser has to be untrained to edit all the child items based on threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf072cec-a8bf-4936-b8f2-f9d0fe7b5f14",
   "metadata": {},
   "source": [
    "## Step by Step procedure \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c076e8d-7b8d-449d-8924-89ab7d31f9c2",
   "metadata": {},
   "source": [
    "### 1.Importing Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1041643-061a-4bb7-b366-eab0651ec76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb45701-ac40-497f-8d45-c145188b3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities\n",
    "import json\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from google.cloud import storage\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e6b924-e54a-43ae-b280-07f3f4520766",
   "metadata": {},
   "source": [
    "### 2.Setup the inputs\n",
    "\n",
    "`gcs_input_path`: This contains the storage bucket path of the input files.        \n",
    "`gcs_output_path`: This contains the storage bucket path of the output files.                  \n",
    "`project_id`: This contains the project ID of the project.               \n",
    "`invoice_processor_id`: This is the processor ID of the invoice processor.                  \n",
    "`location_processor`: This contains the location/region of the processor.        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ec910-4d32-483c-a62e-45e83906423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input details\n",
    "gcs_input_path = \"gs://xxxxxxxxxx/\"\n",
    "gcs_output_path = \"gs://xxxxxxxxxx/\"\n",
    "project_id = \"xxxxxxxxxxxx\"\n",
    "invoice_processor_id = \"xxxxxxxxxxx\"\n",
    "location_processor = \"us\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a0e20-ef09-4a50-8964-57cd08bb9dac",
   "metadata": {},
   "source": [
    "* **Note** : Invoice parser( if schema of standard invoice parser varies from CDE then invoice parser has to be untrained to edit all the child items based on threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea398ef6-3745-42dd-9229-dac482117c80",
   "metadata": {},
   "source": [
    "### 3.Run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a255a6-f607-44e6-a7db-5b87a7a041d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_json(json_dict: object) -> object:\n",
    "    \"\"\"\n",
    "    Updates the JSON document by combining subentities and adjusting page anchors.\n",
    "\n",
    "    Args:\n",
    "    - json_dict (Document): Input document in protobuf format.\n",
    "\n",
    "    Returns:\n",
    "    - Document: Updated document with combined subentities and adjusted page anchors.\n",
    "    \"\"\"\n",
    "    for entity in json_dict.entities:\n",
    "        if entity.properties:\n",
    "            for subentity in entity.properties:\n",
    "                subentity.type = entity.type_ + \"/\" + subentity.type_\n",
    "    line = []\n",
    "    for entity in json_dict.entities:\n",
    "        if entity.properties:\n",
    "            line.append(entity)\n",
    "    for line_1 in line:\n",
    "        x_temp = []\n",
    "        y_temp = []\n",
    "        for subentity in line_1.properties:\n",
    "            for item in subentity.page_anchor.page_refs[\n",
    "                0\n",
    "            ].bounding_poly.normalized_vertices:\n",
    "                # for item_1 in item:\n",
    "                x_temp.append(item.x)\n",
    "                y_temp.append(item.y)\n",
    "        x_min = min(x_temp)\n",
    "        y_min = min(y_temp)\n",
    "        x_max = max(x_temp)\n",
    "        y_max = max(y_temp)\n",
    "\n",
    "        line_1.page_anchor = {\n",
    "            \"page_refs\": [\n",
    "                {\n",
    "                    \"bounding_poly\": {\n",
    "                        \"normalized_vertices\": [\n",
    "                            {\"x\": x_min, \"y\": y_min},\n",
    "                            {\"x\": x_max, \"y\": y_max},\n",
    "                            {\"x\": x_min, \"y\": y_max},\n",
    "                            {\"x\": x_max, \"y\": y_min},\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    updated_ent = []\n",
    "    for ent in json_dict.entities:\n",
    "        if entity.properties:\n",
    "            pass\n",
    "        else:\n",
    "            updated_ent.append(ent)\n",
    "\n",
    "    for l1 in line:\n",
    "        updated_ent.append(l1)\n",
    "\n",
    "    json_dict.entities = updated_ent\n",
    "    return json_dict\n",
    "\n",
    "\n",
    "def review_document_sample(\n",
    "    project_id: str, location: str, processor_id: str, file_path: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Sends a human review request for a processed document.\n",
    "\n",
    "    Args:\n",
    "    - project_id (str): Project ID.\n",
    "    - location (str): Location of the document processor.\n",
    "    - processor_id (str): ID of the document processor.\n",
    "    - file_path (str): Path to the document file.\n",
    "\n",
    "    Returns:\n",
    "    - str: Operation name that can be used to check the status of the request.\n",
    "    \"\"\"\n",
    "    # You must set the api_endpoint if you use a location other than 'us'.\n",
    "    opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "\n",
    "    # Create a client\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    # Make Processing Request\n",
    "    inline_document = json_to_inline(file_path)\n",
    "\n",
    "    # Gets the full resource name of the human review config\n",
    "    human_review_config = client.human_review_config_path(\n",
    "        project_id, location, processor_id\n",
    "    )\n",
    "\n",
    "    # Options are DEFAULT, URGENT\n",
    "    priority = documentai.ReviewDocumentRequest.Priority.DEFAULT\n",
    "\n",
    "    # Sends the human review request\n",
    "    request = documentai.ReviewDocumentRequest(\n",
    "        inline_document=inline_document,\n",
    "        human_review_config=human_review_config,\n",
    "        enable_schema_validation=True,\n",
    "        priority=priority,\n",
    "    )\n",
    "\n",
    "    # Make a request for human review of the processed document\n",
    "    operation = client.review_document(request=request)\n",
    "\n",
    "    # Return operation name, can be used to check status of the request\n",
    "    operation_name = operation.operation.name\n",
    "    return operation\n",
    "\n",
    "\n",
    "def json_to_inline(file_path: str) -> object:\n",
    "    \"\"\"\n",
    "    Converts a JSON document to inline content.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the JSON document file.\n",
    "\n",
    "    Returns:\n",
    "    - The document object.\n",
    "    \"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(file_path)\n",
    "    json_data = json.loads(blob.download_as_text())\n",
    "    json_data.pop(\"docid\", None)\n",
    "    json_string = json.dumps(json_data)\n",
    "    document = documentai.Document.from_json(json_string)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c24ae6-de52-4818-9176-a393b0fcdf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving updated jsons to ouput folder\n",
    "file_names_list, file_dict = utilities.file_names(gcs_input_path)\n",
    "for filename, filepath in tqdm(file_dict.items(), desc=\"Progress\"):\n",
    "    input_bucket_name = gcs_input_path.split(\"/\")[2]\n",
    "    json_dict = utilities.documentai_json_proto_downloader(input_bucket_name, filepath)\n",
    "    json_dict_updated = update_json(json_dict)\n",
    "    output_bucket_name = gcs_output_path.split(\"/\")[2]\n",
    "    output_path_within_bucket = \"/\".join(gcs_output_path.split(\"/\")[3:]) + filename\n",
    "    utilities.store_document_as_json(\n",
    "        documentai.Document.to_json(json_dict_updated),\n",
    "        output_bucket_name,\n",
    "        output_path_within_bucket,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571f378-8407-45d8-9c49-465117ab3330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually triggering HITL using invoice parser HITL end point\n",
    "file_out, file_dict_out = utilities.file_names(gcs_output_path)\n",
    "for filename, filepath in tqdm(file_dict_out.items(), desc=\"Progress\"):\n",
    "    bucket_name = gcs_output_path.split(\"/\")[2]\n",
    "    x = review_document_sample(\n",
    "        project_id=project_id,\n",
    "        location=location_processor,\n",
    "        processor_id=invoice_processor_id,\n",
    "        file_path=filepath,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81bf60b-75b4-45aa-814d-31c0cf0b4a28",
   "metadata": {},
   "source": [
    "### 4.Output\n",
    "\n",
    "The output jsons are similar to the invoice parser jsons(only in terms of line items) and HITL triggered using invoice parser end point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5eacbf-4a4e-4f4c-b7f6-270b12dbf3c7",
   "metadata": {},
   "source": [
    "<img src=\"./Images/HITL_output_1.png\" width=800 height=400 ></img>"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
