{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82928c58-7089-43a5-bcdb-2773dc8344e3",
   "metadata": {},
   "source": [
    "# Vertex Object Detection Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4908259-44c1-442f-b0ff-8a735dd20c58",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32be0c5-4f8c-4d5f-b42d-a1e8b015d5d3",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the DocAI Incubator Team. No guarantees of performance are implied.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2575800a-5d6f-4530-a8a7-949acfc0975b",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This code facilitates sending an image to a specified Vertex object detection model, processes the received predictions, and can also visualize the detected objects by overlapping bounding boxes and class labels on the original image. The results are then displayed, showcasing the model's detection capabilities.\n",
    "\n",
    "Custom models, such as checkbox models, can be trained using your specific data and then deployed as endpoints in Vertex AI. These models can work in conjunction with the Document AI processor to yield more accurate results in checkbox detection. To evaluate the performance of the Vertex AI endpoint model, this script can be utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a065dd-a518-404b-a86d-64d6af197d2d",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "* Python : Jupyter notebook (Vertex) or Google Colab \n",
    "* Access to Vertex Model Endpoint\n",
    "* Permissions, reference or access to Google projects are needed.\n",
    "* Sample Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d006e-4e79-424e-94d7-6b23898a5b4f",
   "metadata": {},
   "source": [
    "### Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c22fd-8e1f-456d-9960-3473a1e52599",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow matplotlib google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b4768-7859-4de8-85e6-79944437410c",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4fa3c5-0a88-4ad8-b5f9-1401fec29d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from typing import Dict, List, Union\n",
    "from typing import Dict, Any, Tuple\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0be8f-69e9-486c-951c-cbd49529f913",
   "metadata": {},
   "source": [
    "### Setup the Required Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692baf08-0aab-44c1-9155-7083223c9bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"your_project_id\"  # Assign your Google Cloud project ID\n",
    "endpoint_id = \"your_endpoint_id\"  # Assign the ID of the AI Platform endpoint\n",
    "location = \"your_location\"  # Assign the location of the AI Platform endpoint (e.g., \"us-central1\")\n",
    "model_signature_has_key = (\n",
    "    True  # Set to True if the model signature includes a key, otherwise False\n",
    ")\n",
    "score_threshold = 0.75  # Set the threshold for displaying detections (e.g., 0.75)\n",
    "file_path = \"path/to/your/image.png\"  # Specify the file path to your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992aa8ff-2926-4371-860d-88a4734cb2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aiplatform_predict_from_endpoint(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    instances: Union[Dict, List[Dict]],\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Make a prediction request to a Google AI Platform endpoint.\n",
    "\n",
    "    Args:\n",
    "        project (str): The project ID of the Google Cloud project.\n",
    "        endpoint_id (str): The ID of the AI Platform endpoint.\n",
    "        instances (Union[Dict, List[Dict]]): The input instances for prediction.\n",
    "            This can be a single dictionary instance or a list of dictionaries.\n",
    "        location (str, optional): The location of the AI Platform endpoint.\n",
    "            Defaults to \"us-central1\".\n",
    "        api_endpoint (str, optional): The API endpoint URL for AI Platform.\n",
    "            Defaults to \"us-central1-aiplatform.googleapis.com\".\n",
    "\n",
    "    Returns:\n",
    "        Dict: The first prediction result from the AI Platform endpoint.\n",
    "    \"\"\"\n",
    "    # Configure client options with the provided API endpoint\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "\n",
    "    # Create an AI Platform Prediction Service client\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "\n",
    "    # Ensure instances is a list\n",
    "    instances = instances if isinstance(instances, list) else [instances]\n",
    "\n",
    "    # Convert instances to Google's Value format\n",
    "    instances = [\n",
    "        json_format.ParseDict(instance_dict, Value()) for instance_dict in instances\n",
    "    ]\n",
    "\n",
    "    # Empty parameters for the prediction request\n",
    "    parameters_dict = {}\n",
    "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "\n",
    "    # Define the endpoint path using project, location and endpoint ID\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "\n",
    "    # Make the prediction request\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "\n",
    "    # Print the response details\n",
    "    print(\"response\")\n",
    "    print(\" deployed_model_id:\", response.deployed_model_id)\n",
    "\n",
    "    # Extract and return the first prediction result\n",
    "    predictions = response.predictions\n",
    "    return dict(predictions[0])\n",
    "\n",
    "\n",
    "def generate_colors(num_colors: int) -> List[Union[str, Tuple[float, float, float]]]:\n",
    "    \"\"\"\n",
    "    Generate a list of colors, mixing predefined named colors and random RGB colors.\n",
    "\n",
    "    Args:\n",
    "        num_colors (int): The number of colors to generate.\n",
    "\n",
    "    Returns:\n",
    "        List[Union[str, Tuple[float, float, float]]]: A list containing color names\n",
    "        and RGB color tuples. RGB colors are represented as tuples of three floats\n",
    "        (ranging from 0 to 1) indicating the red, green, and blue components.\n",
    "    \"\"\"\n",
    "    # Predefined set of color names\n",
    "    predefined_colors = [\"green\", \"red\", \"violet\", \"orange\", \"black\"]\n",
    "\n",
    "    # Generate additional random colors if more are needed\n",
    "    while len(predefined_colors) < num_colors:\n",
    "        # Create a random color as an RGB tuple\n",
    "        random_color = (random.random(), random.random(), random.random())\n",
    "        predefined_colors.append(random_color)\n",
    "\n",
    "    # Return the required number of colors\n",
    "    return predefined_colors[:num_colors]\n",
    "\n",
    "\n",
    "def process_predictions(\n",
    "    predictions: Dict[str, Any], image: Image.Image, score_threshold: float = 0.5\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Processes and visualizes predictions on an image.\n",
    "\n",
    "    Args:\n",
    "        predictions (Dict[str, Any]): A dictionary containing the predictions output\n",
    "            from a model. Expected keys include 'image_info', 'detection_classes_as_text',\n",
    "            'num_detections', 'detection_boxes', and 'detection_scores'.\n",
    "        image (Image.Image): The image on which detections are to be visualized.\n",
    "        score_threshold (float, optional): The threshold for displaying detections.\n",
    "            Only detections with a score above this threshold will be visualized.\n",
    "            Defaults to 0.5.\n",
    "\n",
    "    This function does not return anything but visualizes the detections on the given image.\n",
    "    \"\"\"\n",
    "    # Extract image dimensions from predictions\n",
    "    height, width = int(predictions[\"image_info\"][0][0]), int(\n",
    "        predictions[\"image_info\"][0][1]\n",
    "    )\n",
    "\n",
    "    # Setup the plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Extract unique classes and assign colors\n",
    "    unique_classes = set(predictions[\"detection_classes_as_text\"])\n",
    "    colors = generate_colors(len(unique_classes))\n",
    "    class_color_mapping = dict(zip(unique_classes, colors))\n",
    "\n",
    "    # Iterate over each detection\n",
    "    for i in range(int(predictions[\"num_detections\"])):\n",
    "        ymin, xmin, ymax, xmax = predictions[\"detection_boxes\"][i]\n",
    "\n",
    "        # Filter out detections below the score threshold\n",
    "        if predictions[\"detection_scores\"][i] < score_threshold:\n",
    "            continue\n",
    "\n",
    "        # Get class name and corresponding color\n",
    "        class_name = predictions[\"detection_classes_as_text\"][i]\n",
    "        color = class_color_mapping[class_name]\n",
    "\n",
    "        # Draw a rectangle around the detected object\n",
    "        rect = patches.Rectangle(\n",
    "            (xmin * width, ymin * height),\n",
    "            (xmax - xmin) * width,\n",
    "            (ymax - ymin) * height,\n",
    "            linewidth=2,\n",
    "            edgecolor=color,\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add text annotation for each detection\n",
    "        ax.text(xmin * width, ymin * height, str(i), fontsize=8, color=\"blue\")\n",
    "        display_str = f\"Prediction {i} class: {class_name} score: {predictions['detection_scores'][i]}\"\n",
    "        print(display_str)\n",
    "\n",
    "    # Display the image with annotations\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f938f5-906e-42df-8d81-2261b8c31850",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"rb\") as f:\n",
    "    source_bytes = f.read()\n",
    "b64_source_bytes_as_str = base64.b64encode(source_bytes).decode(\"utf-8\")\n",
    "image = Image.open(io.BytesIO(source_bytes))\n",
    "\n",
    "json_request = {}\n",
    "json_request[\"encoded_image\"] = {\"b64\": b64_source_bytes_as_str}\n",
    "if model_signature_has_key:\n",
    "    json_request[\"key\"] = \"0\"\n",
    "prediction_response = aiplatform_predict_from_endpoint(\n",
    "    project=project_id,\n",
    "    endpoint_id=endpoint_id,\n",
    "    location=location,\n",
    "    instances=json_request,\n",
    ")\n",
    "process_predictions(prediction_response, image)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
