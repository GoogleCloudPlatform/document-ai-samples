{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cbcbc6b-0c0b-42d5-8619-ebd1f4bf8657",
   "metadata": {},
   "source": [
    "# Tag line information to Layout Text Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054d9da-3034-4fb0-b828-cd536198f68c",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c2600-51ad-4085-9555-7f3332ccc1b4",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the **DocAI Incubator Team**. No guarantees of performance are implied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d9223-2537-4ae0-98a5-32e372d1419d",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The purpose of this tool is to append line information to the output of the Layout parser by utilizing the output of Document OCR. Each text block is augmented with the detectedLanguages attribute, which contains information about line attributes that are consistent with the OCR output.\n",
    "\n",
    "NOTE: This tool expect same exact same text-block of Layout parser should exist in Document OCR Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07918d4f-aae3-428d-8a71-4fbe2d6c8c90",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* Vertex AI Notebook\n",
    "* GCP DocumentAI Layout Parser & Document OCR Parser id’s\n",
    "* GCS bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d9b0c-4c03-41b6-aa2e-fcf838791610",
   "metadata": {},
   "source": [
    "## Step by Step procedure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d50f73-088d-4b58-9cfc-f276f2201f9c",
   "metadata": {},
   "source": [
    "### 1.Importing Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01d013-4198-463f-9c6b-2792ec407efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512cb48-2d05-4f19-9669-64af75a1edcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-documentai google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad415a6d-6b54-4241-a781-678a527f0ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Any, List, Dict\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from google.cloud import storage\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from utilities import file_names, store_document_as_json\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110046b1-ebea-4a2b-990d-5acda4a3b66c",
   "metadata": {},
   "source": [
    "### 2.Setup the inputs\n",
    "\n",
    "* `project_id` : A unique identifier for a Google Cloud project.\n",
    "* `location` : The geographic region of the resource or operation, e.g., us-central1.\n",
    "* `ocr_processor_id` : Identifier for the Optical Character Recognition (OCR) processor.\n",
    "* `ocr_processor_version` : Version number of the OCR processor.\n",
    "* `layout_processor_id` : Identifier for the layout processor.\n",
    "* `layout_processor_version` : Version number of the layout processor.\n",
    "* `input_path` : File path to the input data.\n",
    "* `output_path` : File path for the processed output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41618163-fafe-438a-a8d4-25571fc600b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"xxxx-xxxx-xxxx\"\n",
    "location = \"us\" or \"eu\"\n",
    "ocr_processor_id = \"xxxx-xxxx-xxxx\"\n",
    "ocr_processor_version = \"xxxx-xxxx-xxxx\"\n",
    "layout_processor_id = \"xxxx-xxxx-xxxx\"\n",
    "layout_processor_version = \"xxxx-xxxx-xxxx\"\n",
    "input_path = \"gs://bucket_name/path_to_pdf's/\"\n",
    "output_path = \"gs://bucket_name/path_to_output_folder/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40376d0f-1bb2-426b-8c72-fb7b4fb0ec31",
   "metadata": {},
   "source": [
    "#### Global Variable declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f079318d-785e-493f-910f-2e9113ba00de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layout_process_options = documentai.ProcessOptions(\n",
    "    layout_config=documentai.ProcessOptions.LayoutConfig(\n",
    "        chunking_config=documentai.ProcessOptions.LayoutConfig.ChunkingConfig(\n",
    "            chunk_size=1000,\n",
    "            include_ancestor_headings=True,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "ocr_process_options = documentai.ProcessOptions(\n",
    "    ocr_config=documentai.OcrConfig(\n",
    "        enable_symbol=True,\n",
    "        premium_features=documentai.OcrConfig.PremiumFeatures(\n",
    "            enable_selection_mark_detection=True, enable_math_ocr=True\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "latest_lookup_index = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846011bb-eb92-454d-9ea9-6c9763490bce",
   "metadata": {},
   "source": [
    "### 3.Run the required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127e1d9-6a45-4827-a10c-481343697abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_document_sample(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    pdf_bytes: bytes,\n",
    "    processor_version: Optional[str] = None,\n",
    "    process_options: Optional[Any] = None,\n",
    ") -> documentai.Document:\n",
    "    \"\"\"\n",
    "    Process a PDF document using the Document AI processor and return the processed document.\n",
    "\n",
    "    Parameters:\n",
    "    project_id (str): The ID of the Google Cloud project.\n",
    "    location (str): The location of the processor (e.g., 'us' or 'eu').\n",
    "    processor_id (str): The ID of the Document AI processor.\n",
    "    pdf_bytes (bytes): The bytes of the PDF file to be processed.\n",
    "    processor_version (Optional[str]): The specific version of the processor (default is None).\n",
    "    process_options (Optional[Any]): Additional processing options (default is None).\n",
    "\n",
    "    Returns:\n",
    "    documentai.Document: The processed document with recognized text and entities.\n",
    "    \"\"\"\n",
    "\n",
    "    # You must set the `api_endpoint` if you use a location other than \"us\".\n",
    "    opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "    if processor_version:\n",
    "        name = client.processor_version_path(\n",
    "            project_id, location, processor_id, processor_version\n",
    "        )\n",
    "    else:\n",
    "        name = client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    raw_document = documentai.RawDocument(\n",
    "        content=pdf_bytes, mime_type=\"application/pdf\"\n",
    "    )\n",
    "    # Configure the process request\n",
    "    request = documentai.ProcessRequest(\n",
    "        name=name,\n",
    "        raw_document=raw_document,\n",
    "        process_options=process_options,\n",
    "    )\n",
    "    # Recognizes text entities in the PDF document\n",
    "    result = client.process_document(request=request)\n",
    "\n",
    "    return result.document\n",
    "\n",
    "\n",
    "def standardize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Standardizes the input text by replacing newlines and certain quotation marks with simpler equivalents.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The text to be standardized.\n",
    "\n",
    "    Returns:\n",
    "    str: The standardized text with newlines replaced by spaces, and smart quotes replaced by regular quotes.\n",
    "    \"\"\"\n",
    "    return text.replace(\"\\n\", \" \").replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "\n",
    "\n",
    "def get_line_info(\n",
    "    blocks: List[Dict[str, Any]], ocr_json: Dict[str, Any]\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Processes OCR text blocks to retrieve line-level language detection information from the provided OCR JSON data.\n",
    "\n",
    "    Parameters:\n",
    "    blocks (List[Dict[str, Any]]): A list of blocks, where each block contains text and related metadata.\n",
    "    ocr_json (Dict[str, Any]): The OCR data containing text, page, and language information.\n",
    "\n",
    "    Returns:\n",
    "    List[Dict[str, Any]]: The modified list of blocks with detected languages added to the corresponding text blocks.\n",
    "    \"\"\"\n",
    "    for block in blocks:\n",
    "        page_start = int(block[\"pageSpan\"][\"pageStart\"])\n",
    "        if \"textBlock\" in block.keys():\n",
    "            block_text = block[\"textBlock\"][\"text\"]\n",
    "            block_text = standardize_text(block_text)\n",
    "            source_text = standardize_text(ocr_json[\"text\"])\n",
    "            start_index = latest_lookup_index.get(block_text, -1)\n",
    "            start = source_text.find(block_text, start_index + 1)\n",
    "            latest_lookup_index[block_text] = start\n",
    "            end = start + len(block_text) + 1\n",
    "            page = ocr_json[\"pages\"][page_start - 1]\n",
    "            detectedLanguages = []\n",
    "            for line in page[\"lines\"]:\n",
    "                text_segments = line[\"layout\"][\"textAnchor\"][\"textSegments\"][0]\n",
    "                s_index, e_index = int(text_segments[\"startIndex\"]), int(\n",
    "                    text_segments[\"endIndex\"]\n",
    "                )\n",
    "                if start <= s_index and e_index <= end:\n",
    "                    detectedLanguages.extend(line[\"detectedLanguages\"])\n",
    "            block[\"textBlock\"][\"detectedLanguages\"] = detectedLanguages\n",
    "            if len(block[\"textBlock\"][\"blocks\"]) != 0:\n",
    "                get_line_info(block[\"textBlock\"][\"blocks\"], ocr_json)\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2b3e0-8d10-4a57-83ab-330b041fa187",
   "metadata": {},
   "source": [
    "### 4.Run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b255b0-cb06-4f4e-8f0e-75c2d56a52bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    input_bucket = input_path.split(\"/\")[2]\n",
    "    output_bucket = output_path.split(\"/\")[2]\n",
    "    output_path_prefix = \"/\".join(output_path.split(\"/\")[3:])\n",
    "    _, files_dict = file_names(input_path)\n",
    "    storage_client = storage.Client()\n",
    "    input_bucket_obj = storage_client.get_bucket(input_bucket)\n",
    "    for file_name, file_path in files_dict.items():\n",
    "        pdf_bytes = input_bucket_obj.blob(file_path).download_as_bytes()\n",
    "        print(f\"processing...{file_name}\")\n",
    "        ocr_res = process_document_sample(\n",
    "            project_id=project_id,\n",
    "            location=location,\n",
    "            processor_id=ocr_processor_id,\n",
    "            pdf_bytes=pdf_bytes,\n",
    "            processor_version=ocr_processor_version,\n",
    "            process_options=ocr_process_options,\n",
    "        )\n",
    "        ocr_json_data = json.loads(documentai.Document.to_json(ocr_res))\n",
    "        layout_res = process_document_sample(\n",
    "            project_id=project_id,\n",
    "            location=location,\n",
    "            processor_id=layout_processor_id,\n",
    "            pdf_bytes=pdf_bytes,\n",
    "            process_options=layout_process_options,\n",
    "        )\n",
    "        layout_json_data = json.loads(documentai.Document.to_json(layout_res))\n",
    "        # latest_lookup_index = {}\n",
    "        blocks = get_line_info(\n",
    "            layout_json_data[\"documentLayout\"][\"blocks\"], ocr_json_data\n",
    "        )\n",
    "        layout_json_data[\"documentLayout\"][\"blocks\"] = blocks\n",
    "        output_file_name = f\"{output_path_prefix}{file_name.replace('.pdf','.json')}\"\n",
    "        print(\"saving \", output_bucket, output_file_name)\n",
    "        store_document_as_json(\n",
    "            json.dumps(layout_json_data), output_bucket, output_file_name\n",
    "        )\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c9da6-5333-4b95-90dc-7f78425b597e",
   "metadata": {},
   "source": [
    "### 5.Output\n",
    "\n",
    "The updated JSONs containing line information will be saved to the specified output folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6390a5e8-f8c8-49de-b832-05a43d7357d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Updated JSON file \n",
    "<img src=\"./Images/Updated_JSON.png\" width=800 height=400 ></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da77cc-daa6-445e-8a20-33b7be984ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
