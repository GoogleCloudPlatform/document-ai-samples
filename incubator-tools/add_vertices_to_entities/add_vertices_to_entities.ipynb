{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cbcbc6b-0c0b-42d5-8619-ebd1f4bf8657",
   "metadata": {},
   "source": [
    "# Adding vertices to Entities in Document JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054d9da-3034-4fb0-b828-cd536198f68c",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c2600-51ad-4085-9555-7f3332ccc1b4",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the **DocAI Incubator Team**. No guarantees of performance are implied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d9223-2537-4ae0-98a5-32e372d1419d",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This document guides how to add vertices to an entity using its normalized vertices. This approach considers entity nesting as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07918d4f-aae3-428d-8a71-4fbe2d6c8c90",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* Vertex AI Notebook Or Colab (If using Colab, use authentication) \n",
    "* Permission for Vertex AI Notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d9b0c-4c03-41b6-aa2e-fcf838791610",
   "metadata": {},
   "source": [
    "## Step by Step procedure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d50f73-088d-4b58-9cfc-f276f2201f9c",
   "metadata": {},
   "source": [
    "### 1.Importing Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01d013-4198-463f-9c6b-2792ec407efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad415a6d-6b54-4241-a781-678a527f0ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from google.cloud import storage\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "\n",
    "from utilities import blob_downloader, store_document_as_json, file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110046b1-ebea-4a2b-990d-5acda4a3b66c",
   "metadata": {},
   "source": [
    "### 2.Setup the inputs\n",
    "\n",
    "* `file_path` : Location of the Json File in the Google Cloud Storage(GCS) Bucket\n",
    "* `output_path` : The Google Cloud Storage(GCS) path for updated labeled jsons to store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c194a-f607-488e-afd5-1747bd5e45b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"gs://bucket_name/input_sub_folder_path/\"\n",
    "output_path = \"gs://bucket_name/output_sub_folder_path/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846011bb-eb92-454d-9ea9-6c9763490bce",
   "metadata": {},
   "source": [
    "### 3.Run the required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127e1d9-6a45-4827-a10c-481343697abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalized_to_original(\n",
    "    normalized_vertices: List[Dict[str, float]], page_width: int, page_height: int\n",
    ") -> List[Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Convert normalized vertices (with values between 0 and 1) to original pixel-based vertices using the page's width and height.\n",
    "\n",
    "    Args:\n",
    "        normalized_vertices (List[Dict[str, float]]): A list of dictionaries representing the normalized vertices where\n",
    "                                                      'x' and 'y' values are between 0 and 1.\n",
    "        page_width (int): The width of the page in pixels.\n",
    "        page_height (int): The height of the page in pixels.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, int]]: A list of dictionaries representing the original vertices with 'x' and 'y' values converted\n",
    "                              to pixel coordinates based on the page dimensions.\n",
    "    \"\"\"\n",
    "    original_vertices = []\n",
    "    for vertex in normalized_vertices:\n",
    "        original_vertex = {\n",
    "            \"x\": round(vertex[\"x\"] * page_width),\n",
    "            \"y\": round(vertex[\"y\"] * page_height),\n",
    "        }\n",
    "        original_vertices.append(original_vertex)\n",
    "\n",
    "    return original_vertices\n",
    "\n",
    "\n",
    "def extract_page_dimensions(document: dict, page_index: int) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Extract the width and height of a page at the given index from the document.\n",
    "\n",
    "    Args:\n",
    "        document (dict): A dictionary representing the document, which includes a list of pages.\n",
    "        page_index (int): The index of the page from which to extract the dimensions.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: The width and height of the page as a tuple of float values.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the page does not have width and height dimensions.\n",
    "    \"\"\"\n",
    "    page = document.get(\"pages\", [])[page_index]\n",
    "    dimension = page.get(\"dimension\", {})\n",
    "    width = dimension.get(\"width\")\n",
    "    height = dimension.get(\"height\")\n",
    "\n",
    "    if width is not None and height is not None:\n",
    "        return width, height\n",
    "    else:\n",
    "        raise ValueError(f\"Page {page_index} dimensions not found.\")\n",
    "\n",
    "\n",
    "def process_entity(entity: dict, document: dict, page_index: int) -> Optional[None]:\n",
    "    \"\"\"\n",
    "    Process a single entity by converting its normalized vertices to original pixel-based vertices.\n",
    "\n",
    "    Args:\n",
    "        entity (dict): A dictionary representing the entity, which includes page references and bounding polygon details.\n",
    "        document (dict): The entire document containing pages, dimensions, and other metadata.\n",
    "        page_index (int): The index of the page from which the entity is extracted.\n",
    "                          Used as a default if no page information is provided in the entity.\n",
    "\n",
    "    Returns:\n",
    "        None: The function modifies the entity in place by adding original vertices based on page dimensions.\n",
    "              If the entity lacks normalized vertices or page information, it returns None to skip further processing.\n",
    "    \"\"\"\n",
    "    entity_page_refs = entity.get(\"pageAnchor\", {}).get(\"pageRefs\", [])\n",
    "\n",
    "    # Use page 0 as default if no page information is present and assume single page document\n",
    "    if not entity_page_refs:\n",
    "        entity_page_ref = {\"page\": page_index}\n",
    "        entity_page_refs = [entity_page_ref]\n",
    "\n",
    "    # Use the first page reference (assuming single-page entities)\n",
    "    entity_page_ref = entity_page_refs[0]\n",
    "    page_index = int(\n",
    "        entity_page_ref.get(\"page\", page_index)\n",
    "    )  # Default to page_index if page info is missing\n",
    "    entity_bounding_poly = entity_page_ref.get(\"boundingPoly\", {})\n",
    "    entity_normalized_vertices = entity_bounding_poly.get(\"normalizedVertices\", [])\n",
    "\n",
    "    if not entity_normalized_vertices:\n",
    "        return  # Skip if there are no normalized vertices for the entity\n",
    "\n",
    "    # Get the dimensions of the page where this entity is located\n",
    "    try:\n",
    "        page_width, page_height = extract_page_dimensions(document, page_index)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "    # Convert normalized vertices to original vertices (in pixel coordinates)\n",
    "    entity_bounding_poly[\"vertices\"] = normalized_to_original(\n",
    "        entity_normalized_vertices, page_width, page_height\n",
    "    )\n",
    "\n",
    "\n",
    "def handle_nested_entities(\n",
    "    entities: List[Dict], document: Dict, page_index: int = 0\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Recursively process a list of entities and their nested entities by converting\n",
    "    normalized vertices to original pixel-based vertices.\n",
    "\n",
    "    Args:\n",
    "        entities (List[Dict]): A list of dictionaries representing entities, each potentially containing\n",
    "                               properties (nested entities) and bounding polygon details.\n",
    "        document (Dict): The document structure that includes page dimensions and other metadata.\n",
    "        page_index (int, optional): The index of the page to be used as a fallback if no page information\n",
    "                                    is provided for an entity. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        None: The function processes each entity in place, handling both parent and nested entities.\n",
    "    \"\"\"\n",
    "    for entity in entities:\n",
    "        # Process the current entity\n",
    "        process_entity(entity, document, page_index)\n",
    "\n",
    "        # Check for nested entities and process them recursively\n",
    "        nested_entities = entity.get(\"properties\", [])\n",
    "        if nested_entities:\n",
    "            handle_nested_entities(nested_entities, document, page_index)\n",
    "\n",
    "\n",
    "def add_vertices_to_entities(document: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Adds original pixel-based vertices to all entities in the provided document by converting\n",
    "    their normalized vertices using the document's page dimensions.\n",
    "\n",
    "    Args:\n",
    "        document (Dict): A dictionary representing the document, which contains entity data,\n",
    "                         page information, and normalized vertices.\n",
    "\n",
    "    Returns:\n",
    "        Dict: The modified document where all entities (including nested ones) are updated\n",
    "              with their original pixel-based vertices.\n",
    "    \"\"\"\n",
    "    page_index = 0  # Default to page 0 for single-page documents\n",
    "\n",
    "    # Retrieve all entities from the document\n",
    "    entities = document.get(\"entities\", [])\n",
    "\n",
    "    # Process the entities if any are present\n",
    "    if entities:\n",
    "        handle_nested_entities(entities, document, page_index)\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2b3e0-8d10-4a57-83ab-330b041fa187",
   "metadata": {},
   "source": [
    "### 4.Run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b255b0-cb06-4f4e-8f0e-75c2d56a52bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    file_name_list, file_path_dict = file_names(file_path)\n",
    "    print(file_path)\n",
    "    for i in range(len(file_name_list)):\n",
    "        json_file_path = (\n",
    "            \"gs://\" + file_path.split(\"/\")[2] + \"/\" + file_path_dict[file_name_list[i]]\n",
    "        )\n",
    "        print(json_file_path)\n",
    "        document_data = blob_downloader(\n",
    "            json_file_path.split(\"/\")[2], \"/\".join(json_file_path.split(\"/\")[3:])\n",
    "        )\n",
    "        # print(document_data)\n",
    "\n",
    "        updated_document = add_vertices_to_entities(document_data)\n",
    "\n",
    "        # Save the updated JSON\n",
    "        print(output_path)\n",
    "        store_document_as_json(\n",
    "            json.dumps(updated_document),\n",
    "            output_path.split(\"/\")[2],\n",
    "            (\"/\").join(output_path.split(\"/\")[3:]) + \"/\" + file_name_list[i],\n",
    "        )\n",
    "\n",
    "    print(f\"Vertices added to entities. Output file saved to {output_path}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c9da6-5333-4b95-90dc-7f78425b597e",
   "metadata": {},
   "source": [
    "### 5.Output\n",
    "\n",
    "Compare the difference between before and after updated json file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6390a5e8-f8c8-49de-b832-05a43d7357d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Before Updating the Json File\n",
    "<img src=\"./Images/before_updation.png\" width=800 height=400 ></img>\n",
    "#### After Updating the Json File\n",
    "<img src=\"./Images/after_updation.png\" width=800 height=400 ></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59be77-64c0-4201-8db9-79d937cc9efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
