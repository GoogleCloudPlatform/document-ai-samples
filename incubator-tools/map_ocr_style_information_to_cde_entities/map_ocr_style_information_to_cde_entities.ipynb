{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cbcbc6b-0c0b-42d5-8619-ebd1f4bf8657",
   "metadata": {},
   "source": [
    "# Map OCR style information to CDE entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054d9da-3034-4fb0-b828-cd536198f68c",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c2600-51ad-4085-9555-7f3332ccc1b4",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the **DocAI Incubator Team**. No guarantees of performance are implied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d9223-2537-4ae0-98a5-32e372d1419d",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This document provides a step-by-step guide to help you add OCR style information for every CDE entity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07918d4f-aae3-428d-8a71-4fbe2d6c8c90",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* Vertex AI JupyterLab Environment\n",
    "* Google Cloud Storage Bucket\n",
    "* OCR Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d9b0c-4c03-41b6-aa2e-fcf838791610",
   "metadata": {},
   "source": [
    "## Step by Step procedure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d50f73-088d-4b58-9cfc-f276f2201f9c",
   "metadata": {},
   "source": [
    "### 1.Importing Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01d013-4198-463f-9c6b-2792ec407efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad415a6d-6b54-4241-a781-678a527f0ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from google.cloud import storage\n",
    "from typing import Dict, List, Tuple, Sequence, Any, Optional\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from google.api_core.client_options import ClientOptions\n",
    "import json\n",
    "import io\n",
    "from io import BytesIO\n",
    "from utilities import file_names, store_document_as_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110046b1-ebea-4a2b-990d-5acda4a3b66c",
   "metadata": {},
   "source": [
    "### 2.Setup the inputs\n",
    "\n",
    "* `project_id` : This is the unique identifier for the Google Cloud project.\n",
    "* `location` : This specifies the location or region where the resources are located.\n",
    "* `processor_id` : This is the unique identifier for a processor in Google Cloud.\n",
    "* `processor_version` : This identifies the specific version of the processor or model you are using.\n",
    "* `gcs_input_path` : This is the path to a Google Cloud Storage (GCS) bucket and folder where input documents are stored.\n",
    "* `gcs_output_path` : This is the GCS path where output will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41618163-fafe-438a-a8d4-25571fc600b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"rand-automl-project\"\n",
    "location = \"us\"\n",
    "processor_id = \"5cda88db4990c164\"\n",
    "processor_version_id = (\n",
    "    \"pretrained-ocr-v2.0-2023-06-02\"  # version should be greater or equal to ocr-v2.0\n",
    ")\n",
    "\n",
    "gcs_input_path = \"gs://nachinta/customer_testing/test_harness/async_batch_process/test_1/iteration_1/12512366521158903846/\"  # '/' should be present at the end of the path.\n",
    "gcs_output_path = \"gs://nachinta/customer_testing/test_harness/sync_process/test_1/mapping_test/\"  # '/' should be present at the end of the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8707016c-f88d-4580-b777-199efedfcd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"project-id\"\n",
    "location = \"us\"\n",
    "processor_id = \"processor-id\"\n",
    "processor_version = (\n",
    "    \"pretrained-ocr-v2.0-2023-06-02\"  # version should be greater or equal to ocr-v2.0\n",
    ")\n",
    "gcs_input_path = \"gs://{bucket-name}/{sub-folder}/{input-jsons-files}/\"  # '/' should be present at the end of the path.\n",
    "gcs_output_path = \"gs://{bucket-name}/{sub-folder}/{output-json-path-to-store}/\"  # '/' should be present at the end of the path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846011bb-eb92-454d-9ea9-6c9763490bce",
   "metadata": {},
   "source": [
    "### 3.Run the required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127e1d9-6a45-4827-a10c-481343697abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_pdf_bytes(json: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Creates PDF bytes from image content in a JSON document (typically ground truth data),\n",
    "    which is used for further processing of files. This function decodes image data and\n",
    "    combines them into a single PDF.\n",
    "\n",
    "    Args:\n",
    "        json (str): The JSON string representing the ground truth data, typically retrieved\n",
    "        from Google Cloud's Document AI output or other sources. The JSON should contain image data in\n",
    "        its content field.\n",
    "\n",
    "    Returns:\n",
    "        bytes: A byte representation of the generated PDF containing all images.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no images are found in the input JSON or an invalid image format is encountered.\n",
    "\n",
    "    Example:\n",
    "        json_str = '{\"pages\": [{\"image\": {\"content\": \"<image_bytes_in_base64>\"}}]}'\n",
    "        pdf_bytes = create_pdf_bytes(json_str)\n",
    "    \"\"\"\n",
    "    from google.cloud import documentai_v1beta3\n",
    "\n",
    "    def decode_image(image_bytes: bytes) -> Image.Image:\n",
    "        \"\"\"Decodes image bytes into a PIL Image object.\"\"\"\n",
    "        with io.BytesIO(image_bytes) as image_file:\n",
    "            image = Image.open(image_file)\n",
    "            image.load()\n",
    "        return image\n",
    "\n",
    "    def create_pdf_from_images(images: Sequence[Image.Image]) -> bytes:\n",
    "        \"\"\"Creates a PDF from a sequence of images.\n",
    "\n",
    "        Args:\n",
    "            images: A sequence of images to be included in the PDF.\n",
    "\n",
    "        Returns:\n",
    "            bytes: The PDF bytes generated from the images.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If no images are provided.\n",
    "        \"\"\"\n",
    "        if not images:\n",
    "            raise ValueError(\"At least one image is required to create a PDF\")\n",
    "\n",
    "        # PIL PDF saver does not support RGBA images\n",
    "        images = [\n",
    "            image.convert(\"RGB\") if image.mode == \"RGBA\" else image for image in images\n",
    "        ]\n",
    "\n",
    "        with io.BytesIO() as pdf_file:\n",
    "            images[0].save(\n",
    "                pdf_file, save_all=True, append_images=images[1:], format=\"PDF\"\n",
    "            )\n",
    "            return pdf_file.getvalue()\n",
    "\n",
    "    d = documentai_v1beta3.Document\n",
    "    document = d.from_json(json)\n",
    "    synthesized_images = []\n",
    "    for i in range(len(document.pages)):\n",
    "        synthesized_images.append(decode_image(document.pages[i].image.content))\n",
    "    pdf_bytes = create_pdf_from_images(synthesized_images)\n",
    "\n",
    "    return pdf_bytes\n",
    "\n",
    "\n",
    "def process_document_sample(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    processor_version_id: str,\n",
    "    mime_type,\n",
    ") -> documentai.ProcessResponse:\n",
    "    \"\"\"\n",
    "    Processes a document using a specified Document AI processor in Google Cloud and\n",
    "    returns the processed result. This function reads a file, processes it through a Document AI processor,\n",
    "    and retrieves the result which may include text extraction, form parsing, etc.\n",
    "\n",
    "    Args:\n",
    "        project_id (str): The Google Cloud project ID where the Document AI processor is located.\n",
    "        location (str): The location/region of the Document AI processor (e.g., 'us', 'eu').\n",
    "        processor_id (str): The ID of the Document AI processor to use for processing.\n",
    "        file_path (str): The local path or in-memory string content of the document to be processed.\n",
    "        processor_version_id (Optional[str], optional): The specific processor version to use, if any.\n",
    "            If not provided, the default processor version will be used. Defaults to None.\n",
    "        mime_type (Optional[str], optional): The MIME type of the document. Defaults to 'application/pdf'.\n",
    "        field_mask (Optional[str], optional): Field mask specifying the parts of the document to process.\n",
    "            If not provided, the entire document will be processed. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        documentai.ProcessResponse: The response object containing the processed document data from the processor.\n",
    "    \"\"\"\n",
    "    # You must set the `api_endpoint` if you use a location other than \"us\".\n",
    "    opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "    if processor_version_id:\n",
    "        name = client.processor_version_path(\n",
    "            project_id, location, processor_id, processor_version_id\n",
    "        )\n",
    "    else:\n",
    "        name = client.processor_path(project_id, location, processor_id)\n",
    "    # Read the file into memory\n",
    "    image_content = file_path\n",
    "    # Load binary data\n",
    "    raw_document = documentai.RawDocument(content=image_content, mime_type=mime_type)\n",
    "\n",
    "    process_options = documentai.ProcessOptions(\n",
    "        ocr_config=documentai.OcrConfig(\n",
    "            enable_native_pdf_parsing=False,\n",
    "            enable_image_quality_scores=False,\n",
    "            enable_symbol=False,\n",
    "            # OCR Add Ons https://cloud.google.com/document-ai/docs/ocr-add-ons\n",
    "            premium_features=documentai.OcrConfig.PremiumFeatures(\n",
    "                compute_style_info=True,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    request = documentai.ProcessRequest(\n",
    "        name=name,\n",
    "        raw_document=raw_document,\n",
    "        process_options=process_options,\n",
    "    )\n",
    "    result = client.process_document(request=request)\n",
    "\n",
    "    return result.document\n",
    "\n",
    "\n",
    "def get_token_xy(token: Any) -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Extracts the normalized bounding box coordinates (min_x, min_y, max_x, max_y) of a token.\n",
    "\n",
    "    Args:\n",
    "    - token (Any): A token object with layout information.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[float, float, float, float]: The normalized bounding box coordinates.\n",
    "\n",
    "    \"\"\"\n",
    "    vertices = token.layout.bounding_poly.normalized_vertices\n",
    "    minx_token, miny_token = min(point.x for point in vertices), min(\n",
    "        point.y for point in vertices\n",
    "    )\n",
    "    maxx_token, maxy_token = max(point.x for point in vertices), max(\n",
    "        point.y for point in vertices\n",
    "    )\n",
    "\n",
    "    return minx_token, miny_token, maxx_token, maxy_token\n",
    "\n",
    "\n",
    "def get_token_data(\n",
    "    json_dict: documentai.Document,\n",
    "    min_x: float,\n",
    "    max_x: float,\n",
    "    min_y: float,\n",
    "    max_y: float,\n",
    "    page_num: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts token data from the JSON dictionary based on provided bounding box coordinates and page number.\n",
    "\n",
    "    Args:\n",
    "    - json_dict (Dict[str, Any]): The JSON dictionary containing token data.\n",
    "    - min_x (float): Minimum x-coordinate of the bounding box.\n",
    "    - max_x (float): Maximum x-coordinate of the bounding box.\n",
    "    - min_y (float): Minimum y-coordinate of the bounding box.\n",
    "    - max_y (float): Maximum y-coordinate of the bounding box.\n",
    "    - page_num (int): Page number.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[str, List[Dict[str, Any]], List[Dict[str, float]]]: A tuple containing:\n",
    "        1. The extracted text from the tokens.\n",
    "        2. A list of dictionaries containing text anchor data for each token.\n",
    "        3. A list of dictionaries containing page anchor data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        font_details = []\n",
    "\n",
    "        y_allowance = (\n",
    "            0.005  # edit this if the line items are closer and your not getitng desir\n",
    "        )\n",
    "        x_allowance = 0.005\n",
    "        for page in json_dict.pages:\n",
    "            if page_num == page.page_number - 1:\n",
    "                for token in page.tokens:\n",
    "                    minx_token, miny_token, maxx_token, maxy_token = get_token_xy(token)\n",
    "                    if (\n",
    "                        min_y <= miny_token + y_allowance\n",
    "                        and max_y >= maxy_token - y_allowance\n",
    "                        and min_x <= minx_token + x_allowance\n",
    "                        and max_x >= maxx_token - x_allowance\n",
    "                    ):\n",
    "                        # print(token)\n",
    "                        font_details.append(token.style_info)\n",
    "    except:\n",
    "        print(\"No tokens found in the entity\")\n",
    "\n",
    "    return font_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2b3e0-8d10-4a57-83ab-330b041fa187",
   "metadata": {},
   "source": [
    "### 4.Run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b255b0-cb06-4f4e-8f0e-75c2d56a52bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_name_list, file_dicts = file_names(gcs_input_path)\n",
    "    storage_client = storage.Client()\n",
    "    source_bucket = storage_client.bucket(gcs_input_path.split(\"/\")[2])\n",
    "    for i in file_dicts.values():\n",
    "        try:\n",
    "            file_name = (\"/\").join(i.split(\"/\")[-2:])\n",
    "            print(\n",
    "                \"Processing File >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> \",\n",
    "                file_name.split(\"/\")[-1],\n",
    "            )\n",
    "            js_json = source_bucket.blob(i).download_as_string().decode(\"utf-8\")\n",
    "            merged_pdf = create_pdf_bytes(js_json)\n",
    "            js = json.loads(js_json)\n",
    "            res = process_document_sample(\n",
    "                project_id=project_id,\n",
    "                location=location,\n",
    "                processor_id=processor_id,\n",
    "                file_path=merged_pdf,\n",
    "                processor_version_id=processor_version_id,\n",
    "                mime_type=\"application/pdf\",\n",
    "            )\n",
    "            for entity in js[\"entities\"]:\n",
    "                if \"properties\" in entity.keys() and len(entity[\"properties\"]) != 0:\n",
    "                    for child in entity[\"properties\"]:\n",
    "                        try:\n",
    "                            norm_vert = child[\"pageAnchor\"][\"pageRefs\"][0][\n",
    "                                \"boundingPoly\"\n",
    "                            ][\"normalizedVertices\"]\n",
    "                            min_x = min([ver[\"x\"] for ver in norm_vert])\n",
    "                            min_y = min([ver[\"y\"] for ver in norm_vert])\n",
    "                            max_x = max([ver[\"x\"] for ver in norm_vert])\n",
    "                            max_y = max([ver[\"y\"] for ver in norm_vert])\n",
    "                            font_dts = get_token_data(\n",
    "                                res,\n",
    "                                min_x,\n",
    "                                max_x,\n",
    "                                min_y,\n",
    "                                max_y,\n",
    "                                int(\n",
    "                                    child[\"pageAnchor\"][\"pageRefs\"][0].get(\n",
    "                                        \"pageNumber\", \"0\"\n",
    "                                    )\n",
    "                                ),\n",
    "                            )\n",
    "                            temp_list = []\n",
    "                            if len(font_dts) > 0:\n",
    "                                for i in font_dts:\n",
    "                                    temp = {\n",
    "                                        \"fontSize\": i.font_size,\n",
    "                                        \"pixelFontSize\": i.pixel_font_size,\n",
    "                                        \"fontType\": i.font_type,\n",
    "                                        \"fontWeight\": i.font_weight,\n",
    "                                        \"handWritten\": i.handwritten,\n",
    "                                        \"textColor\": {\n",
    "                                            \"red\": i.text_color.red,\n",
    "                                            \"green\": i.text_color.green,\n",
    "                                            \"blue\": i.text_color.blue,\n",
    "                                        },\n",
    "                                        \"backgroundColor\": {\n",
    "                                            \"red\": i.background_color.red,\n",
    "                                            \"green\": i.background_color.green,\n",
    "                                            \"blue\": i.background_color.blue,\n",
    "                                        },\n",
    "                                    }\n",
    "                                    temp_list.append(temp)\n",
    "                            child[\"styleInfo\"] = temp_list\n",
    "                        except Exception as e:\n",
    "                            print(\"Error:\", e)\n",
    "                else:\n",
    "                    try:\n",
    "                        norm_vert = entity[\"pageAnchor\"][\"pageRefs\"][0][\"boundingPoly\"][\n",
    "                            \"normalizedVertices\"\n",
    "                        ]\n",
    "                        min_x = min([ver[\"x\"] for ver in norm_vert])\n",
    "                        min_y = min([ver[\"y\"] for ver in norm_vert])\n",
    "                        max_x = max([ver[\"x\"] for ver in norm_vert])\n",
    "                        max_y = max([ver[\"y\"] for ver in norm_vert])\n",
    "                        font_dts = get_token_data(\n",
    "                            res,\n",
    "                            min_x,\n",
    "                            max_x,\n",
    "                            min_y,\n",
    "                            max_y,\n",
    "                            int(\n",
    "                                entity[\"pageAnchor\"][\"pageRefs\"][0].get(\n",
    "                                    \"pageNumber\", \"0\"\n",
    "                                )\n",
    "                            ),\n",
    "                        )\n",
    "                        # print(font_dts)\n",
    "                        temp_list = []\n",
    "                        if len(font_dts) > 0:\n",
    "                            for i in font_dts:\n",
    "                                temp = {\n",
    "                                    \"fontSize\": i.font_size,\n",
    "                                    \"pixelFontSize\": i.pixel_font_size,\n",
    "                                    \"fontType\": i.font_type,\n",
    "                                    \"fontWeight\": i.font_weight,\n",
    "                                    \"handWritten\": i.handwritten,\n",
    "                                    \"textColor\": {\n",
    "                                        \"red\": i.text_color.red,\n",
    "                                        \"green\": i.text_color.green,\n",
    "                                        \"blue\": i.text_color.blue,\n",
    "                                    },\n",
    "                                    \"backgroundColor\": {\n",
    "                                        \"red\": i.background_color.red,\n",
    "                                        \"green\": i.background_color.green,\n",
    "                                        \"blue\": i.background_color.blue,\n",
    "                                    },\n",
    "                                }\n",
    "                                temp_list.append(temp)\n",
    "                        entity[\"styleInfo\"] = temp_list\n",
    "                    except Exception as e:\n",
    "                        print(\"Error:\", e)\n",
    "            print(\"Processed Successfully : \", file_name.split(\"/\")[-1])\n",
    "            store_document_as_json(\n",
    "                json.dumps(js),\n",
    "                gcs_output_path.split(\"/\")[2],\n",
    "                \"/\".join(gcs_output_path.split(\"/\")[3:]) + file_name.split(\"/\")[-1],\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"Main Try Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c9da6-5333-4b95-90dc-7f78425b597e",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "The updated JSONs containing Style information for each entity and will be saved to the specified output folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6390a5e8-f8c8-49de-b832-05a43d7357d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Before Tooling JSON file \n",
    "<img src=\"./images/before_tooling.png\" width=400 height=200 ></img>\n",
    "#### After Tooling JSON file \n",
    "<img src=\"./images/after_tooling.png\" width=400 height=200 ></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd9604-02c4-4da8-9c7e-3941ace26fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1b8e4-83dd-4026-85aa-e40fec15c94b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
