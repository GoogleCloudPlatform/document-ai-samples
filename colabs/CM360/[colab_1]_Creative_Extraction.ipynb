{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "[colab-1] Creative Extraction.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "x4wEttlQ6BEd"
   ],
   "toc_visible": true,
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/caseynjustus/document-ai-samples/blob/main/colabs/CM360/%5Bcolab_1%5D_Creative_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIOFwP_z5aeU"
   },
   "source": [
    "The Project focuses on analysing Ad Creatives and its related performance metrics and tries to find correlations between the elements present in the past creatives to suggest what can be good add-ons and what can help to improve performance of future creatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4wEttlQ6BEd"
   },
   "source": [
    "#GCP Setup\n",
    "\n",
    " 1. Create a new Service Account is created in the IAM. Assign the following permissions to the service account:\n",
    "\t - BigQuery Admin\n",
    "\t - Storage Admin\n",
    "\t - optional: AutoML Editor\n",
    " 2. Enable the DCM/DFA Reporting and Trafficking API, using the link: [create or select a project in the Google API Console and enable the API](https://console.developers.google.com/start/api?id=dfareporting&credential=client_key). Using this link guides you through the process and activates the DCM/DFA Reporting and Trafficking API automatically.\n",
    " 3. Enable the Vision API, using this [link](https://console.cloud.google.com/flows/enableapi?apiid=vision.googleapis.com&_ga=2.111164166.345275315.1594895230-1299350283.1594895230)\n",
    " 4. Download the json key for the new Service Account created in step1 and paste in cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqzpZ0GDTfIe"
   },
   "source": [
    "\n",
    "# CM Setup\n",
    "\n",
    " 1. For CM link, follow this link: [Manage user access](https://support.google.com/dcm/answer/6098287#email) to provide access to the service account email and get job profile id\n",
    " 2. Use the offline reporting API to download the creative level performance data (Creative ID will be the primary key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBXoDDeG7cbk"
   },
   "source": [
    "### Input1\n",
    "Paste the json key downloaded from GCP over placeholder contents in cell below"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "26AWCwTTSvN7"
   },
   "source": [
    "%%writefile credentials.json\n",
    "{\n",
    "  \"type\": \"service_account\",\n",
    "  \"project_id\": \"[project_id]\",\n",
    "  \"private_key_id\": \"[private_key_id]\",\n",
    "  \"private_key\": \"[private_key]\",\n",
    "  \"client_email\": \"[client_email]\",\n",
    "  \"client_id\": \"[client_id]\",\n",
    "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "  \"client_x509_cert_url\": \"[client_x509_cert_url]\"\n",
    "  }"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-GoEMI4PTbRI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "47b958f3-0e72-4425-e3e8-7074e65348f9"
   },
   "source": [
    "%%writefile utils_mini.py\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "from googleapiclient import discovery\n",
    "\n",
    "def get_credentials():\n",
    "  credentials = service_account.Credentials.from_service_account_file(\n",
    "    'credentials.json', scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "  print(\"credentials\"+str(credentials))\n",
    "  return credentials\n",
    "\n",
    "def init_bq():\n",
    "  credentials = get_credentials()\n",
    "  bq_client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "  return bq_client\n",
    "\n",
    "def init_cm():\n",
    "  api_name = 'dfareporting'\n",
    "  api_version = 'v3.4'\n",
    "  oauth_scopes = ['https://www.googleapis.com/auth/dfatrafficking']\n",
    "\n",
    "  credentials = get_credentials()\n",
    "  credentials = credentials.with_scopes(oauth_scopes)\n",
    "  service = discovery.build(api_name, api_version, credentials=credentials)\n",
    "\n",
    "  return service\n",
    "\n",
    "bq_client = init_bq()\n",
    "cm_client = init_cm()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Overwriting utils_mini.py\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZC8jEXy92r7V",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "70efc853-fc64-4097-8d01-c64fca714ec8"
   },
   "source": [
    "%%writefile bq_helper_mini.py\n",
    "\n",
    "from utils_mini import bq_client\n",
    "from google.cloud import bigquery\n",
    "import ndjson\n",
    "\n",
    "#bq_input_schema: row_num, creative_id, file_name (should include extension), full_url, creative_pixel_size (recommended)\n",
    "\n",
    "def write_batch_to_json(creative_data, batch_file_name):\n",
    "  with open(batch_file_name, 'w') as f:\n",
    "    ndjson.dump(creative_data, f)\n",
    "\n",
    "def write_to_bq(dataset_name, table_name, table_file_name):\n",
    "  try:\n",
    "    global bq_client\n",
    "    dataset_ref = bq_client.dataset(dataset_name)\n",
    "    table_ref = dataset_ref.table(table_name)\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "    job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "    job_config.autodetect = True\n",
    "    with open(table_file_name, \"rb\") as source_file:\n",
    "      job = bq_client.load_table_from_file(source_file, table_ref,\n",
    "                                           job_config=job_config)\n",
    "      job.result()\n",
    "    print(f\"Loaded {table_name} table\")\n",
    "  except Exception as e:\n",
    "    print(f\"ERROR - {table_name}: {e}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Overwriting bq_helper_mini.py\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "peOdQCkT3yfI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7447aff5-0209-44e1-dce5-4e89869cd886"
   },
   "source": [
    "%%writefile cm_helper.py\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from utils_mini import cm_client\n",
    "from googleapiclient.errors import HttpError\n",
    "from ssl import SSLError\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def retry(request, retries=4):\n",
    "  \"\"\"Retries a standard CM request for appropriate error codes.\n",
    "\n",
    "  Args:\n",
    "    request: CM request (before .execute())\n",
    "    retries: cap on retries\n",
    "\n",
    "  Returns:\n",
    "    response\n",
    "\n",
    "  Raises:\n",
    "    HttpError: if exceeded\n",
    "  \"\"\"\n",
    "\n",
    "  for this_retry in range(retries):\n",
    "    try:\n",
    "      return request.execute()\n",
    "    except HttpError as e:\n",
    "      if this_retry == retries - 1 or e.resp.status not in [403, 429, 500, 503]:\n",
    "        raise\n",
    "      wait = 10 * 2**this_retry\n",
    "      time.sleep(wait)\n",
    "    except SSLError as e:\n",
    "      if this_retry == retries - 1 or 'timed out' not in e.message:\n",
    "        raise\n",
    "      wait = 10 * 2**this_retry\n",
    "      time.sleep(wait)\n",
    "\n",
    "\n",
    "def fetch_cm_creatives(cm_profile_id, job_type,\n",
    "                       start_date=None, end_date=None, limit=False):\n",
    "  \"\"\"Fetches creatives using the CM API.\n",
    "\n",
    "  Args:\n",
    "    cm_profile_id: Campaign Manager User Profile with read access to creatives\n",
    "    job_type: 'image' or 'video'\n",
    "    start_date: filter on last changelog timestamp\n",
    "    end_date: filter on last changelog timestamp\n",
    "    limit: optional numerical limit for number of creatives\n",
    "\n",
    "  Returns:\n",
    "    list of dicts, each with keys Creative_ID, Advertiser_ID, Creative_Name,\n",
    "      Full_URL\n",
    "  \"\"\"\n",
    "\n",
    "  global cm_client\n",
    "\n",
    "  # This extraction is done in three steps:\n",
    "  # 1. Search changelogs for all creatives modified in date range\n",
    "  # In batches of 500 (maximum filter size for creative IDs):\n",
    "  # 2. Fetch creative objects matching those IDs\n",
    "  # 3. Extract URLs from each batch of creatives\n",
    "  # Step 1 is done because a date filter isn't available in the API's creative\n",
    "  # endpoint, and step 2 is done to reduce the number of API calls vs. 1 per\n",
    "  # creative.\n",
    "\n",
    "  # STEP 1: search changelogs\n",
    "  print('fetching creative updates from changelogs...')\n",
    "\n",
    "  # make time/date strings for filtering changelogs\n",
    "  zero_time = \"T00:00:00-00:00\" # UTC\n",
    "  start_str = None if start_date is None else str(start_date) + zero_time\n",
    "  end_str = None if end_date is None else str(end_date) + zero_time\n",
    "\n",
    "  # assemble request\n",
    "  request = cm_client.changeLogs().list(profileId=cm_profile_id,\n",
    "                                 objectType='OBJECT_CREATIVE',\n",
    "                                 minChangeTime=start_str,\n",
    "                                 maxChangeTime=end_str)\n",
    "\n",
    "  # paginate\n",
    "  creative_ids = set()\n",
    "  start = time.time()\n",
    "  page = 0\n",
    "  while True:\n",
    "    page += 1\n",
    "    print('fetching page {}, time: {}...'\n",
    "          .format(page, time.time() - start))\n",
    "    response = retry(request)\n",
    "\n",
    "    # collect creative IDs from changelog response\n",
    "    for changelog in response['changeLogs']:\n",
    "      creative_ids.add(changelog['objectId'])\n",
    "\n",
    "    if 'nextPageToken' in response:\n",
    "      request = cm_client.changeLogs().list_next(request, response)\n",
    "    else:\n",
    "      break\n",
    "    if limit and len(creative_ids) >= limit:\n",
    "      break\n",
    "\n",
    "  creative_ids = list(creative_ids)\n",
    "  if limit and len(creative_ids) > limit:\n",
    "    creative_ids = creative_ids[:limit]\n",
    "  print('found {} creatives modified in date range'.format(len(creative_ids)))\n",
    "\n",
    "  # BATCH: define batches for steps 2 & 3\n",
    "  batch_size = 500\n",
    "  out_creatives = []  # final output collection\n",
    "  row_num=1\n",
    "  for i in range(0, len(creative_ids), batch_size):\n",
    "    print('processing creative batch {} to {}...'.format(i, i + batch_size))\n",
    "\n",
    "    # STEP 2: assemble creative list\n",
    "    print('fetching creative details...')\n",
    "    batch_cids = creative_ids[i:i + batch_size]\n",
    "    request = cm_client.creatives().list(profileId=cm_profile_id, ids=batch_cids)\n",
    "    response = retry(request)\n",
    "    creatives = response['creatives']\n",
    "\n",
    "    # STEP 3: extract asset URLs\n",
    "    print('extracting URLs...')\n",
    "    for creative in creatives:\n",
    "      if 'creativeAssets' not in creative:\n",
    "        continue\n",
    "\n",
    "      assets = creative['creativeAssets']\n",
    "      assets.sort(reverse=True, key=(lambda asset: asset['fileSize']))\n",
    "\n",
    "      accepted_formats = {\n",
    "          'video': ['mp4', 'mov', 'wmv', 'm4v', 'webm'],\n",
    "          'image': ['jpg', 'png', 'gif', 'jpeg','html','htm']\n",
    "      }\n",
    "\n",
    "      url = None\n",
    "      for asset in assets:\n",
    "        # check two special cases for video creatives first, in which case\n",
    "        # the URL is easy to get\n",
    "        if job_type == 'video' and 'progressiveServingUrl' in asset:\n",
    "          url = asset['progressiveServingUrl']\n",
    "          break\n",
    "        elif job_type == 'video' and 'streamingServingUrl' in asset:\n",
    "          url = asset['streamingServingUrl']\n",
    "          break\n",
    "        # otherwise, for image creatives or video creatives not captured by the\n",
    "        # above, try a reconstructed URL and check the file extension\n",
    "        else:\n",
    "          # one parameter in the reconstructed_url is unknown, and we\n",
    "          # must try multiple candidates\n",
    "          params = [creative['advertiserId'], 'sadbundle', 'simgad']\n",
    "\n",
    "          for param in params:\n",
    "            reconstructed_url = 'https://s0.2mdn.net/{}/{}'.format(\n",
    "                param,\n",
    "                asset['assetIdentifier']['name'])\n",
    "            extension = reconstructed_url.split('.')[-1].lower()\n",
    "\n",
    "            if extension in accepted_formats[job_type]:\n",
    "              # check if valid url\n",
    "              request = requests.get(reconstructed_url)\n",
    "              if request.status_code == 200:\n",
    "                url = reconstructed_url\n",
    "                break\n",
    "\n",
    "      if url:\n",
    "        if (creative['size']['width']>1) and (creative['size']['height']):\n",
    "          out_creatives.append({\n",
    "              'row_num' : row_num,\n",
    "              'creative_id': creative['id'],\n",
    "              'advertiser_id': creative['advertiserId'],\n",
    "              'creative_name': creative['name'],\n",
    "              'full_url': url,\n",
    "              'file_name': str(creative['name']+\".\"+extension),\n",
    "              'creative_pixel_size': str(str(creative['size']['width'])+'x'+str(creative['size']['height'])),\n",
    "              'last_modified_date': \"\"\n",
    "          })\n",
    "          row_num+=1\n",
    "\n",
    "  print('found {} creatives with suitable assets'.format(len(out_creatives)))\n",
    "  return out_creatives"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Overwriting cm_helper.py\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4slBH4yg7-yy"
   },
   "source": [
    "### Input2\n",
    "\n",
    "- CM_profile_id : Obtained from CM account while setting up user profile\n",
    "- job_type : image to process jpeg, gif & html5 creatives\n",
    "- start_date & end_date : To filter out creatives changed with in a specific time duration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M78fnfYS5qXm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4f87fb24-f6d3-471d-c91c-e4ab00d49547"
   },
   "source": [
    "from cm_helper import *\n",
    "\n",
    "profile_id = 6471785  # @param {type:'integer'}\n",
    "start_date = \"2019-01-03\"  # @param {type:'string'}\n",
    "end_date = \"2021-04-21\"  # @param {type:'string'}\n",
    "creatives = fetch_cm_creatives(\n",
    "    cm_profile_id=profile_id, job_type=\"image\", start_date=start_date, end_date=end_date\n",
    ")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "fetching creative updates from changelogs...\n",
      "fetching page 1, time: 2.1457672119140625e-06...\n",
      "fetching page 2, time: 0.7818288803100586...\n",
      "found 133 creatives modified in date range\n",
      "processing creative batch 0 to 500...\n",
      "fetching creative details...\n",
      "extracting URLs...\n",
      "found 52 creatives with suitable assets\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ET39xC8Bj4Do",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4c4d21f0-86cc-4e5d-f059-90c4e0c5f553"
   },
   "source": [
    "print(\"#Creatives with suitable assets : \" + str(len(creatives)))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "#Creatives with suitable assets : 52\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1qOv8S1W1DS"
   },
   "source": [
    "Viewing the Data for a Creative"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "awkQ2Shwj5uw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0108eef3-fcf5-42ce-80ae-af06de333c07"
   },
   "source": [
    "creatives[0]"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'advertiser_id': '4895563',\n",
       " 'creative_id': '63346142',\n",
       " 'creative_name': 'Accessories_120x600_A_ShopNow.png',\n",
       " 'creative_pixel_size': '120x600',\n",
       " 'file_name': 'Accessories_120x600_A_ShopNow.png.png',\n",
       " 'full_url': 'https://s0.2mdn.net/4895563/1-Accessories_120x600_A_ShopNow.png',\n",
       " 'last_modified_date': '',\n",
       " 'row_num': 1}"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jkFobWSXHMk"
   },
   "source": [
    "Install python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_dWTbsWYThVE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "823a7862-20db-42ee-bcde-14ceaadb7df9"
   },
   "source": [
    "!pip install ndjson"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ndjson in /usr/local/lib/python3.7/dist-packages (0.3.1)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aEyRIr9Xbyd"
   },
   "source": [
    "Exporting the urls in json file"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sBNDu0asj69g"
   },
   "source": [
    "from bq_helper_mini import *\n",
    "\n",
    "write_batch_to_json(creatives, \"creatives.json\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Gi_caVnXeyB"
   },
   "source": [
    "Exporting the Urls to BQ dataset\n",
    "\n",
    "Inputs\n",
    "- Enter valid BQ dataset Name\n",
    "- Enter valid BQ table Name"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t6EbgtTkJpIn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "efd5a41e-69fe-4164-e89e-2aa841fb3fe2"
   },
   "source": [
    "input_dataset_name = \"demoverse\"  # @param {type:'string'}\n",
    "input_table_name = \"creative_urls\"  # @param {type:'string'}\n",
    "write_to_bq(\n",
    "    dataset_name=input_dataset_name,  # BQ Dataset Name\n",
    "    table_name=input_table_name,  # BQ Table Name\n",
    "    table_file_name=\"creatives.json\",  # json file name\n",
    ")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Loaded creative_urls table\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}